<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[防火墙和网络地址转换]]></title>
    <url>%2Fnetwork-protocol%2Fnat_firewall.html</url>
    <content type="text"><![CDATA[防火墙和网络地址转换 互联网发展到现在，最主要有两点问题： 一是容易遭受攻击，通常使用防火墙来限制和控制互联网中流量的流向 二是 IPv4 地址数量已经枯竭，虽然 IPv6 的进程在加快，但在完全应用之前，还是需要 NAT 地址转换来缓解 IPv4 地址不足的压力 防火墙常见的防火墙分为两种，包过滤防火墙 和 代理防火墙。它们主要的区别是操作的协议层次不同。包过滤防火墙是一个互联网路由器，可以丢弃符合（或不符合）一定条件的数据包，而代理防火墙可以看作一个多宿主的服务器主机。 包过滤防火墙简单的过滤包括网络层或传输层报头中各个部分的比较，如 IP 地址、IP 选项、ICMP 报文的类型，或是根据端口确定的各种服务。 这里还可将其分为无状态和有状态的。无状态即对每个数据包单独处理，而有状态要考虑该报文是否为分片，能够关联已经到达或即将到达的数据包来推断流的信息。 通常来说，对于外出的规则很少，而为了防范各种攻击，只允许很少流量进入。 代理防火墙代理防火墙并不是真正意义上的路由器，它只是运行一个火多个应用层网关的主机，不转发 IP 报文，但能在应用层中继两个连接之间的特定类型的流量。 最常见的有两种，HTTP 代理防火墙和 SOCKS 代理防火墙 HTTP 代理防火墙 也叫 Web 代理，只支持 HTTP 和 HTTPS。对于客户端来说，它是服务器，对于服务器来说，它是客户端。这种代理往往提供 Web 缓存功能，保存网页副本，减少延迟。也能作为内容过滤器，基于“黑名单”来阻止用户访问某些网站。相反的，有一些隧道代理服务器可以避免用户的访问被“黑名单”所过滤。 SOCKS 协议 SOCKS 协议可以用于 Web 之外的服务，通常用作科学上网。more NAT 地址转换 NAT （Network Address Translation），本质上是允许在互联网不同地方重复使用相同的 IP 地址的机制。当所有进出的流量通过 NAT 设备时，该设备把内部的地址空间和外部全球地址空间分割开。 基本 NAT 和 NAPT基本 NAT 只执行 IP 地址的重写，本质上将私有 IP 改写为一个公共地址，一个内部地址对应一个外部地址。 比较流行的方式是使用端口号来作为标识，通常使用一个外部地址(也可以是一个 IP 地址池)： 很明显 NAPT 可以减少对公共 IP 地址的需求。 不过注意，并不是说，NAT 内部的地址一定是私有地址范围，也可以是公网地址。原理上是可以接受的，但如果私有地址内部要访问一个远端地址，而这个地址正好呗内部某个主机使用，则造成屏蔽，永远到达不了远端系统。 通常我们说的 NAT 同时包含传统 NAT 和 NAPT。 NAT 和 TCP对于 TCP 连接来说，需要保持 源 IP、源端口、目标 IP、目标端口 的四元组，NAT 会创建一个内部状态记住一个新的连接，以便收到该链接数据的时候，能够正确的返回给内部主机，这种状态叫 NAT 映射。 当连接正常断开（交换 FIN 包）时，这条映射会被清除。但如果连接没有正常关闭，会造成 NAT 映射无法删除。 NAT 在发出 SYN 报文后激活一个连接计时器，如果超时没有收到 ACK，那么删除映射。在建立连接后也激活一个会话计时器，时间通常为小时单位，如果没有数据传输并且会话计时器超时，那么响内部主机发送探测报文，以检测连接是否还“活着”，如果活着，重置计时器，如果连接已经断开，则会收到内部主机的 RST，然后清除映射。 另外，NAT 无法处理 IP 分片的报文，因为分片报文中除了第一个分片，都不包含端口信息。 NAT 端口转换和过滤行为转换NAT 的操作方式差别很大，大部分细节设计具体的地址和端口映射。 若对于任何 Y1、Y2，X1:x1=X2:x2，那么称 NAT 是独立于端点的 若仅当 Y1=Y2 时，X1:x1=X2:x2，那么称 NAT 是依赖于地址的 若仅当 Y1:y1=Y2:y2 时，X1:x1=X2:x2，那么 NAT 是依赖于端口和地址的 过滤为了安全的考虑，对每种方式有不同的过滤行为： 行为名称 转换行为 过滤行为 独立于端点的 对于任何 Y1、Y2，X1:x1=X2:x2 只要任何 X1:x1 存在，允许任何数据包进入 依赖于地址的 仅当 Y1=Y2 时，X1:x1=X2:x2 只要 X1之前联系过 Y1，就允许任何来自 Y1 的数据 依赖于端口和地址的 仅当 Y1:y1=Y2:y2 时，X1:x1=X2:x2 只要 X1之前联系过 Y1:y1，就允许任何来自 Y1:y1 的数据 静态 NAT有时候互联网上的服务器也位于 NAT 之后，要想提供稳定的服务，必须保证每次转换的 IP 和端口完全相同。可以采用静态配置，也叫端口转发。 NAT 环回当一台主机要访问同一个 NAT 私有空间的服务器，且只知道服务器提供服务的公用地址时，源地址会是 Y:y 还是 Y1:y1 呢？ 实际上 NAT 设备都支持 X 以 X1:x1 为源地址到达 Y，这种行为称作有“外部源 IP 地址和端口”的发夹行为。 NAT 穿越当讨论 client/server 模型时，client 通过 NAT 向服务器发送请求，在 NAT 上生产了映射，那么服务器响应的数据可以畅通的返回。 但如果通信是以 P2P 为基础，那么 NAT 给通信带来了巨大的困难，特别是当双方的 NAT 不是独立于端口的时候。如：A、B 主机均在“依赖于端口和地址的 NAT”之后，A 主机向 B 主机发起连接，那么 B 主机所在的 NAT 设备没有关于 A 的信息，则会丢弃数据。反过来，B 要连接 A 也会被丢弃。 有的应用采用 TCP 同时连接 的技术来解决这个问题。A 和 B 在“同一时刻”向对方发送 SYN，在经过各自的 NAT 设备时，都产生了一个映射，那么对方的 SYN 到来的时候，就能够通过 NAT 设备。当然并不是真的同时，允许差一些时间，但是不能太长（大约 6 s ？），因为太长的时间差内，很可能 NAT 设备已经删除了映射。 不过这种办法可靠性不是特别高，需要更可靠的方法：STUN 和 TURN。详见more 配置防火墙和 NATNAT 通常只需要很少的配置，但防火墙通常需要配置，大多数网络中，NAT、IP 路由、防火墙等功能都在一台设备上。 防火墙需要一套说明匹配条件的指令来控制流量，通常叫访问控制列表（Access Control List，ACL）。许多防火墙允许在处理顺序中的某一点运用防火墙规则。Linux 中，主要使用 iptables。 如图，有五个重要节点（POSTROUTING/FORWARD/POSTROUTING/INPUT/OUTPUT），每个节点上有一条 链，这个链可以有多个行为组成： FILTER，负责过滤数据包 NAT，负责地址转换 MANGLE，拆解报文，做出修改并重新封装 RAW，关闭连接追踪 其中，每种行为有对应的 表，这个表就是对应行为的多条规则，比如过滤有多条规则：IP 地址不能为 x.x.x.x；端口必须为 3000 等等。 链和表关系： 可以用如下命令查看 Linux iptables 配置： 12# -t 代表查看哪个表，-L 表示 listiptables -t filter -L 如下命令添加规则： 12# 命令语法：iptables -t 表名 -A 链名 匹配条件 -j 动作iptables -t filter -A INPUT -s 192.168.1.146 -j DROP]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP 和自动配置]]></title>
    <url>%2Fnetwork-protocol%2Fdhcp.html</url>
    <content type="text"><![CDATA[DHCP 和自动配置 为了使用 TCP/IP 协议族，每台主机都要有一定的配置信息，特别是 IP 地址。通常这些配置信息有三种方法获得： 手工获取 通过一个系统服务获得 通过某种算法获得 手工获取就是静态配置 IP、DNS 等信息，主要讨论后两种方法。 DHCP动态主机配置协议（Dynamic Host Configuration Protocol，DHCP），它动态的分配 IP 地址和其他信息（子网掩码、路由器 IP 地址、DNS 服务器 IP 地址）给主机。DHCP 的设计基于早期的 Internet 引导程序协议(BOOTP)，它使用租用的概念来扩展 BOOTP，允许客户机使用一个商定好的时间来配置信息。通常客户端使用 68 端口，服务端使用 67 端口。 租用的时间是一个重要的配置参数。如果时间太短，可以提供一个可用性较高的地址池，但频繁的分配导致稳定性减小、网络流量负荷增大；较长的租期稳定性较好，但通常会较快耗尽可用地址。默认的租期在 12~24 小时，在租期过半时，客户端可以申请续租。 DHCPv4 和 BOOTPDHCP 是基于 BOOTP 的，并且 DHCPv4 是兼容 BOOTP 的，BOOTP 消息格式如下： 基本字段 字段 含义 yiaddr 从 server 送回 client 之 DHCP OFFER 与 DHCPACK 封包中，此栏填写分配给 client 的 IP 地址。 TRANSACTION ID DHCP REQUEST 时产生的数值，以作 DHCPREPLY 时的依据。 sname Server 之名称字符串，以 0x00 结尾。 siaddr 若 client 需要透过网络开机，从 server 送出之 DHCP OFFER、DHCPACK、DHCPNACK封包中，此栏填写开机程序代码所在 server 之地址。 SECONDS Client 端启动时间（秒）。（时间戳） options 允许厂商定议选项（Vendor-Specific Area)，以提供更多的设定信息（如：Netmask、Gateway、DNS、等等）。 OP 若是 client 送给 server 的封包，设为 1 ，反向为 2。 HTYPE 硬件类别，Ethernet 为 1。 HOPS 若封包需经过 router 传送，每站加 1 ，若在同一网内，为 0。 HLEN 硬件地址长度， Ethernet 为 6。 giaddr 若需跨网域进行 DHCP 发放，此栏为 relay agent 的地址，否则为 0。 FLAGS 从 0 到 15 共 16 bits ，最左一 bit 为 1 时表示 server 将以广播方式传送封包给 client ，其余尚未使用。 file 若 client 需要透过网络开机，此栏将指出开机程序名称，稍后以 TFTP 传送。 ciaddr 要是 client 端想继续使用之前取得之 IP 地址，则列于这里。 chaddr Client 之硬件地址。 选项DHCP 通过选项来扩展 BOOTP，选项用于携带 IP 地址之外的信息，如 子网掩码、路由器地址、DNS 地址 等等，其中还有一个消息类型选项，表明一个 BOOTP 报文是哪种 DHCP 消息： DHCP DISCOVER DHCP OFFER DHCP REQUEST DHCP DECLINE DHCP ACK DHCP NACK DHCP RELEASE DHCP 操作过程DHCP 消息是带有一组特殊选项的 BOOTP 消息，客户端连接到网络时，首先要发现网络中的 DHCP 服务器，然后请求服务器： discover一开始 client 使用 0 地址作为源，广播地址作为目标地址，去发现 DHCP 服务器： offer然后收到服务器的 offer 响应，这里可能有多个服务器，先收集所有信息。 注意大部分 offer 是以广播形式发送的，只不过我的电脑设置了单播，所以抓的包是单播形式。但是这里非常奇怪，为什么把还没正式分配的地址作为目标地址呢？如果网络中已经有一个 IP 地址为 10.0.0.51 的主机怎么办 ？这样为什么能够找到 client 主机呢？rfc 如下： 1If the BROADCAST bit is cleared to 0, the message SHOULD be sent as an IP unicast to the IP address specified in the &apos;yiaddr&apos; field and the link-layer address specified in the &apos;chaddr&apos; field. 但 rfc 回答了第一个问题。第二个问题，注意图中 offer 之前，服务器发送了一个 ARP 报文，这是在探测目前是否有主机使用了这个 IP 地址，通常是没有的，如果有，那么服务器会在 offer 中提供另一个 IP 地址。第三个问题，通过 Mac 地址找到 client，虽然此时 client IP 地址(0.0.0.0) 和 报文目标 IP 地址不同，不过 client 并不会丢弃这个报文（这很特殊）。 requestoffer 响应包含了服务器 可以提供的 IP 地址，client 从多个里面选取自己想要的（通常是以前使用过的），然后发送广播包请求： ACK、NAK服务器收到请求后，再次确认是否可以分配，然后响应 ACK 或 NAK 同意或不同意这个请求，如果发送 ACK，那么 client 就拥有了一个合法的 IP 地址，并且 client 发送 GARP 宣告自己的身份使得同网络的主机更新 ARP 缓存。 另外，client 从 ACK 中得到租用时间 T，计算出更新时间 T1=T/2，重新绑定时间 T2=7T/8. DHCP 状态机 DHCPv6DHCPv6 过程和 DHCPv4 类似，消息类型和 DHCPv4 对应如下： DHCPv6 DHCPv4 SOLICIT DISCOVER ADVERTISE OFFER REQUEST REQUEST RENEW REQUEST REBIND DISCOVER REPLY ACK/NAK DECLINE DECLINE 略。 DHCP 中继以上 DHCP 服务有一个前提条件，就是服务器要和客户端在同一个网段，因为广播无法跨过路由器。如果一个企业有上百个部门，对应上百个子网，要配置上百个 DHCP 服务器。配置麻烦不说，而且资源分配可能不均衡，很可能出现一个部门地址不够分，另一个却有很多空闲。 所以需要统一管理分配，可是如何跨越广播域呢？可以通过一个中继来帮助客户端和服务器发现彼此。 DHCP 中继代理当DHCP客户端与服务器不在同一个子网上，就必须有DHCP中继代理来转发DHCP请求和应答消息。DHCP中继代理的数据转发，与通常路由转发是不同的，通常的路由转发相对来说是透明传输的，设备一般不会修改IP包内容。而DHCP中继代理接收到DHCP消息后，进行转换源目的IP，MAC生成一个DHCP消息，然后转发出去。 在DHCP客户端看来，DHCP中继代理就像DHCP服务器；在DHCP服务器看来，DHCP中继代理就像DHCP客户端。 不需要在各个用户网关设备上启用DHCP server功能，而只要在网络中心安装一个 DHCP 服务器，就可以实现对多个网段的动态IP管理，统一维护，即Client—Relay—Server 模式的DHCP动态IP管理 当dhcp client 启动并进行dhcp 初始化时，它会在本地网络广播配置请求报文。 如果本地网络存在 dhcp server，则可以直接进行 dhcp 配置，不需要 dhcp relay。 如果本地网络没有 dhcp server，则与本地网络相连的具有 dhcprelay 功能的网络设备收到该广播报文后，将进行适当处理并转发给指定的其它网络上的 dhcp server。 dhcp server 根据 dhcp client 提供的信息进行相应的配置，并通过 dhcp relay 将配置信息发送给 dhcp client，完成对dhcp client 的动态配置。 无状态地址自动配置对于一个全球性的地址，这些地址的某一部分通常需要被管理，也就是通过 DHCP 动态分配的。但如果只是链路本地的地址，通常通过自动配置来获得，也就是主机自己决定自己的 IP 地址。称为无状态地址自动配置（SLAAC）。 IPv4 链路本地的动态配置当一个网络没有 DHCP 服务器和中继，主机不能获取 IP 地址，那么只能自己分配一个链路本地地址。IPv4 链路本地的范围是 168.254.0.1~168.254.254.254，使用子网掩码 255.255.0.0。 这种方法也叫自动专用 IP 寻址（Auto Private IP Addressing）。就是从特定范围随机选择一个地址，然后通过 GARP 检查是否有冲突。 链路本地 IPv6 的 SLAAC无状态地址自动配置（StateLess Address Auto Config，SLAAC）可用于无路由器环境，只分配链路本地地址。IPv6 的链路本地地址以 fe80::/10 为前缀，最后 N 位是一个接口 ID（IID），其余位为 0。IID 可以通过主机的 Mac 地址按照一定的规则来生成，也可以是一个随机数，基本可以保证局域网中的唯一性。 由于没有路由器，这个地址只能在子网内部使用，不可路由。 全球地址的 IPv6 SLAAC一个节点获得链路本地地址后，还可能需要一个或多个全球地址。全球地址的形成类似于链路本地地址，只不过前缀不再是 fe80::/10，而是由路由器给出的可以路由的前缀。 无状态 DHCP无状态 DHCP 模式下， DHCPv6 提供 IP 地址以外的其他信息。在分配 IP 地址时，需要维护 IP 地址的租用状态（见前面的 DHCP 状态机），如果不提供 IP 地址，那么也就不用维护状态，故称无状态 DHCP。 通常把 IPv6 全球地址 SLAAC 和无状态 DHCP 结合起来用。 相关攻击最大的漏洞就是如果有恶意主机，冒充正常主机，不断使用伪造的 Mac 地址来申请 IP 地址，那么 IP 地址资源很快用尽。可以采用授权的方式，使得合法的请求才能获取 IP 地址，同时限制未授权用户的数量，像链路层认证（如 WIFI 网络使用的 WPA2）就有助于限制未授权客户机的数量。]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go String 笔记]]></title>
    <url>%2Fgo-sdk%2Fgo_sdk_runtime_string.html</url>
    <content type="text"><![CDATA[Go String 笔记什么是 string ？标准库builtin的解释： 123type stringstring is the set of all strings of 8-bit bytes, conventionally but not necessarily representing UTF-8-encoded text. A string may be empty, but not nil. Values of string type are immutable. 简单的来说字符串是一系列 8 位字节的集合，通常但不一定代表 UTF-8 编码的文本。字符串可以为空，但不能为 nil。而且字符串的值是不能改变的。不同的语言字符串有不同的实现，在 go 的源码中 src/runtime/string.go，string 在底层的定义如下： 1234type stringStruct struct &#123; str unsafe.Pointer len int&#125; 可以看到 str 其实是个指针，指向某个数组的首地址，这个数组就是一个字节数组，里面存着 string 的真正内容。其实字节数组指针更像是 c 语言的字符串形式，而在 go 里，对其进行封装。不同的是， c 语言的 string 是以 null 或 /0 结尾，计算长度的时候对其遍历；而 go 的 string 结尾没有特殊符号，只不过用空间换时间，把长度存在了 len 字段里。 那么问题来了，我们平时用的 string 又是什么呢？它的定义如下： 1type string string 。。。好像和刚刚说的不太一样哈(-_-!)。这个 string 就是一个名叫 string 的类型，其实什么也不代表。只不过为了直观，使用的时候，把 stringStruct 转换成 string 类型。 12345func gostringnocopy(str *byte) string &#123; ss := stringStruct&#123;str: unsafe.Pointer(str), len: findnull(str)&#125; s := *(*string)(unsafe.Pointer(&amp;ss)) return s&#125; 为了验证，我们可以试一下： 123456789101112131415package mainimport ( "fmt" "unsafe")func main() &#123; var a = "nnnn" fmt.Println(a) var b = (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;a)) + 8)); // 按照 stringStruct 结构，把 a 地址偏移 int 的长度位，得到 len 字段地址 // 这里我的电脑是 64 位，而系统寻址以一个在节为单位，所以 +8 fmt.Println(*b) // 这里输出的是 a 的长度 4&#125; string 操作拼接我们可以用 + 来完成字符串的拼接，就像这样：s := x+y+z+… 底层如何实现的呢？ 123456789101112131415161718192021222324252627282930313233type tmpBuf [tmpStringBufSize]byte // 这是一个很重要的类型，tmpStringBufSize 为常量 32，但这个值并没有什么科学依据(-_-!)func concatstrings(buf *tmpBuf, a []string) string &#123;// 把所有要拼接的字符串放到 a 里面 idx := 0 l := 0 count := 0 for i, x := range a &#123; // 这里主要计算总共需要的长度，以便分配内存 n := len(x) if n == 0 &#123; continue &#125; if l+n &lt; l &#123; throw("string concatenation too long") &#125; l += n count++ idx = i &#125; if count == 0 &#123; return "" // 需要注意的是，虽然空字符串看起来不占空间，可是底层还是 stringStruct，仍要占两个 int 空间 &#125; if count == 1 &amp;&amp; (buf != nil || !stringDataOnStack(a[idx])) &#123; return a[idx] // count 为 1 表明不需要拼接，直接返回源 string，并且没有内存拷贝 &#125; s, b := rawstringtmp(buf, l) // 这里分配了一个长度为 l 字节的内存，这个内存并没有初始化 for _, x := range a &#123; copy(b, x) // 把每个字符串的内容复制到新的字节数组里面 b = b[len(x):] &#125; return s&#125; 可是这里有个问题，b 是一个字节切片，而 x 是字符串，为什么能直接复制呢？ 与切片的转换内置函数copy会有一种特殊情况copy(dst []byte, src string) int，但是两者并不能直接 copy，需要把 string 转换成 []byte。 1234567891011121314151617181920212223func stringtoslicebyte(buf *tmpBuf, s string) []byte &#123; var b []byte if buf != nil &amp;&amp; len(s) &lt;= len(buf) &#123; *buf = tmpBuf&#123;&#125; // 清零 b = buf[:len(s)] &#125; else &#123; b = rawbyteslice(len(s)) &#125; copy(b, s) return b&#125;// 申请新的内存，返回切片func rawbyteslice(size int) (b []byte) &#123; cap := roundupsize(uintptr(size)) // 使申请内存的大小为 8 的倍数 p := mallocgc(cap, nil, false) // 第三个参数为 FALSE 表示不用给分配的内存清零 if cap != uintptr(size) &#123; memclrNoHeapPointers(add(p, uintptr(size)), cap-uintptr(size)) // 超出需要的部分内存清零 &#125; *(*slice)(unsafe.Pointer(&amp;b)) = slice&#123;p, size, int(cap)&#125; return&#125; string 与内存string 字面量前面提到过，字符串的值是不能改变的，可是为什么呢？ 这里说的字符串通常指的是 字符串字面量，因为它的存储位置不在堆和栈上，通常 string 常量是编译器分配到只读段的(.rodata)，对应的数据地址不可修改。 不过等等，好像有什么不对？下面的代码为啥改了呢？ 12var str = "aaaa"str = "bbbb" 这是因为前面提到过的 stringStruct，我们拿到的 str 实际上是 stringStruct 转换成 string 的。常量aaaa被保存在了只读段，下面函数参数 str 就是这个常量的地址： 12345func gostringnocopy(str *byte) string &#123; ss := stringStruct&#123;str: unsafe.Pointer(str), len: findnull(str)&#125; s := *(*string)(unsafe.Pointer(&amp;ss)) return s&#125; 所以我们拿到的 str 本来是 stringStruct.str ，给 str 赋值相当于给 stringStruct.str 赋值，使其指向 bbbb所在地只读段地址，而 aaaa本身是没有改变的。在改变 stringStruct.str 的同时，解释器也会更新 stringStruct.len 的值。 动态 string所谓动态是指字符串 stringStruct.str 指向的地址不在只读段，而是指向由 malloc 动态分配的堆地址。尽管如此，直接修改 string 的内容还是非法的。要修改内容，可以先把 string 转成 []byte，不过这里会有一次内存拷贝，这点在转换的代码中可以看到。不过也可以做到 ‘零拷贝转换’： 123456789func stringtoslicebyte(s string) []byte &#123; sh := (*reflect.StringHeader)(unsafe.Pointer(&amp;s)) bh := reflect.SliceHeader&#123; Data: sh.Data, Len: sh.Len, Cap: sh.Len, &#125; return *(*[]byte)(unsafe.Pointer(&amp;bh))&#125; 不过这种方法不建议使用，因为一旦 string 指向的内存位于只读段，转换成 []byte 后对其进行写操作会引发系统的段错误。 临时 string有时候我们会把 []byte 转换成 string，通常也会发生一次内存拷贝，但有的时候我们只需要 ‘临时的’ 字符串，比如： 使用 m[string(k)] 来查找map 用作字符拼接： &quot;&lt;&quot;+string(b)+&quot;&gt;&quot; 用于比较： string(b)==”foo” 这些情况下我们都只是临时的使用一下一个 []byte 的字符串形式的值，如果分配内存有点不划算，所以编译器会做出一些优化，使用如下函数来转换： 12345678910111213func slicebytetostringtmp(b []byte) string &#123; if raceenabled &amp;&amp; len(b) &gt; 0 &#123; racereadrangepc(unsafe.Pointer(&amp;b[0]), uintptr(len(b)), getcallerpc(), funcPC(slicebytetostringtmp)) &#125; if msanenabled &amp;&amp; len(b) &gt; 0 &#123; msanread(unsafe.Pointer(&amp;b[0]), uintptr(len(b))) &#125; // 注意，以上两个 if 都为假，所以不会执行。不知道有什么用(-_-!) return *(*string)(unsafe.Pointer(&amp;b))&#125; 以上是读了 src/runtime/string.go 代码的一些个人想法，连蒙带猜，所以有些地方可能不太对，欢迎指出啦(^_^)！]]></content>
      <categories>
        <category>go sdk</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ARP 地址解析协议]]></title>
    <url>%2Fnetwork-protocol%2Farp.html</url>
    <content type="text"><![CDATA[ARP 协议 在网络通信中，主机和主机通信的数据包需要依据OSI模型从上到下进行数据封装，当数据封装完整后，再向外发出。所以在局域网的通信中，不仅需要源目IP地址的封装，也需要源目MAC的封装。上层应用程序更多关心IP地址而不关心MAC地址，所以需要通过ARP协议来获知目的主机的MAC地址 IP 协议使得报文可以跨越不同网络进行传输，当 IP 报文到达目标地址所在网络后，接下来要靠对方的 Mac 地址才能交付，这时候也要用到 ARP 地址解析协议。 ARP 原理请求与应答我在 Mac 上使用 ping 命令查询 192.168.0.105，由于不知道对方的 Mac 地址，所以先 ARP 请求。抓到的 ARP 请求报文如下： 不知道对方是否存在以及在哪里，所以向所在网段发送链路层广播请求，询问谁是 192.168.0.105 ，也就是目标 Mac 地址为 ff:ff:ff:ff:ff:ff，并且带上自己的 IP 和 Mac 信息。响应报文如下： IP 地址为 ARP 目标 IP 地址的主机收到后，由于知道这个请求是谁发出的，就以单播的形式返回一个响应报文，并且告诉对方自己的 Mac 地址。其他主机收到 ARP 请求会默认丢弃。 请求方收到响应后，即可把目标 Mac 地址封装到帧里然后发送数据。 ARP 缓存为了提高效率，每个主机维护了一个 ARP 缓存，维护着从网络层地址到硬件地址的最新映射，每条映射有一个到期时间，默认是 20min。 当收到多条 ARP 回应的时候，ARP 缓存按照”后到优先”原则，新的缓存直接覆盖旧的。 ARP 攻击攻击原理正常主机收到 ARP 请求，如果 目标 IP 不是自己，那么丢弃此报文。但当存在恶意节点时，则会造成 ARP 攻击： 恶意节点会发送大量的 ARP 响应，由于“后到覆盖”原则，几乎总是拿到错误数据。那么主机 A 会把发给主机 B 的数据都发送给 主机 C。同理，如果主机 B 要发送数据给主机 A，那么 C 也会冒充 A，就形成了 A &lt;=&gt; C &lt;=&gt; B 的情形，这就是典型的中间人攻击。 更严重的情况是，恶意节点冒充网关，拦截所有流量，这时候恶意节点可以直接使别的主机断连，当然很容易被发现，所以更多的时候实行限速。最严重的是，可能会盗取个人信息和密码。 防御 ARP 攻击 ARP防御可以在网络设备上实现，也可以在用户端实现，更可以在网络设备和用户端同时实现 网络设备防御先来了解下网络设备（例如这里的交换机）的防御技术，这种防御技术被称为DAI（Dynamic ARP Inspection）- 动态ARP检测，原理可以用两句话简单概括： 交换机记录每个接口对应的 IP 地址和 MAC，即 port&lt;=&gt;mac&lt;=&gt;ip，生成DAI检测表； 交换机检测每个接口发送过来的 ARP 回应包，根据 DAI 表判断是否违规，若违规则丢弃此数据包并对接口进行惩罚 如果判断出包是虚假的欺骗包，交换机马上丢弃这个包，并且可以对接口做惩罚（不同设备的惩罚方式有所不同，可以直接将接口”软关闭“，直接将攻击者断网；也可以”静默处理“，仅丢弃欺骗包，其他通信正常） 对于这个方案，有几点问题： 交换机可以查看 IP ？ 从现在的网络技术来看，分层界限越来越模糊，融合式的网络设备才是主流，现在的接入交换机基本能被Telnet/SSH/Web管理。不要被”交换机就是二层设备”给束缚了 如何生成 DAI 表 ？ 在交换机上开启DHCP侦听技术，当用户第一次通过DHCP获取到地址的时候，交换机就把用户电脑的IP、MAC、Port信息记录在DHCP侦听表，后面ARP检测直接调用这张DHCP侦听表即可 主机防御主机有两种方法防御： 安装 ARP 防火墙 静态绑定：静态绑定的信息比动态学习的优先级高 代理 ARP(PARP)在发送数据包时需要填写目标 Mac 地址，可是如果源主机和目标主机不在同一个网络会如何？如图，client 向 Server 发送请求，client 上配置了默认网关。 那么 client 上包的目标 Mac 填什么呢？很显然不可能知道 Server 的 Mac 地址： 路由器隔离广播域，每个接口/网段都是独立的广播域 ARP 请求是二层广播包，广播包没法过路由器 此时如果 client 上配置了默认网关，那么直接找到默认网关的 Mac 地址作为目标地址。 但如果没有默认网关，则采用代理 ARP。 代理 ARP 本质上是一种欺骗，原理和 ARP 攻击一样，冒充目标地址，不过目的是为了正常通信 在这种情况下，路由器上如果配置了代理 ARP，则会冒充目的地址。 总结如下： ①当电脑没有网关（采用代理ARP）时：”跨网段访问谁，就问谁的MAC” ②当电脑有网关（采用正常ARP）时：”跨网段访问谁，都问网关的MAC” ③无论哪种ARP，跨网段通信时，发送方请求得到的目标MAC地址都是网关MAC。 免费/无故 ARP(Gratuitous ARP)用于检测局域网内的IP地址冲突，在一定程度上能够给用户和网络运维人员提供帮助。相比『免费』这个翻译，『无故』这个词其实会更加好理解：”在没有人问自己的情况下，无缘无故自问自答“。 如下是我的电脑和隔壁老王的电脑一起设置了静态 IP 地址，都设成 192.168.0.108，抓到的包： 先看第四条，我的电脑设了静态 IP 后，广播发送无故 ARP，注意这里 tell 后面是 0.0.0.0，也就是说，不用告诉我谁是 192.168.0.108，只是我自己宣告，我就是 192.168.0.108。 再看第五条，这不是一个 ARP 响应，而是老王的电脑也在向外宣告，他自己是 192.168.0.108，可以看到下面详细信息里目标 Mac 地址是老王的(72结尾的)。我这里收到后，告诉他我才是 192.168.0.108。 然后两台机器就开始互怼，同一局域网的其他主机，则根据这两个免费 ARP 信息不断的修改本地 ARP 表。 之后老王把他的 IP 改回 DHCP（第二个红框），路由器(192.168.0.1)这里同时扮演了 DHCP 的分配者，它向外询问是否有人占用了 192.168.0.104 这个地址，没有收到回应，于是分配给老王这个地址。分配了地址后，老王还是要向外宣告他自己的身份，使得同局域网的主机刷新 ARP 缓存，同时检测是否还有地址冲突。 第三个红框是老王关闭 WIFI 又重启。 总结一下讨论了三种 ARP： ARP：通过 IP 地址找到 Mac 地址 PARP：在没有网关的时候辅助通信 GARP：解决地址冲突的问题 其实还有 RARP(Reverse ARP) 和 IARP(Inverse ARP)，不过使用极少，就不再赘述。]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP(II) 协议]]></title>
    <url>%2Fnetwork-protocol%2Finternet_protocol.html</url>
    <content type="text"><![CDATA[Internet 协议 IP 是 TCP/IP 的核心协议，它提供的是尽力而为的服务。 IPv4 头部 简单介绍一下一些字段： IHL ，initial header length。表示 IP 首部 长度。占 4 位，最大值为 15，单位是 32 位，也就是最大长度为 15 * 4 字节 = 60 字节 ToS，type of service。这个字段使用很少，于是被分为两个部分，前六位 DS，后两位位 ECN DS，distinguish service，服务区分。用于描述 IP 服务的类型，通常为 000000 ，表示尽力而为的服务。这个域极少使用 ECN，explicit congestion notification，显式拥塞提醒。这个字段用于在路由器由于拥塞丢弃数据时，显式的告知 TCP 发送方链路拥塞，以减缓发送速率 第二行是关于 IP 分片的。16 位的标识区别了属于不同源报文的分片，后面三位标识分别表示 当前报文是否为一个分片，1 表示是一个分片 是否允许分片，默认为 0，可以分片。如果需要分配，但是改标识位为 1，那么路由器丢弃该包 是否有更多分片，0 表示没有 13 位的分片偏移表示当前分片在源数据中的位置，由于只有 13 位，但可能表示 16 位的数据，所以这里单位为 8 字节。如果当前包不是一个分片，则全为 0。 TTL，time to live，最开始表示 IP 包生存时间，现在表示剩余路由跳数，每经过一个路由，该值减一，若跳数为 0，那么路由器丢弃该包，并由 ICMP 告知发送方。这样可以防止包在路由环路中无限循环 协议字段，表示 IP 数据段有效荷载的数据类型。通常是传输层协议，17（UDP），6（TCP），但也可能表示其他协议，4（ipv4 in ipv4） 校验和，仅计算头部，由于每经过一个路由器 TTL 值减一，所以造成校验和字段重新计算 IP 选项，多数选项很少或从未使用，并且通常会在企业网络边界被防火墙拒绝或剥离，所以略过 IPv6 头部 IPv6 的头部精简了许多，版本、DS 和 ECN、跳数限制 都和 IPv4头部一个意思。 流标签本身也是一个比较复杂的话题，该字段用于某些对连接的服务质量有特殊要求的通信，诸如音频 或视频等实时数据传输。在IPv6中，同一信源和信宿之间可以有多种不同的数据流，彼此之间以非“0”流标记区分。如果不要求路由器做特殊处理，则该字段 值置为“0”。详见这里。 负载长度表示数据段长度，包括扩展头部，最大 65535 个字节，超过这一字节数的负载，该字段 值置为“0”。不过 IPv6 支持超长数据报选项，单个分组最大可支持 4GB 下一个头部，8位。IPv6 通过增加扩展头部来实现一些想 IPv4 选项提供的特殊功能，这个字段说明紧跟着的下一个头部类型 IPv6 扩展头部IPv6 头部固定为 40 字节，扩展头部只在需要时添加，并且要求仅由终端主机处理（有一个例外）。扩展头部也可以是上层的协议如 TCP、UDP 也可以是多个头部级联起来: 需要注意的是，每种类型的扩展头部必须按照固定的顺序排列： 这其中 hop-by-hop 和 destination 比较特殊，称为选项头部。 hop-by-hop 逐跳选项可以出现多次，destination 目的地选项可以出现两次（传输过程的 IP 地址和最终 IP 地址），别的头部只能出现一次。 IPv6 选项选项头部有固定的格式，被编码为 类型-长度-值（TLV）集合： 其中动作表示如果路由器不识别这个选项，应该做的操作： 值 动作 00 跳过该选项，处理下一个选项或头部 01 丢弃该数据包 10 丢弃该数据包，并向源地址发送 ICMPv6参数问题 消息 11 与 10 相同，但仅当目的地址不是组播地址时才这样 有如下常用的选项： 超大有效负荷：可以携带有效荷载为 64KB ~ 4GB 的数据包。用此选项时，IPv6负载长度字段被置为 0。属于逐跳选项 隧道封装限制：隧封指把一个 IP 数据包封装在另一个 IP 报文的有效荷载部分。这个选项指明了封装的最大层数。属于‘目的地选项’ 家乡地址：使用移动 IP 时，这个选项保存家乡地址的值。属于目的地选项 分片头部如果数据包大小超过下一跳的 MTU，那么任何主机和路由器可以将数据包分片（和 IPv4 不同的是，IPv4 有一个位用于说明是否能分片，但是 IPv6 没有）。分片头部如下，占 8 字节： 其中保留 8 位和 Res 2位都为全 0，目前都被接收方忽略。M，more，表示是否还有更多分片。分片偏移和 IPv4 一样，都为 13 位，并且都是以 8 字节位单位。 对于分片过程来说，一个数据包有两个部分，一个是“不可分片部分”，包括路由头部之前的所有头部，剩下的部分是“可分片部分”。不可分片部分在每个分片中都有一个副本。分片完成后要修改 IPv6 基本头部中的负载长度字段。 IP 转发大多数主机即可以配置位路由器，也可以配置为主机，前者会转发不是由它自己生成的数据包，后者不会。IP 层包括一些位于内存的信息，通常称为路由表。路由表包含的信息类似于如下示例： 目的地 掩码 网关（下一跳） 接口 0.0.0.0 0.0.0.0 10.0.0.1 10.0.0.100 10.0.0.0 255.255.255.128 10.0.0.100 10.0.0.100 转发行为主机或路由器转发一条数据报时，使用报文中的目的 IP 地址 D 来执行最长前缀匹配算法： di = D^Mi，Mi 表示第 i 条路由表的掩码，把 di 和 ai (第 i 条路由表的目的地址)相比较，若 di 满足 ai，那么 ai 和 D 相“匹配” 找到所有“匹配”的条目，选择其中掩码 1 的个数最多的一条，将其下一跳字段的值作为转发的 IP 地址 如果没有找到匹配的条目，那么 ICMP 返回一个“主机不可达”错误 直接交付每个主机里也有自己缓存的路由表，当发送主机和目的主机在同一子网内，主机的路由表包含目的主机，那么不需要经过路由器，直接经过交换机就能到达目的地，并不关心 IP 地址。不过要提前知道对方的 Mac 地址，可以用 ARP 请求或者 IPv6 的邻居请求来获取。 间接交付当源主机自己的路由表没有目的主机的信息，那么使用自己的默认路由条目，局域网内通常是 10.0.0.1，这通常是网关的地址，然后由路由器为我们转发到目的地。在每一跳的过程中，IP 地址可能不变，但底层的 Mac 地址一直在变，它是更新为下一跳的 IP 地址所对应的 Mac 地址。 traceroute 原理traceroute 命令会输出 IP 包经过的每一个路由节点的 IP 地址信息，那么它是如何做到的呢？ 还记得前面提到的 TTL 字段吗，当它减为 0 时，该包会被丢弃，并且由 ICMP 向源主机发送 “TTL 过期”错误。traceroute 利用这个特性，分别发送 TTL 为 1，2，3…的 IP 包，也就是说，在经过链路上的第一、二、三… 个节点时，都会由 ICMP 发送回来一个错误信息，这样就得知每个节点信息了。 那么如何判断已经到达目的地呢？事实上，traceroute 默认发送 UDP 报文，并且目标端口通常是选择对方没有开启的端口，这样在报文到达目的地后，对方返回一个 “端口不可达”错误。 由于是 UDP 报文，可能会丢失，所以每个 TTL 值发送三个报文： 移动 IP许多 Internet 协议都要求节点的 IP 地址保持不变。如果其中的任一协议在移动设备上处于活动状态，并且其 IP 地址改变了，则应用该协议将失败。 如果移动计算机（即移动节点）移到新网络后其 IP 地址保持不变，则移动节点的地址不会反映新连接点。因此，所存在的路由协议无法将数据报正确路由到该移动节点。 移动 IP 通过允许移动节点使用两个 IP 地址，可以解决上述问题。第一个地址是家乡地址，它是固定的。第二个地址是转交地址，它在每个新连接点都会发生变化。移动 IP 允许计算机在 Internet 上自由漫游。另外，它还允许计算机在组织的网络上自由漫游，同时仍保持其家乡地址不变。因此，当用户更改计算机的连接点时，通信活动不会中断。 通过使用该图中的移动 IP 拓扑，以下情形说明了数据报是如何在移动 IP 框架的不同点之间移动的。 Internet 主机使用移动节点的家乡地址向移动节点发送数据报（此为标准的 IP 路由过程）。 如果移动节点位于家乡网络，则数据报会通过常规 IP 进程传送到移动节点。否则，数据报将传送到家乡代理。 如果移动节点位于外地网络，则家乡代理将数据报转发到外地代理。家乡代理必须将数据报封装到外部数据报中，以便外地代理的 IP 地址出现在外部 IP 数据包头。 外地代理将数据报传送到移动节点。 数据报通过使用标准的 IP 路由过程从移动节点发送到 Internet 主机。如果移动节点位于外地网络上，则包会传送到外地代理。外地代理随后会将数据报转发到 Internet 主机。 如果存在入口过滤 (ingress filtering)，则发送数据报的子网的源地址在拓扑结构上必须正确，否则路由器无法转发数据报。如果移动节点和通信节点之间的链路上存在这种情况，则外地代理需要提供反向隧道连接支持。然后，外地代理即可将移动节点所发送的每个数据报传送到其家乡代理。家乡代理随后将转发数据报，所使用的路径即是移动节点驻留在家乡网络的情况下数据报应采用的路径。此过程保证数据报必须遍历的所有链路的源地址均正确。 步骤中的数据报封装指的是隧道，IP-over-IP 更多原理参考这里 IP 数据报的主机处理主机模式当主机有两个 IP 地址时，在主机接收到数据包时，可能会出现一些问题。有两种处理策略，分别是强主机模式和弱主机模式 强主机模式中，只有当收到的包的目的 IP 地址与该报文到达的接口所配置的 IP 地址相同时，才把数据交付给本地协议栈。 而弱主机模式则不然，只要接收到的包的目的 IP 地址与主机的任何本地地址相匹配，那么不论到达哪个接口，都交付给本地协议栈处理。 如，在强主机模式下，主机 A 从交换机收到 目的地址为 192.0.2.1 的数据包，那么丢弃它。而弱主机模式下，会接收它。 地址选择当主机有多个 IP 地址，发送数据时，需要填写自己的 IP 地址，那么如何从多个 IP 地址中选择呢？特别是当一个主机有 IPv4 和 IPv6 地址时，地址选择失败可能导致非对称路由、不必要的分组。 默认规则是 优先在相同范围内选择成对的源/目的地址 优先选择更小的范围以避免其他地址可用时使用临时地址 优先选择具有更长公共前缀的成对地址]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP(I) 地址]]></title>
    <url>%2Fnetwork-protocol%2Fip_addr.html</url>
    <content type="text"><![CDATA[IP 地址结构 Internet 中使用的网络层地址，又叫 IP 地址。每一个连接到 Internet 的设备至少有一个 IP 地址。IP 地址标志了流量的来源和去向。 IP 地址的表示IPv4IPv4 地址本质上是 32 位二进制整数，通常用点分十进制表示: 点分十进制 二进制 0.0.0.0 00000000 00000000 00000000 00000000 1.2.3.4 00000001 00000010 00000011 00000100 IPv6ipv6 地址长度为 128 位，被分为 8 个块表示，每个块包含 4 个十六进制数，块之间用 : 分隔。另外有一些规则: 一个块中的前到 0 可以省略 全块的 0 可以用 :: 代替。如：0:0:0:0:0:0:0:1 可以写成 ::1。另外 :: 只能使用一次，并且只能在 0 最多的地方用，如果有两个一样多连续 0 的地方，前者可以使用 :: 在 ipv6 中嵌入 ipv4 地址可以使用混合符号形式。::ffff:10.0.0.1 可以表示 ipv4 地址 10.0.0.1。其中 ipv4地址紧邻 ffff，这被称为 ipv4 映射的 ipv6 地址 ipv6 地址低 32 位通常采用点分十进制，这被称为 兼容 ipv4 的 ipv6 地址 当 ipv6 地址和端口号一起使用时，: 可能造成歧义，所以用 [] 括起来：http://[::3333:22]:443/ 基本的 IP 地址结构IP 地址的分类IP 地址中，被用于识别连接 Internet 或某些专用的内联网的计算机网络接口的地址，叫做单播地址，还有涉及多个接口或者有特殊用途的地址，包括广播、组播、多播地址。 分类寻址单播 IP 地址都有一个网络部分和一个主机部分，分别被用来识别网络和网络中的主机。IP 地址呗分为如下五大类： 更形象一点如图： 但是要注意的是，每个网络里的主机号，全 0 和全 1 的不能被分配给某个主机。全 1 的作为这个子网的广播地址使用。 子网寻址A 类地址的主机数量为 2^24 - 2，B 类地址的主机数量为 2^16 - 2，C 类地址为 2^8 - 2。实际上很难分配到一个大小合适的网络，于是在分类基础上加了子网的概念。 如图，把一个 B 类地址的主机号 ‘借’ 出 8 位作为子网号的例子，这样把一个网络划分出来若干子网，以此来得到一个合适大小的网络。 子网掩码为了能够从 IP 地址中知道主机号中哪些是子网号，哪些是主机号，使用了一个 32 位二进制的子网掩码。它的每一位和 IP 地址一一对应，子网掩码某一位为 1 代表对应 IP 地址那一位不是主机号。 写的时候为了简单，把 IP 地址和子网掩码 1 的位数写在一起，如：128.3.4.5/23。 要注意，只有划分子网内部路由器和主机知道子网结构，在需要子网寻址之前，互联网其他部分仍把它作为站点相关的地址来看。来看一个例子： 可变长度子网掩码Variable Length Subnet Mask, VLSM。在同一站点的不同部分，可以将不同长度的子网掩码应用于相同网络号。增加了配置的复杂性但是也提高了子网结构的灵活性。如图，三个不同掩码被用于 128.32.0.0/16 ，每个子网可以有不同数量的主机： CIDR 和聚合划分子网缓解了增长带来的痛苦，但是随着互联网规模增长，路由表的条目数越来越多，路由性能受到影响。 前缀为了缓解 v4 地址的压力，分类寻址采用了类似于 VLSM 的方案，无类别域间路由（Classless Inter-Domain Router, CIDR）。使用 CIDR，任何没有预定义的地址都可以作为同一个类的一部分，就是说，B 类地址和 C 类地址可以在同一个类。 注意，和普通子网掩码不同的是，CIDR 的掩码不仅限于一个站点，而是全球路由可见的。核心 Internet 路由器必须能够解释和处理 CIDR 掩码。 IP 地址加上一个 0~32 的数字，称为前缀，代表一个子网。 前缀 地址范围 0.0.0.0/0 0.0.0.0 ~ 255.255.255.255 128.0.0.0/1 128.0.0.0 ~ 255.255.255.255 128.0.0.0/24 128.0.0.0 ~ 128.0.0.255 聚合前缀并没有解决路由表性能问题，但是可以把多条路由聚合成一条，以此减轻路由器压力。把网络拓扑排成一棵树，按照分层结构的思想来分配地址，可以在保证最短路由的情况下减少路由器路由条目。 下图是一个随意排布的、路由与位置无关的结构（a, 左图）和拓扑敏感的、位置与路由相关的结构（b, 右图），每个圆点代表路由器： 两者最大的区别在于，a 中顶层路由节点为了能够路由到下面 8 个节点，需要储存 9 条（加上 other Parts 那一条）路由信息；而 b 中顶层节点只需要存储 3 条（同上）。 关键在于，b 把多条路由信息聚合成一条。聚合是把多个相邻的 IP 前缀合并成一个短前缀。 注意，只有连续的、数值相邻的地址才能被聚合，如果中间有一条地址不在此列，那么不能聚合。 特殊用途地址IPv4 和 IPv6 转换IPv4 和 IPv6 转换时，采用特殊地址，称为嵌入 IPv4 的 IPv6 地址，如下，IPv6 前缀必须是以下之一： 其中，63~71 对应的 U 必须为 0。 组播地址。。。 我不会 。。。 没看懂 。。。 。。。 以后再写吧 地址分配IP 地址被分配为较大的块，由一些权威组织负责。这些权威机构给一些小型机构或者大型 ISP (Internet Service Provider) 分配 IP 地址。用户通常以地址前缀形式使用 ISP 地址空间，这些地址范围由 ISP 管理，被称为供应商聚合地址（PA），可以和 ISP 的其他地址前缀聚合。但同时，这些地址是不可移植的。 另一种可选的地址空间类型称为供应商独立（PI）的地址空间，这些地址可以直接分配给用户，并且任何 ISP 都可以使用，但是通常和 ISP 的地址数值不相邻，所以不能聚合。 下面看一下一个站点分配了单播地址后的一些可能的场景 单供应商/无网络/单个地址这种情况最简单，ISP 分配了一个 IP 地址，然后通过网线连接到一台主机，这里没有形成网络。但这太主机还有其他的 IP 地址，包括本地环回的 127.0.0.1 或者 ::1 ####单供应商/单个网络/单个地址 这种场景大多是家庭局域网（LAN）或无线局域网（WLAN），由一台路由器连接 Internet。虽然每个连接到路由器的设备都被分配到一个 IP 地址，但是都是私有的，由 NAT 做转换，对于 ISP 来看，仍然只有一个地址。 单供应商/多个网络/多个地址对应组织或者小型公司来说，一个 IP 地址，特别是当它只是临时分配的不固定的地址时，是不满足需求的。 图中 DMZ 表示非军事区，在主防火墙之外，拥有公网地址，可以被互联网连接。 ####多供应商/多个网络/多个地址 对于一些大型企业，通常使用多个 ISP 以便在失效时提供冗余连接。通常来说，只有一个 ISP 的组织拥有该 ISP 关联的 PA 地址。多个 ISP 的组织，可能有多个不能互相聚合的 PA 地址，或者 PA 地址 + PI 地址。这里讨论一下 PA + PI 的场景。 这里 C、D 相当于两个站点边界路由器，分别拥有一个 PA 地址和一个 PI 地址。 如果站点使用 PA 地址空间，那么 ISP P1 可以聚合该地址，而 P2 不能。本质上 P1 和 P2 都可以到达 12.46.129.1，但从互联网其他部分过来的流量偏向于经过 P2，因为 P2 的路由路径更长，路由器采用最长匹配前缀来计算路由。 如果站点采用 PI 地址空间，则相对公平，因为 P1 和 P2 都无法聚合路由。]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go http server (III)]]></title>
    <url>%2Funcategorized%2Fgo_http_server_3.html</url>
    <content type="text"><![CDATA[GO http server (III) 组建简易 HTTP Server 框架 上篇提到 DefaultServerMux 作为默认的 HTTP Server 框架太过简单，缺少很多功能。这篇我们利用官方库和一些三方库来定制一个简易合用的 HTTP Server 框架。完整代码见这里 Router首先要有 router 模块，这里我使用第三方 gorilla 框架的最小化路由模块 mux，它的作用和 DefaultServerMux 差不多，只不过支持了 RESTful API。 在添加路由和对应 handler 时，很可能我们写的处理函数有 bug，导致没有往 response 里写入内容就返回，这会造成客户端阻塞等待，所以当出现错误提前返回时，需要一个默认的错误处理函数，给客户端返回默认错误信息。 12345678910import ( "net/http" "github.com/gorilla/mux")type Router struct &#123; router *mux.Router ctxPool sync.Pool errHandler func(w http.responseWriter, r *http.request) &#125; 很多时候，执行路由对应 handler 时我们并不想直接操作 http.responseWriter 和 *http.request，并且希望有一些简单的封装，提供更多的功能。再者，这两个对象并不能很好的携带中间件处理过程中产生的一些参数。所以我们会定义一个 Context （下一节）来封装它们。每一个请求都应该有一个 Context，为了方便的管理，使用 sync.Pool 做一个 context 池。 创建新的 Router： 12345678910111213141516// NewRouter returns a router.func NewRouter() *Router &#123; r := &amp;Router&#123; router: mux.NewRouter(), errHandler: func(_ *Context) &#123;&#125;, &#125; r.ctxPool.New = func() interface&#123;&#125; &#123; return NewContext(nil, nil) &#125; r.router.NotFoundHandler = http.NotFoundHandler() r.router.MethodNotAllowedHandler = MethodNotAllowedHandler() return r&#125; router 注册路由，由于使用 gorilla.mux，调用其 HandleFunc ，返回 router 本身，在调用 Method 即可指定请求方法。不过我们还可以在自己的 handler 执行之前，提供一些钩子，这里我们可以添加一些 filter 函数，以便功能扩展。 123456789101112131415161718192021222324252627282930313233type FilterFunc func(*Context) boolfunc (rt *Router) Get(pattern string, handler HandlerFunc, filters ...FilterFunc) &#123; rt.router.HandleFunc(pattern, rt.wrapHandlerFunc(handler, filters...)).Methods("GET")&#125;// Post adds a route path access via POST method.func (rt *Router) Post(pattern string, handler HandlerFunc, filters ...FilterFunc) &#123; rt.router.HandleFunc(pattern, rt.wrapHandlerFunc(handler, filters...)).Methods("POST")&#125;// Wraps a HandlerFunc to a http.HandlerFunc.func (rt *Router) wrapHandlerFunc(f HandlerFunc, filters ...FilterFunc) http.HandlerFunc &#123; return func(w http.ResponseWriter, r *http.Request) &#123; c := rt.ctxPool.Get().(*Context) defer rt.ctxPool.Put(c) c.Reset(w, r) if len(filters) &gt; 0 &#123; for _, filter := range filters &#123; if passed := filter(c); !passed &#123; c.LastError = errFilterNotPassed return &#125; &#125; &#125; if err := f(c); err != nil &#123; c.LastError = err rt.errHandler(c) &#125; &#125;&#125; Context前面提到可以用一个 Context 包装 http.responseWriter 和 *http.request，并且提供一些额外的功能。额外的功能如 validator，用来对请求做参数验证。这个 validator 我们可以直接用一个第三方库，也可以做成 Interface 以便升级。 另外我们可能需要 Context 能够携带额外的信息，所以可以加一个 map 用来存储。 123456type Context struct &#123; responseWriter http.ResponseWriter request *http.Request Validator *validator.Validate store map[string]interface&#123;&#125;&#125; 不要忘了在 Router 里面我们是用一个线程安全的池来管理 context ，也就是每次用完 context 需要还回去来避免临时分配带来的开销。所以别忘了还回去之前需要把 context 重置成原来的样子。 12345func (c *Context) Reset(w http.ResponseWriter, r *http.Request) &#123; c.responseWriter = w c.request = r c.store = make(map[string]interface&#123;&#125;)&#125; Server有了 router 和 context，我们还需要封装一个 server。首先定义一个 EntryPoiont 结构体，当然名字随意。非常确认的是我们需要用到 http 包的 Server，还可以加上可能用到的 net.Listener。另外，我们需要方便的添加一些即插即用的工具，所以需要中间件，这里我使用第三方库 negroni 。然后我们可能需要一个通知关闭所有连接的机制，用一个 channel 可以做到。所以 EntryPoint 大致如下： 12345type Entrypoint struct &#123; server *http.Server listener net.Listener middlewares []negroni.Handler&#125; negroni其实 negroni 的核心代码也很简单，就只是把多个 middleware 串起来使其能够串行调用。 12345678910111213type Negroni struct &#123; middleware middleware handlers []Handler&#125;type middleware struct &#123; handler Handler next *middleware&#125;type Handler interface &#123; ServeHTTP(rw http.ResponseWriter, r *http.Request, next http.HandlerFunc)&#125; 关键就是 Handler 接口，所有第三方实现的中间件要和 negroni 一起用的话，都要实现它，并且每个中间件执行完自己的功能后，要去调用 next 触发下一个中间件的执行。 添加中间件： 12345678910111213141516171819202122func (n *Negroni) Use(handler Handler) &#123; if handler == nil &#123; panic("handler cannot be nil") &#125; n.handlers = append(n.handlers, handler) n.middleware = build(n.handlers)&#125;func build(handlers []Handler) middleware &#123; var next middleware if len(handlers) == 0 &#123; return voidMiddleware() &#125; else if len(handlers) &gt; 1 &#123; next = build(handlers[1:]) &#125; else &#123; next = voidMiddleware() &#125; return middleware&#123;handlers[0], &amp;next&#125;&#125; 添加中间件的时候，递归地调用 build ，把所有 middlewares 串起来。必然的，negroni 实现了 http.Handler 接口，这使得 Negroni 可以当做 http.Handler 传给 Server.Serve() 1234567func (n *Negroni) ServeHTTP(rw http.ResponseWriter, r *http.Request) &#123; n.middleware.ServeHTTP(NewResponseWriter(rw), r)&#125;func (m middleware) ServeHTTP(rw http.ResponseWriter, r *http.Request) &#123; m.handler.ServeHTTP(rw, r, m.next.ServeHTTP)&#125; 整合 router当所有中间件执行完了以后，应该把 context 传给 router 去执行对应的路由，所以把 router 作为最后一个中间件传到 negroni 。 1234567891011func (ep *Entrypoint) buildRouter(router http.Handler) http.Handler &#123; n := negroni.New() for _, mw := range ep.middlewares &#123; n.Use(mw) &#125; n.Use(negroni.Wrap(http.HandlerFunc(router.ServeHTTP))) return n&#125; 当然在启动 Server.Serve() 之前，还要把 ep.buildRouter 返回的对象赋给 ep.Server.Handler，使这个对象代替 DefaultServerMux。 12345678910111213141516171819func (ep *Entrypoint) prepare(router http.Handler) error &#123; var ( err error listener net.Listener ） listener, err = net.Listen("tcp", ep.configuration.Address) if err != nil &#123; return err &#125; ep.listener = listener ep.server = &amp;http.Server&#123; Addr: ep.configuration.Address, Handler: ep.buildRouter(router), &#125; return nil&#125; 接下来就可以调用 start 跑起服务： 123456789101112131415func (ep *Entrypoint) Start(router http.Handler) error &#123; if router == nil &#123; return errNoRouter &#125; if err := ep.prepare(router); err != nil &#123; return err &#125; go ep.startServer() fmt.Println("Serving on:", ep.configuration.Address) return nil&#125; 中间件封装有的时候有一些现成的中间件，但是不能直接放到 negroni 里面用，就需要我们给它加一层封装。 例如，我们要做 jwt 验证，使用第三方的 jwtmiddleware.JWTMiddleware，但是有的路径我们不需要 token，需要跳过 jwt 中间件。不方便改别人的代码，可以这样封装来代替原来的 jwtmiddleware.JWTMiddleware： 1234567type Skipper func(path string) bool// JWTMiddleware is a wrapper of go-jwt-middleware, but added a skipper func on it.type JWTMiddleware struct &#123; *jwtmiddleware.JWTMiddleware skipper Skipper&#125; 使用 jwtmiddleware.JWTMiddleware 作为一个匿名变量，这样可以在自定义的 JWTMiddleware 上直接调用 jwtmiddleware.JWTMiddleware 的函数。然后用 handler 函数覆盖原有的 HandlerWithNext 函数，这样就能通过调用时传入的 skipper 函数判断是否需要跳过 jwt： 123456789func (jm *JWTMiddleware) handler(w http.ResponseWriter, r *http.Request, next http.HandlerFunc) &#123; path := r.URL.Path if skip := jm.skipper(path); skip &#123; next(w, r) return &#125; jm.HandlerWithNext(w, r, next)&#125; 最后用 negroni 包装一下，使它能够直接被 negroni 使用： 1234567891011121314151617181920212223func NegroniJwtHandler(key string, skipper Skipper, signMethod *jwt.SigningMethodHMAC, errHandler func(w http.ResponseWriter, r *http.Request, err string)) negroni.Handler &#123; if signMethod == nil &#123; signMethod = jwt.SigningMethodHS256 &#125; jm := jwtmiddleware.New(jwtmiddleware.Options&#123; ValidationKeyGetter: func(token *jwt.Token) (interface&#123;&#125;, error) &#123; return []byte(key), nil &#125;, SigningMethod: signMethod, ErrorHandler: errHandler, &#125;) if skipper == nil &#123; skipper = defaulSkiper &#125; JM := JWTMiddleware&#123; jm, skipper, &#125; return negroni.HandlerFunc(JM.handler)&#125; 总结目前为止我们实现了一个简易通用的 HTTP server 框架，虽然功能还不是很完善，不过好在可扩展性比较高，我们可以在此基础上任意扩展，可以添加上缓存、数据库、监控等等模块。 如果有兴趣的话，可以去看看 echo 的实现，其实也是大同小异。 最后，再放一遍项目地址，还有一些别的库，欢迎 star 和 pr 啦！]]></content>
  </entry>
  <entry>
    <title><![CDATA[Go http server (II)]]></title>
    <url>%2Funcategorized%2Fgo_http_server_2.html</url>
    <content type="text"><![CDATA[GO http server (II) Server.Handler 上一篇里讨论了 go 官方库里提供的 http 服务框架，使用者需要关心的是 Server 的 handler 域。当 Server 调用 Serve 函数时 Server.Handler 为 nil，则默认使用 http.DefaultServeMux 作为 handler。 DefaultServeMux来看一下它的定义和描述： 1234// ServeMux is an HTTP request multiplexer.// It matches the URL of each incoming request against a list of registered// patterns and calls the handler for the pattern that// most closely matches the URL. 简单的说，它就是一个路由分发器。 路由注册123456789101112131415type ServeMux struct &#123; mu sync.RWMutex m map[string]muxEntry //路由规则，一个string对应一个mux实例对象，map的key就是注册的路由表达式(string类型的) hosts bool // whether any patterns contain hostnames&#125;var defaultServeMux ServeMuxvar DefaultServeMux = &amp;defaultServeMuxtype muxEntry struct &#123; // 代表着一个 路由-处理函数 组合 explicit bool //表示 patern 是否已经被明确注册过了 h Handler pattern string //路由表达式&#125; 之前提到过，Server.Handler 需要有路由功能，并且可以执行路由对应的处理函数。当注册路由时，调用mux.Handle: 123456789101112131415161718192021222324252627282930313233343536373839func (mux *ServeMux) Handle(pattern string, handler Handler) &#123; mux.mu.Lock() defer mux.mu.Unlock() if pattern == "" &#123; panic("http: invalid pattern " + pattern) &#125; if handler == nil &#123; panic("http: nil handler") &#125; if mux.m[pattern].explicit &#123; panic("http: multiple registrations for " + pattern) &#125; if mux.m == nil &#123; mux.m = make(map[string]muxEntry) &#125; mux.m[pattern] = muxEntry&#123;explicit: true, h: handler, pattern: pattern&#125; if pattern[0] != '/' &#123; mux.hosts = true &#125; // 以下是很有用的功能:当pattern == “/tree/”时, // 会插入一条永久的重定向到“/tree”,注意最后的斜杠。 // 当然前提是在这之前没有“/tree”这条路由 n := len(pattern) if n &gt; 0 &amp;&amp; pattern[n-1] == '/' &amp;&amp; !mux.m[pattern[0:n-1]].explicit &#123; //如果包含host， path := pattern if pattern[0] != '/' &#123; // In pattern, at least the last character is a '/', so // strings.Index can't be -1. path = pattern[strings.Index(pattern, "/"):] &#125; url := &amp;url.URL&#123;Path: path&#125; mux.m[pattern[0:n-1]] = muxEntry&#123;h: RedirectHandler(url.String(), StatusMovedPermanently), pattern: pattern&#125; &#125;&#125; 代码挺多，其实主要就做了一件事，向DefaultServeMux的map[string]muxEntry中增加对应的路由规则和handler。注意这里每条路由并没有包含我们常说的 GET、POST 等等区别，主要有两个原因：一是为了简洁，很多开发者偏好不同的处理方法，官方库只提供最基本的功能；二是不直接和请求方法绑定起来便于写 RESTful API。 但是这里还要注意路径结尾的/,这时候该路径为一个子树，如果能完全匹配到其子路由，那么也能匹配到这个子树，不过路由越长，优先级越大；如果不能完全匹配到其子路由，会匹配到这个子树的路由。比如有一个根路由/、/example/和 /example/1，那么访问/example/2时，会匹配到/example/，访问/nothing会匹配到/。 处理路由请求注册好路由，并且没有使用别的 handler 时，DefaultServerMux 的 ServeHTTP 就会在接收到 request 时被调用。 12345678910func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) &#123; handler := sh.srv.Handler if handler == nil &#123; handler = DefaultServeMux &#125; if req.RequestURI == "*" &amp;&amp; req.Method == "OPTIONS" &#123; handler = globalOptionsHandler&#123;&#125; &#125; handler.ServeHTTP(rw, req)&#125; ServeHTTP 主要从之前注册好的路由表中获取对应的 handler： 12345678910111213141516171819202122232425262728293031323334353637func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) &#123; ... h, _ := mux.Handler(r) // 匹配和 request 最接近的路由，拿到对应的 handler h.ServeHTTP(w, r)&#125;func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) &#123; ... host := stripHostPort(r.Host) path := cleanPath(r.URL.Path) if path != r.URL.Path &#123; _, pattern = mux.handler(host, path) url := *r.URL url.Path = path return RedirectHandler(url.String(), StatusMovedPermanently), pattern //注意这里的重定向 handler &#125; return mux.handler(host, r.URL.Path)&#125;func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) &#123; mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones if mux.hosts &#123; h, pattern = mux.match(host + path) &#125; if h == nil &#123; h, pattern = mux.match(path) // match 做的是字符串匹配的工作 &#125; if h == nil &#123; h, pattern = NotFoundHandler(), "" &#125; return&#125; 在没有找到匹配的路由时，返回 NotFoundHandler， 默认只是写入 404 not found，但通常我们会自定义它，然后返回一个专门的好看的 404 页面。 如果需要重定向，则会通过返回的 redirectHandler 调用 Redirect： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func Redirect(w ResponseWriter, r *Request, url string, code int) &#123; if u, err := parseURL(url); err == nil &#123; // If url was relative, make absolute by // combining with request path. // The browser would probably do this for us, // but doing it ourselves is more reliable. // NOTE(rsc): RFC 2616 says that the Location // line must be an absolute URI, like // "http://www.google.com/redirect/", // not a path like "/redirect/". // Unfortunately, we don't know what to // put in the host name section to get the // client to connect to us again, so we can't // know the right absolute URI to send back. // Because of this problem, no one pays attention // to the RFC; they all send back just a new path. // So do we. if u.Scheme == "" &amp;&amp; u.Host == "" &#123; oldpath := r.URL.Path if oldpath == "" &#123; // should not happen, but avoid a crash if it does oldpath = "/" &#125; // no leading http://server if url == "" || url[0] != '/' &#123; // make relative path absolute olddir, _ := path.Split(oldpath) url = olddir + url &#125; var query string if i := strings.Index(url, "?"); i != -1 &#123; url, query = url[:i], url[i:] &#125; // clean up but preserve trailing slash trailing := strings.HasSuffix(url, "/") url = path.Clean(url) if trailing &amp;&amp; !strings.HasSuffix(url, "/") &#123; url += "/" &#125; url += query &#125; &#125; w.Header().Set("Location", hexEscapeNonASCII(url)) w.WriteHeader(code) // RFC 2616 recommends that a short note "SHOULD" be included in the // response because older user agents may not understand 301/307. // Shouldn't send the response for POST or HEAD; that leaves GET. if r.Method == "GET" &#123; note := "&lt;a href=\"" + htmlEscape(url) + "\"&gt;" + statusText[code] + "&lt;/a&gt;.\n" fmt.Fprintln(w, note) &#125;&#125; 可以看到，DefaultServerMux 只有一个最基本的路由功能，是一个最简单的 HTTP 服务框架。可是这通常不能满足我们的需求，于是我们可以根据我们自己的需要自定义一个简单通用的 HTTP Server 框架。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Go http server (I)]]></title>
    <url>%2Funcategorized%2Fgo_http_server_1.html</url>
    <content type="text"><![CDATA[Go http server (I) 源码阅读 这个系列会写三到四篇文章，第一篇是 go sdk 里 net/http/server.go 的阅读笔记，之后会写一下如何利用 server.go 的接口自定义一个简易通用的 HTTP server 框架。 example先从一个简单的例子开始吧： 123456789101112131415161718192021222324package mainimport ( "net/http" "fmt" "log")//开启web服务func test() &#123; http.HandleFunc("/", sayHello) err := http.ListenAndServe(":9090", nil) // 注意这里第二个参数为 nil if err != nil &#123; log.Fatal("ListenAndServer:", err) &#125;&#125;func sayHello(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, "Hello Guest!")&#125;func main() &#123; test()&#125; 运行代码，此时浏览器访问localhost:9090就会看到输出 “Hello Guest!”，其实访问localhost:9090/+任意字符串，都能得到结果。这段代码先用http.HandleFunc注册了一个处理函数，然后调用http.ListenAndServe监听端口，当有请求到来时，会根据访问路径找到并执行对应的处理函数。 我们通常还能看到另一种写法： 12345678910111213141516171819202122232425262728package mainimport ( "net/http" "fmt" "log")//开启web服务func test() &#123; http.Handle("/", &amp;handler&#123;&#125;) err := http.ListenAndServe(":9090", nil) // if err != nil &#123; log.Fatal("ListenAndServer:", err) &#125;&#125;func sayHello(w http.ResponseWriter, r *http.Request) &#123;...&#125;func main() &#123; test()&#125;type handler struct&#123;&#125;func (h *handler) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; sayHello(w, r)&#125; 这段代码效果一样。区别就是http.HandleFunc和http.Handle需要的第二个参数，前者要一个func (w http.ResponseWriter, r *http.Request)函数，后者要一个实现了该函数的结构体。 123456789func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) &#123; mux.Handle(pattern, HandlerFunc(handler))&#125;func Handle(pattern string, handler Handler) &#123; DefaultServeMux.Handle(pattern, handler) &#125;func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) &#123; DefaultServeMux.HandleFunc(pattern, handler)&#125; 可以看到，两个函数都会调用mux.handle 1func (mux *ServeMux) Handle(pattern string, handler Handler) 第二个参数是Handler，是一个接口: 123type Handler interface &#123; ServeHTTP(ResponseWriter, *Request)&#125; 现在回到上面的HandleFunc,注意这个：HandlerFunc(handler),这里很容易让人误以为HandlerFunc是一个函数并且包装了传入的handler，再返回一个Handler类型。而实际上这里是类型转换，来看HandlerFunc的定义： 123456type HandlerFunc func(ResponseWriter, *Request)// ServeHTTP calls f(w, r).func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) &#123; f(w, r)&#125; 虽然HandlerFunc的类型是一个函数，但它是一种类型，因为是以type来定义而不是func，并且实现了ServeHTTP(w ResponseWriter, r *Request)，在这个函数里，它又调用了自身。这个细节是十分重要的，因为这一步关乎到当路由规则匹配时，相应的响应方法是否会被调用的问题！这里的类型转换用法使一个函数自身实现了一个接口，就不用每次都要先写一个本身无用结构体，再用结构体实现接口。请仔细体会这种技巧！ 。。。有点扯偏了，这里记住 Handler 这个接口是 go 语言 HTTP 服务最最最重要的接口，官方库和第三方库都按照这个接口来扩展。 Server来看一下 Server 这个结构体吧, 这里我只列出了几个核心的域： 12345678type Server struct &#123; Addr string // TCP address to listen on, ":http" if empty Handler Handler // handler to invoke, http.DefaultServeMux if nil TLSConfig *tls.Config // optional TLS config, used by ServeTLS and ListenAndServeTLS listeners map[net.Listener]struct&#123;&#125; onShutdown []func()&#125; handler这里主要关注 Handler，这个 Handler 就是刚刚的那个接口，可以在创建 Server 时传入，也可以在调用 Server.ListenAndServe 时传入： 1234func ListenAndServe(addr string, handler Handler) error &#123; server := &amp;Server&#123;Addr: addr, Handler: handler&#125; return server.ListenAndServe()&#125; 这个 handler 是在建立连接后收到客户端请求时用到： 123456789101112131415161718192021222324func (c *conn) serve(ctx context.Context) &#123; // conn 指当前连接 ... for &#123; w, err := c.readRequest(ctx) ... serverHandler&#123;c.server&#125;.ServeHTTP(w, w.req) ... &#125;&#125;type serverHandler struct &#123; srv *Server&#125;func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) &#123; handler := sh.srv.Handler if handler == nil &#123; handler = DefaultServeMux &#125; if req.RequestURI == "*" &amp;&amp; req.Method == "OPTIONS" &#123; handler = globalOptionsHandler&#123;&#125; &#125; handler.ServeHTTP(rw, req)&#125; 从 serverHandler 的 ServeHTTP 函数可以看到，当 server.handler==nil 时，使用内部全局变量，也就是前面提到过的 DefaultServeMux。也就是说，我们在收到请求时通过这个 handler 来执行自己的逻辑代码，所以这个 handler 必须包含路由功能，并且能够执行路由对应的处理函数。同时我们用的第三方 HTTP server 框架(echo、beego…)也是通过自定义 handler 来实现功能扩展。这也是 Handler 这个接口是最最重要的接口的原因。 关于 DefaultServeMux 和 自定义的 handler，会在之后详细讨论。接下来回到 Server 本身。 Server.Serve在主函数中可以调用 http.ListenAndServe 或者 http.Serve 来开始 HTTP 服务， 原理都一样： 1234567891011func (srv *Server) ListenAndServe() error &#123; addr := srv.Addr if addr == "" &#123; addr = ":http" &#125; ln, err := net.Listen("tcp", addr) if err != nil &#123; return err &#125; return srv.Serve(tcpKeepAliveListener&#123;ln.(*net.TCPListener)&#125;)&#125; 仔细看下 srv.Serve 的实现： 12345678910111213141516171819202122232425262728293031323334353637383940func (srv *Server) Serve(l net.Listener) error &#123; defer l.Close() var tempDelay time.Duration // how long to sleep on accept failure if err := srv.setupHTTP2_Serve(); err != nil &#123;// 如果设置了 http2，就使用 http2 服务， return err &#125; baseCtx := context.Background() // base is always background, per Issue 16220 ctx := context.WithValue(baseCtx, ServerContextKey, srv) for &#123; rw, e := l.Accept() // 这里会等待新的连接的建立，会阻塞在这里。 if e != nil &#123; select &#123; case &lt;-srv.getDoneChan(): return ErrServerClosed default: &#125; if ne, ok := e.(net.Error); ok &amp;&amp; ne.Temporary() &#123; if tempDelay == 0 &#123; tempDelay = 5 * time.Millisecond &#125; else &#123; tempDelay *= 2 &#125; if max := 1 * time.Second; tempDelay &gt; max &#123; tempDelay = max &#125; srv.logf("http: Accept error: %v; retrying in %v", e, tempDelay) time.Sleep(tempDelay) continue &#125; return e &#125; tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) &#125;&#125; 这里要详细解释一下的就是 Accept 返回的 error 了。有以下几种可能： Accept 的时候 Server 由于某种原因停止了 收到系统信号产生中断，当然如果 返回的是 EINTR 表示可以重新调用 之前断掉的连接在短时间被重用了，此时该连接处于 TIME_WAIT 状态，新连接暂时不可用。可参考这里 对于暂时性的错误，可以稍等一会儿，所以会出现 sleep。如果成功拿到 conn，先标记连接状态，然后创建新 goroutine 开始对连接服务。 conn.serve 这里由于 HTTPS 和 HTTP2 本身比较复杂，主要讨论 HTTP1.1 的实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788func (c *conn) serve(ctx context.Context) &#123; c.remoteAddr = c.rwc.RemoteAddr().String() ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr()) defer func() &#123; if err := recover(); err != nil &amp;&amp; err != ErrAbortHandler &#123; const size = 64 &lt;&lt; 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] c.server.logf("http: panic serving %v: %v\n%s", c.remoteAddr, err, buf) &#125; if !c.hijacked() &#123; c.close() c.setState(c.rwc, StateClosed) &#125; &#125;() if tlsConn, ok := c.rwc.(*tls.Conn); ok &#123; // 处理 https &#125; // HTTP/1.x from here on. ctx, cancelCtx := context.WithCancel(ctx) c.cancelCtx = cancelCtx defer cancelCtx() c.r = &amp;connReader&#123;conn: c&#125; c.bufr = newBufioReader(c.r) c.bufw = newBufioWriterSize(checkConnErrorWriter&#123;c&#125;, 4&lt;&lt;10) for &#123; // 同一个连接有多个请求，循环处理 w, err := c.readRequest(ctx) // 读取请求，会阻塞 if c.r.remain != c.server.initialReadLimitSize() &#123; // If we read any bytes off the wire, we're active. c.setState(c.rwc, StateActive) &#125; if err != nil &#123; // handle error return &#125; // Expect 100 Continue support req := w.req if req.expectsContinue() &#123; if req.ProtoAtLeast(1, 1) &amp;&amp; req.ContentLength != 0 &#123; // Wrap the Body reader with one that replies on the connection req.Body = &amp;expectContinueReader&#123;readCloser: req.Body, resp: w&#125; &#125; &#125; else if req.Header.get("Expect") != "" &#123; w.sendExpectationFailed() return &#125; c.curReq.Store(w) if requestBodyRemains(req.Body) &#123; // 支持管线化，处理当前请求时可能还在接收请求 registerOnHitEOF(req.Body, w.conn.r.startBackgroundRead) &#125; else &#123; if w.conn.bufr.Buffered() &gt; 0 &#123; w.conn.r.closeNotifyFromPipelinedRequest() &#125; w.conn.r.startBackgroundRead() &#125; serverHandler&#123;c.server&#125;.ServeHTTP(w, w.req) // 这里就是之前提到的，自定义处理的入口 w.cancelCtx() if c.hijacked() &#123; return &#125; w.finishRequest() // 把数据 flush 到网络层，此次请求在应用层结束 if !w.shouldReuseConnection() &#123; if w.requestBodyLimitHit || w.closedRequestBodyEarly() &#123; c.closeWriteAndWait() // 发送 TCP FIN ，关闭连接 &#125; return &#125; ... if d := c.server.idleTimeout(); d != 0 &#123; // 设置空闲超时，超时后关闭连接 c.rwc.SetReadDeadline(time.Now().Add(d)) if _, err := c.bufr.Peek(4); err != nil &#123; return &#125; &#125; c.rwc.SetReadDeadline(time.Time&#123;&#125;) &#125;&#125; 这里代码比较复杂，包含了比较完整的 HTTP、HTTPs、HTTP2 协议的实现，建议了解了协议的内容再来看具体实现。代码协议的细节部分代码就不详细谈了，我们需要理解的是 创建 listener，从 Accept 拿到连接，等待并读取到 request，用 handler 处理 request 并把结果或错误信息写到 response 的过程。 需要注意的是，我们所讨论的是 go 语言官方库的 HTTP 的实现，这里的发送和接收数据都是指的发给下层传输层和从传输层接收，也就是调用 socket 接口，一定要分清楚各个层次。]]></content>
  </entry>
  <entry>
    <title><![CDATA[netstack TCP(IV) 收发数据(下)]]></title>
    <url>%2Fnetstack-tcp%2Fnetstack_tcp_receive.html</url>
    <content type="text"><![CDATA[Netstack TCP(IV) 收发数据(下) 接上文，现在看一下 receiver 是如何接收数据的。 endpoint 上关于接收数据的字段如下： 123456rcvListMu sync.MutexrcvList segmentListrcvClosed boolrcvBufSize intrcvBufUsed intsegmentQueue segmentQueue 存储结构有 segmentList 和 segmentQueue 。而在 receiver 上主要是 pendingRcvdSegments segmentHeap，一个堆。记住这三个结构，接下来围绕它们展开。这三个结构之间的关系最后总结。 前面讨论发送数据时是从应用层和传输层之间接口 Write 开始的，而接收数据我们从网络层到传输层的接口 HandlePacket 开始讨论，这样符合数据流方向。 1234567891011121314151617func (e *endpoint) HandlePacket(r *stack.Route, id stack.TransportEndpointID, vv *buffer.VectorisedView) &#123; s := newSegment(r, id, vv) if !s.parse() &#123; atomic.AddUint64(&amp;e.stack.MutableStats().MalformedRcvdPackets, 1) s.decRef() return &#125; // 把收到的包直接放到 endpoint 的 segmentQueue 里面，但是顺序是没有保障的。 if e.segmentQueue.enqueue(s) &#123; e.newSegmentWaker.Assert() &#125; else &#123; // The queue is full, so we drop the segment. atomic.AddUint64(&amp;e.stack.MutableStats().DroppedPackets, 1) s.decRef() &#125;&#125; 在上一篇的 mainLoop 函数里，已经注册过 newSegmentWaker 和它的回调 handleSegments 函数，然后在循环中等待 waker。这里收到包，添加到队列里，然后通知 mainLoop 有新的包到来，触发 handleSegments ，先来看下大概执行过程： 123456789101112131415161718192021222324252627282930313233343536func (e *endpoint) handleSegments() bool &#123; checkRequeue := true for i := 0; i &lt; maxSegmentsPerWake; i++ &#123; // maxSegmentsPerWake 是一个常量，值为 100，其实是随意设置的一个值，因为每次 newSegmentWaker 被触发时可能有很多包要被处理 s := e.segmentQueue.dequeue() // 从队列拿到无序的数据包 if s == nil &#123; checkRequeue = false break &#125; ... if s.flagIsSet(flagRst) &#123; if e.rcv.acceptable(s.sequenceNumber, 0) &#123; ... return false &#125; &#125; else if s.flagIsSet(flagAck) &#123; ... e.rcv.handleRcvdSegment(s) // e.snd.handleRcvdSegment(s) // 分别调用 sender 和 receiver 处理同样的包 &#125; s.decRef() &#125; if checkRequeue &amp;&amp; !e.segmentQueue.empty() &#123; e.newSegmentWaker.Assert() // 当 100 次过后还有未处理的包，再次触发 newSegmentWaker &#125; // Send an ACK for all processed packets if needed. if e.rcv.rcvNxt != e.snd.maxSentAck &#123; e.snd.sendAck() &#125; return true&#125; 这里主要分为两个分支，分别交给 endpoint 的 receiver 和 sender 来处理。这里需要注意，每个 endpoint 只有一个 sender 和 一个 receiver，所以 sender 除了正常向外发送包，还需要在收到包时负责发送 ACK 或 SACK 。所以收到一个数据包时，receiver 和 sender 都要处理，这个过程大致如图 两个主要过程如下： rcv.handleRcvdSegment这个函数主要作用是接收乱序的包，放到 receiver 的 pendingRcvdSegments 这个最小堆里，在合适的时候把连续、完整的几个包放到 endpoint 的 rcvList，应用层读取连接的数据就是通过这个 rcvList。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546func (r *receiver) handleRcvdSegment(s *segment) &#123; segLen := seqnum.Size(s.data.Size()) segSeq := s.sequenceNumber if !r.acceptable(segSeq, segLen) &#123;// 判断包的合法性，是否在接收窗口范围 r.ep.snd.sendAck() // 发送冗余 ACK return &#125; if !r.consumeSegment(s, segSeq, segLen) &#123;// consumeSegment 判断当前收到的包是否可以造成接收窗口右移，如果是，说明 pendingRcvdSegments 这个堆里的数据包是连续的，然后把连续的包存到 endpoint 的 rcvList 队列里；如果不是，说明收到失序报文段，返回 FALSE if segLen &gt; 0 || s.flagIsSet(flagFin) &#123; // We only store the segment if it's within our buffer // size limit. if r.pendingBufUsed &lt; r.pendingBufSize &#123; r.pendingBufUsed += s.logicalLen() s.incRef() heap.Push(&amp;r.pendingRcvdSegments, s) &#125; UpdateSACKBlocks(&amp;r.ep.sack, segSeq, segSeq.Add(segLen), r.rcvNxt) // Immediately send an ack so that the peer knows it may // have to retransmit. r.ep.snd.sendAck() &#125; return &#125; // 继续检查 pendingRcvdSegments 里是否有更多连续的数据，如果有，取出来放到 rcvList 里 for !r.closed &amp;&amp; r.pendingRcvdSegments.Len() &gt; 0 &#123; s := r.pendingRcvdSegments[0] segLen := seqnum.Size(s.data.Size()) segSeq := s.sequenceNumber // Skip segment altogether if it has already been acknowledged. if !segSeq.Add(segLen-1).LessThan(r.rcvNxt) &amp;&amp; !r.consumeSegment(s, segSeq, segLen) &#123; break &#125; heap.Pop(&amp;r.pendingRcvdSegments) r.pendingBufUsed -= s.logicalLen() s.decRef() &#125;&#125; snd.handleRcvdSegment这里主要是在收到新的数据包后返回 ACK 或 SACK，并且更新当前状态，比如在外数据值、接收窗口、RTT、RTO… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879func (s *sender) handleRcvdSegment(seg *segment) &#123; // Check if we can extract an RTT measurement from this ack. if s.rttMeasureSeqNum.LessThan(seg.ackNumber) &#123; s.updateRTO(time.Now().Sub(s.rttMeasureTime)) s.rttMeasureSeqNum = s.sndNxt &#125; // Update Timestamp if required. See RFC7323, section-4.3. s.ep.updateRecentTimestamp(seg.parsedOptions.TSVal, s.maxSentAck, seg.sequenceNumber) // Count the duplicates and do the fast retransmit if needed. rtx := s.checkDuplicateAck(seg) // Stash away the current window size. s.sndWnd = seg.window // Ignore ack if it doesn't acknowledge any new data. ack := seg.ackNumber if (ack - 1).InRange(s.sndUna, s.sndNxt) &#123; // When an ack is received we must reset the timer. We stop it // here and it will be restarted later if needed. s.resendTimer.disable() // Remove all acknowledged data from the write list. acked := s.sndUna.Size(ack) s.sndUna = ack ackLeft := acked originalOutstanding := s.outstanding for ackLeft &gt; 0 &#123; // We use logicalLen here because we can have FIN // segments (which are always at the end of list) that // have no data, but do consume a sequence number. seg := s.writeList.Front() datalen := seg.logicalLen() if datalen &gt; ackLeft &#123; seg.data.TrimFront(int(ackLeft)) break &#125; if s.writeNext == seg &#123; s.writeNext = seg.Next() &#125; s.writeList.Remove(seg) s.outstanding-- seg.decRef() ackLeft -= datalen &#125; // Update the send buffer usage and notify potential waiters. s.ep.updateSndBufferUsage(int(acked)) // If we are not in fast recovery then update the congestion // window based on the number of acknowledged packets. if !s.fr.active &#123; s.updateCwnd(originalOutstanding - s.outstanding) &#125; // It is possible for s.outstanding to drop below zero if we get // a retransmit timeout, reset outstanding to zero but later // get an ack that cover previously sent data. if s.outstanding &lt; 0 &#123; s.outstanding = 0 &#125; &#125; // Now that we've popped all acknowledged data from the retransmit // queue, retransmit if needed. if rtx &#123; s.resendSegment() &#125; // Send more data now that some of the pending data has been ack'd, or // that the window opened up, or the congestion window was inflated due // to a duplicate ack during fast recovery. This will also re-enable // the retransmit timer if needed. s.sendData()&#125; 三个存储结构开始提到的三个字段，关系如下，结合图，再回过头看整个处理过程，其实很清楚了，每个结构的分工还是很明确的。]]></content>
      <categories>
        <category>netstack_tcp</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>netstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netstack TCP(III) 收发数据(上)]]></title>
    <url>%2Fnetstack-tcp%2Fnetstack_tcp_send.html</url>
    <content type="text"><![CDATA[Netstack TCP(III) 收发数据(上) 上一篇我们讨论了 TCP 连接建立的过程，这篇接着讨论连接建立以后的故事。 如果是被动建立连接，这个连接会经过 deliverAccept 函数被放到 Accept 队列，然后由应用程序去调用 Accept 来获取一个连接，Go SDK 1.9.2 的 net/http/server.go 中是这样调用的： 12345678910111213141516171819func (srv *Server) Serve(l net.Listener) error &#123; defer l.Close() ... for &#123; rw, e := l.Accept() if e != nil &#123; if ne, ok := e.(net.Error); ok &amp;&amp; ne.Temporary() &#123; ... time.Sleep(tempDelay) continue &#125; return e &#125; tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) &#125;&#125; 在这个程序中，循环去调用 Accept 去获取一个可读写的连接，但是可能会有一个暂时性的错误，所以让它 sleep 了一小会儿。当然，这里的 Accept 是对系统调用的封装， 和 netstack 的 Accept 不是同一个，但是基本原理是一样的。来看下 netstack 的 Accept： 1234567891011121314151617181920212223func (e *endpoint) Accept() (tcpip.Endpoint, *waiter.Queue, *tcpip.Error) &#123; e.mu.RLock() defer e.mu.RUnlock() // Endpoint must be in listen state before it can accept connections. if e.state != stateListen &#123; return nil, nil, tcpip.ErrInvalidEndpointState &#125; // Get the new accepted endpoint. var n *endpoint select &#123; case n = &lt;-e.acceptedChan: default: return nil, nil, tcpip.ErrWouldBlock // 注意这里，当没有新的连接时，没有一直阻塞，而是返回一个 ‘暂时不可用’ 的错误。这也是上一段代码里 sleep 一小会儿的原因。 &#125; // Start the protocol goroutine. wq := &amp;waiter.Queue&#123;&#125; n.startAcceptedLoop(wq) return n, wq, nil&#125; 获取到新的连接后进入 startAcceptedLoop， startAcceptedLoop只是对 protocolMainLoop的简单封装。 而如果是主动建立连接，三次握手后，直接进入 protocolMainLoop循环。 protocolMainLoop 如图，虚线框里的就是 protocolMainLoop 的主要内容。代码如下： 1234567891011121314151617181920212223242526272829303132333435func protocolMainLoop() *tcpip.Error&#123; ... // One time set-up. s := sleep.Sleeper&#123;&#125; funcs := []struct &#123; w *sleep.Waker f func() bool &#125;&#123; &#123; w: &amp;e.sndWaker, f: e.handleWrite, &#125;, &#123; w: &amp;e.sndCloseWaker, f: e.handleClose, &#125;, &#123; w: &amp;e.newSegmentWaker, f: e.handleSegments, &#125;, ... &#125; for i := range funcs &#123; s.AddWaker(funcs[i].w, i) &#125; // Called repeatedly. for &#123; v, _ := s.Fetch(true) if !funcs[v].f() &#123; return nil &#125; &#125; &#125; 可以看到，主要是注册一些回调，添加到 sleeper 的 waker 里，然后进入循环，Fetch 拿到触发了的事件，然后执行这些事件对应的回调。这是大体框架，接下来详细了解一些比较重要的事件及其回调。 ####sender 先来关注一个连接作为发送方需要的功能，sender 是比较复杂的，它需要关注 TCP 窗口大小、流量控制、超时重传、拥塞控制、保活探测等一系列机制，同时由于一个 endpoint 只有一个 sender 和 receiver，收到数据后返回 ACK 或者 SACK 的工作也需要 sender 来控制。 在 endpoint 上和发送有关的域有如下几个： 12345678sndBufMu sync.MutexsndBufSize intsndBufUsed intsndClosed boolsndBufInQueue seqnum.SizesndQueue segmentList // 用来保存还未发出的数据sndWaker sleep.WakersndCloseWaker sleep.Waker 在 sender 上也有一个writeList segmentList 域，这里 segmentList 是一个有头有尾的链表结构。这两个 segmentList 分别有什么作用和区别呢？我们通过 Write 函数来看下： 12345678910111213141516171819202122232425// 这是 socket 的标准接口之一，调用的时候通常放在一个循环里，确保数据被写入func (e *endpoint) Write(p tcpip.Payload, opts tcpip.WriteOptions) (uintptr, *tcpip.Error) &#123; ... // Check against the limit. avail := e.sndBufSize - e.sndBufUsed // 检查发送窗口大小 if avail &lt;= 0 &#123; // 可用窗口 &lt;= 0,暂时不可发送，返回一个‘暂时性’的错误，表示多试几次即可 return 0, tcpip.ErrWouldBlock &#125; v, perr := p.Get(avail) l := len(v) var err *tcpip.Error if p.Size() &gt; avail &#123; err = tcpip.ErrWouldBlock &#125; l := len(v) s := newSegmentFromView(&amp;e.route, e.id, v) // 把整块的数据根据当前窗口大小切出一个包，也就是说数据在此之前是‘流式’的 ... e.sndQueue.PushBack(s) // 注意这里先把数据包存在了 endpoint 的链表里。 ... e.handleWrite() return uintptr(l), err&#125; 需要注意的是，这里的 sendQueue 是可以被多个 goroutine 访问的，所以操作它要加锁（以上代码里为了简要删掉了）。在调用 e.handleWrite() 里，把 e.sendQueue 整个链表追加到了 endpoint.snd.writeList 尾部，由sender 接管，在这里由于调用 handlewrite 已经加了锁，所以 sender 的writeList 只能被一个 goroutine 操作，不需要再加锁。e.handleWrite 做了另一件事就是调用了 sendData 函数。涉及了 TCP 发送方的诸多细节和算法，如超时重传、慢启动、拥塞避免、快速恢复、Reno、newReno、窗口探测等等，读这段代码前需要对 TCP 协议有详细的了解，否则可以先跳过这段。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687func (s *sender) sendData() &#123; limit := s.maxPayloadSize // Reduce the congestion window to min(IW, cwnd) per RFC 5681, page 10. // "A TCP SHOULD set cwnd to no more than RW before beginning // transmission if the TCP has not sent data in the interval exceeding // the retrasmission timeout." if !s.fr.active &amp;&amp; time.Now().Sub(s.lastSendTime) &gt; s.rto &#123; if s.sndCwnd &gt; InitialCwnd &#123; s.sndCwnd = InitialCwnd &#125; &#125; // TODO: We currently don't merge multiple send buffers // into one segment if they happen to fit. We should do that // eventually. var seg *segment end := s.sndUna.Add(s.sndWnd) for seg = s.writeNext; seg != nil &amp;&amp; s.outstanding &lt; s.sndCwnd; seg = seg.Next() &#123; // We abuse the flags field to determine if we have already // assigned a sequence number to this segment. if seg.flags == 0 &#123; seg.sequenceNumber = s.sndNxt seg.flags = flagAck | flagPsh &#125; var segEnd seqnum.Value if seg.data.Size() == 0 &#123; seg.flags = flagAck s.ep.rcvListMu.Lock() rcvBufUsed := s.ep.rcvBufUsed s.ep.rcvListMu.Unlock() s.ep.mu.Lock() // We're sending a FIN by default fl := flagFin if (s.ep.shutdownFlags&amp;tcpip.ShutdownRead) != 0 &amp;&amp; rcvBufUsed &gt; 0 &#123; // If there is unread data we must send a RST. // For more information see RFC 2525 section 2.17. fl = flagRst &#125; s.ep.mu.Unlock() seg.flags |= uint8(fl) segEnd = seg.sequenceNumber.Add(1) &#125; else &#123; // We're sending a non-FIN segment. if !seg.sequenceNumber.LessThan(end) &#123; break &#125; available := int(seg.sequenceNumber.Size(end)) if available &gt; limit &#123; available = limit &#125; if seg.data.Size() &gt; available &#123; // Split this segment up. nSeg := seg.clone() nSeg.data.TrimFront(available) nSeg.sequenceNumber.UpdateForward(seqnum.Size(available)) s.writeList.InsertAfter(seg, nSeg) seg.data.CapLength(available) &#125; s.outstanding++ segEnd = seg.sequenceNumber.Add(seqnum.Size(seg.data.Size())) &#125; s.sendSegment(&amp;seg.data, seg.flags, seg.sequenceNumber) // Update sndNxt if we actually sent new data (as opposed to // retransmitting some previously sent data). if s.sndNxt.LessThan(segEnd) &#123; s.sndNxt = segEnd &#125; &#125; // Remember the next segment we'll write. s.writeNext = seg // Enable the timer if we have pending data and it's not enabled yet. if !s.resendTimer.enabled() &amp;&amp; s.sndUna != s.sndNxt &#123; s.resendTimer.enable(s.rto) &#125;&#125; 最后实际发送是调用 sender.sendSegment —&gt; endpoint.sendRaw —&gt; sendTCP —&gt; route.ref.ep.WritePacket，route 是这条连接对应的路由，WritePacket 把这个数据包传到对应的网络层endpoint，TCP sender 的工作到此结束了。 12345678910111213141516171819202122232425262728293031323334353637func (s *sender) sendSegment(data *buffer.VectorisedView, flags byte, seq seqnum.Value) *tcpip.Error &#123; ... rcvNxt, rcvWnd := s.ep.rcv.getSendParams() ... return s.ep.sendRaw(data.First(), flags, seq, rcvNxt, rcvWnd)&#125;func (e *endpoint) sendRaw(data buffer.View, flags byte, seq, ack seqnum.Value, rcvWnd seqnum.Size) *tcpip.Error &#123; ... err := sendTCP(&amp;e.route, e.id, data, flags, seq, ack, rcvWnd) return err&#125;func sendTCP(r *stack.Route, id stack.TransportEndpointID, data buffer.View, flags byte, seq, ack seqnum.Value, rcvWnd seqnum.Size) *tcpip.Error &#123; // 添加 TCP 首部 hdr := buffer.NewPrependable(header.TCPMinimumSize + int(r.MaxHeaderLength())) tcp := header.TCP(hdr.Prepend(header.TCPMinimumSize)) tcp.Encode(&amp;header.TCPFields&#123; SrcPort: id.LocalPort, DstPort: id.RemotePort, SeqNum: uint32(seq), AckNum: uint32(ack), DataOffset: header.TCPMinimumSize, Flags: flags, WindowSize: uint16(rcvWnd), &#125;) ... return r.WritePacket(&amp;hdr, data, ProtocolNumber)&#125;func (r *Route) WritePacket(hdr *buffer.Prependable, payload buffer.View, protocol tcpip.TransportProtocolNumber) *tcpip.Error &#123; return r.ref.ep.WritePacket(r, hdr, payload, protocol)&#125;]]></content>
      <categories>
        <category>netstack_tcp</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>netstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netstack(II) 链路层]]></title>
    <url>%2Funcategorized%2Fnetstack_linklayer.html</url>
    <content type="text"><![CDATA[Netstack(II) 链路层 链路层没有特别指明 Protocol 的接口，不过其 endpoint 如下： 123456789101112131415161718192021222324252627282930// LinkEndpoint 被以太网、环回、raw 等链路层协议实现，网络层协议用它来往外发送数据。type LinkEndpoint interface &#123; // MTU is the maximum transmission unit for this endpoint. This is // usually dictated by the backing physical network; when such a // physical network doesn't exist, the limit is generally 64k, which // includes the maximum size of an IP packet. MTU() uint32 // Capabilities returns the set of capabilities supported by the // endpoint. Capabilities() LinkEndpointCapabilities // MaxHeaderLength returns the maximum size the data link (and // lower level layers combined) headers can have. Higher levels use this // information to reserve space in the front of the packets they're // building. MaxHeaderLength() uint16 // LinkAddress returns the link address (typically a MAC) of the // link endpoint. LinkAddress() tcpip.LinkAddress // WritePacket writes a packet with the given protocol through the given // route. WritePacket(r *Route, hdr *buffer.Prependable, payload buffer.View, protocol tcpip.NetworkProtocolNumber) *tcpip.Error // Attach attaches the data link layer endpoint to the network-layer // dispatcher of the stack. Attach(dispatcher NetworkDispatcher)&#125; 通常用一个 endpointID 和它联系起来: 1type LinkEndpointID uint64 fdbased endpointLinkEndpoint 的实现有多种，这里我们主要看一下基于文件描述符的。 12345678910111213141516type endpoint struct &#123; fd int mtu uint32 hdrSize int // 指链路层首部长度，这里特别讨论一下，可能有两个值，0 或 14。14 好理解，6 字节 dst MAC 地址，6字节 src MAC 地址，2 字节类型。为什么可能是 0 呢，如果是 localhost 的数据，是不需要 dst 和 src Mac地址的。 addr tcpip.LinkAddress caps stack.LinkEndpointCapabilities // closed is a function to be called when the FD's peer (if any) closes // its end of the communication pipe. closed func(*tcpip.Error) vv *buffer.VectorisedView iovecs []syscall.Iovec views []buffer.View&#125; 这里 主要了解 View 和 VectorisedView： 123456type View []bytetype VectorisedView struct &#123; views []View size int&#125; 另外还有一个 Prependable： 1234type Prependable struct &#123; buf View usedIdx int&#125; 这三个结构是整个系统里用的最多的底层结构，用来表示要传输的包。特别是 Prependable，它是可以扩展的，并且是在数据的开始处扩展，想想各层网络协议的首部，是在上一层数据的最前面添加这一层的首部。 iovec 这里重点提一下 向量IO 的概念。这是一种在单词系统调用中操作多个缓冲区的 I/O 方法，可以将单个数据流的内容写到多个缓冲区，或者把单个数据流读到多个缓冲区中。 效率：单个向量I/O 操作能代替多个线性I/O 操作 性能：除了系统调用次数的降低，由于内部优化，向量I /O 比线性I/O 提供更好的性能。 原子性：不同于多个线性I/O 操作，一个进程可以执行单个向量I/O操作而且避免了与其它进程交叉操作的风险。 实际上，内核里的所有I/O 都是向量I/O，read()和 write()是只有一个向量的向量I/O，且向量中只有一个段。 代码里这个 iovecs 字段就是用于向量 IO，内存分配如下： 12345678910111213141516var BufConfig = []int&#123;128, 256, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768&#125; // 总共接近 64KB，其实有点困惑，真的需要这么多内存吗？因为 MTU 也就 1500Bfunc (e *endpoint) allocateViews(bufConfig []int) &#123; for i, v := range e.views &#123; if v != nil &#123; break &#125; b := buffer.NewView(bufConfig[i]) e.views[i] = b e.iovecs[i] = syscall.Iovec&#123; Base: &amp;b[0], Len: uint64(len(b)), &#125; &#125;&#125; 发送数据先看发送，就是系统调用往对应的 fd 里写入内容，需要注意的是这是非阻塞写入。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// WritePacket writes outbound packets to the file descriptor. If it is not// currently writable, the packet is dropped.func (e *endpoint) WritePacket(r *stack.Route, hdr *buffer.Prependable, payload buffer.View, protocol tcpip.NetworkProtocolNumber) *tcpip.Error &#123; if e.hdrSize &gt; 0 &#123; // 不是 localhost，需要加上首部 eth := header.Ethernet(hdr.Prepend(header.EthernetMinimumSize)) eth.Encode(&amp;header.EthernetFields&#123; DstAddr: r.RemoteLinkAddress, SrcAddr: e.addr, Type: protocol, &#125;) &#125; if len(payload) == 0 &#123; return rawfile.NonBlockingWrite(e.fd, hdr.UsedBytes()) &#125; return rawfile.NonBlockingWrite2(e.fd, hdr.UsedBytes(), payload)&#125;// 非阻塞写func NonBlockingWrite(fd int, buf []byte) *tcpip.Error &#123; var ptr unsafe.Pointer if len(buf) &gt; 0 &#123; ptr = unsafe.Pointer(&amp;buf[0]) &#125; _, _, e := syscall.RawSyscall(syscall.SYS_WRITE, uintptr(fd), uintptr(ptr), uintptr(len(buf))) if e != 0 &#123; return TranslateErrno(e) &#125; return nil&#125;// 利用 '向量 IO' 写入func NonBlockingWrite2(fd int, b1, b2 []byte) *tcpip.Error &#123; ... iovec := [...]syscall.Iovec&#123; // &#123; Base: &amp;b1[0], Len: uint64(len(b1)), &#125;, &#123; Base: &amp;b2[0], Len: uint64(len(b2)), &#125;, &#125; _, _, e := syscall.RawSyscall(syscall.SYS_WRITEV, uintptr(fd), uintptr(unsafe.Pointer(&amp;iovec[0])), uintptr(len(iovec))) if e != 0 &#123; return TranslateErrno(e) &#125; return nil&#125; 接收数据链路层 endpoint 在运行起来后会进入一个接收循环： 123456789101112131415161718192021222324252627282930313233func (e *endpoint) dispatchLoop(d stack.NetworkDispatcher) *tcpip.Error &#123; v := buffer.NewView(header.MaxIPPacketSize) for &#123; cont, err := e.dispatch(d, v) // note: if no data to deliver, it blocks. ... &#125;&#125;func (e *endpoint) dispatch(d stack.NetworkDispatcher, largeV buffer.View) (bool, *tcpip.Error) &#123; e.allocateViews(BufConfig) // 分配内存 n, err := rawfile.BlockingReadv(e.fd, e.iovecs) // 注意这里会阻塞 if err != nil &#123; return false, err &#125; ... used := e.capViews(n, BufConfig) e.vv.SetViews(e.views[:used]) e.vv.SetSize(n) e.vv.TrimFront(e.hdrSize) // note: trim eth header, leave the IP protocol d.DeliverNetworkPacket(e, addr, p, e.vv) // Prepare e.views for another packet: release used views. for i := 0; i &lt; used; i++ &#123; e.views[i] = nil &#125; return true, nil&#125; 以上 dispatch 先分配内存，然后读取，而且很明显只读取一个帧数据，由于 MTU 限制，通常大小为 1518B，所以不明白为什么会分配大约 64KB 的内存。 特别看一下 blockReadv 的实现，这个函数将底层的非阻塞读封装成了阻塞读。先回顾一下非阻塞 IO 模型： 12345678910111213141516171819202122232425func BlockingReadv(fd int, iovecs []syscall.Iovec) (int, *tcpip.Error) &#123; for &#123; n, _, e := syscall.RawSyscall(syscall.SYS_READV, uintptr(fd), uintptr(unsafe.Pointer(&amp;iovecs[0])), uintptr(len(iovecs))) // 注意这里可能阻塞，也可能不阻塞。首先这是一个 NonBlocking IO，如上图。数据没有准备好时，立即返回，数据准备好时，阻塞拷贝到 user 空间。 if e == 0 &#123; return int(n), nil &#125; event := struct &#123; fd int32 events int16 revents int16 &#125;&#123; fd: int32(fd), events: 1, // POLLIN &#125; _, e = blockingPoll(unsafe.Pointer(&amp;event), 1, -1) // 这里会阻塞直到有事件触发。第二个参数是 event 个数，第三个参数是指等待的时间，时间到了，不论有没有事件到来，都要返回，-1 代表无限等待。关于 poll 可以参考这里: // http://www.cnblogs.com/Anker/archive/2013/08/15/3261006.html if e != 0 &amp;&amp; e != syscall.EINTR &#123; // err=EINTR 代表需要重新发起调用 return 0, TranslateErrno(e) &#125; &#125;&#125; 读取到一个数据帧后，调用d.DeliverNetworkPacket(e, addr, p, e.vv)把数据分发到 network 层。这里涉及到 NetworkDispatcher 接口，在代码里由 NIC 实现，这次就不讨论了。 12345type NetworkDispatcher interface &#123; // DeliverNetworkPacket finds the appropriate network protocol // endpoint and hands the packet over for further processing. DeliverNetworkPacket(linkEP LinkEndpoint, remoteLinkAddr tcpip.LinkAddress, protocol tcpip.NetworkProtocolNumber, vv *buffer.VectorisedView)&#125; channel 、loopback、sniffer endpoint这里简单讨论一下其他的 endpoint 实现。 channel endpoint1234567891011121314type PacketInfo struct &#123; Header buffer.View Payload buffer.View Proto tcpip.NetworkProtocolNumber&#125;type Endpoint struct &#123; dispatcher stack.NetworkDispatcher mtu uint32 linkAddr tcpip.LinkAddress // C is where outbound packets are queued. C chan PacketInfo&#125; channel 主要是实现内部通信，所以写数据就是直接把帧放到 channel 形成队列： 12345678910111213141516171819// WritePacket stores outbound packets into the channel.func (e *Endpoint) WritePacket(_ *stack.Route, hdr *buffer.Prependable, payload buffer.View, protocol tcpip.NetworkProtocolNumber) *tcpip.Error &#123; p := PacketInfo&#123; Header: hdr.View(), Proto: protocol, &#125; if payload != nil &#123; p.Payload = make(buffer.View, len(payload)) copy(p.Payload, payload) &#125; select &#123; case e.C &lt;- p: default: &#125; return nil&#125; loopback endpoint环回的 endpoint 就更简单了，不需要经过网卡，经过它发送的数据立即被looped back到IP层的输入队列中。 123456789101112131415func (e *endpoint) WritePacket(_ *stack.Route, hdr *buffer.Prependable, payload buffer.View, protocol tcpip.NetworkProtocolNumber) *tcpip.Error &#123; if len(payload) == 0 &#123; // We don't have a payload, so just use the buffer from the // header as the full packet. v := hdr.View() vv := v.ToVectorisedView([1]buffer.View&#123;&#125;) e.dispatcher.DeliverNetworkPacket(e, "", protocol, &amp;vv) &#125; else &#123; views := []buffer.View&#123;hdr.View(), payload&#125; vv := buffer.NewVectorisedView(len(views[0])+len(views[1]), views) e.dispatcher.DeliverNetworkPacket(e, "", protocol, &amp;vv) &#125; return nil&#125; 另外特别的是，由于不经过实际链路，所以没有通常意义的 MTU，它的 MTU 可以取到最大值： 123func (*endpoint) MTU() uint32 &#123; return 65536&#125; sniffer endpointsniffer 意思是探测器，这个 endpoint 只是对一个正常的 endpoint 的包装，实现 LinkEndpoint 接口的函数都是调用它所包装的 endpoint。它所实现的功能是记录所有经过它的包，可以用它实现抓包。 123456789type endpoint struct &#123; dispatcher stack.NetworkDispatcher lower stack.LinkEndpoint file *os.File&#125;func LogPacket(prefix string, protocol tcpip.NetworkProtocolNumber, b, plb []byte) &#123;...&#125;]]></content>
      <tags>
        <tag>tcp</tag>
        <tag>netstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netstack TCP(II) 连接管理与三次握手]]></title>
    <url>%2Fnetstack-tcp%2Fnetstack_conn_handshake.html</url>
    <content type="text"><![CDATA[Netsatck TCP(II) 连接的建立与三次握手protocolListenLoop当新建一个 endpoint 并且将其 Bind 到一个端口后，这个endpoint 进入 protocolListenLoop，负责监听与连接建立。 12345678910111213141516171819202122232425262728293031323334e.protocolListenLoop(seqnum.Size(e.receiveBufferAvailable()))&#123;// 同时设置了 rcvBuf 的大小 ctx := newListenContext(e.stack, rcvWnd, v6only, e.netProto)// 只是为了带一些参数 s := sleep.Sleeper&#123;&#125; s.AddWaker(&amp;e.notificationWaker, wakerForNotification) s.AddWaker(&amp;e.newSegmentWaker, wakerForNewSegment) for &#123; switch index, _ := s.Fetch(true); index &#123; case wakerForNotification: n := e.fetchNotifications() if n&amp;notifyClose != 0 &#123; // 表示收到退出通知 return nil &#125; case wakerForNewSegment: // Process at most maxSegmentsPerWake segments. mayRequeue := true for i := 0; i &lt; maxSegmentsPerWake; i++ &#123; // maxSegmentsPerWake==100,因为收到一个通知可能对应受到了多个数据包，所以每次 wake // 都处理多次 s := e.segmentQueue.dequeue() if s == nil &#123; break &#125; e.handleListenSegment(ctx, s) &#125; if mayRequeue &amp;&amp; !e.segmentQueue.empty() &#123; e.newSegmentWaker.Assert() // maxSegmentsPerWake 次循环仍然没有处理完所有的包，再次唤醒 waker，继续处理 &#125; &#125; &#125;&#125; handleListenSegment 处理收到的数据包，优先判定是否有 SYN 标识。如果改数据包没有 SYN 而有 ACK 标识的话，那么根据三次握手，它属于第三步，验证其合法后，该数据包对应的连接已经建立，那么为该连接创建一个新的 endpoint，将其发给 Accept 队列。 只要包含 SYN标识，那么说明该连接处于三步握手的第一步。为什么不是第二步？因为这是 Listen 函数，当前处于连接的被动方。这里会有一个队列，称为 SYN_RCVD 队列或半连接队列。长度为 max(64,/proc/sys/net/ipv4/tcp_max_syn_backlog) ，在机器的tcp_max_syn_backlog值在/proc/sys/net/ipv4/tcp_max_syn_backlog下配置。 当这个队列满了，不开启 syncookies 的时候，Server 会丢弃新来的 SYN 包，而 Client 端在多次重发 SYN 包得不到响应而返回（connection time out）错误。但是，当 Server 端开启了 syncookies=1，那么 SYN 半连接队列就没有逻辑上的最大值了，并且 /proc/sys/net/ipv4/tcp_max_syn_backlog 设置的值也会被忽略。在 netstack 中开启了 syncookies。 1234567891011121314151617181920212223func (e *endpoint) handleListenSegment(ctx *listenContext, s *segment) &#123; switch s.flags &#123; case flagSyn: opts := parseSynSegmentOptions(s) if incSynRcvdCount() &#123; // 半连接队列长度 +1，成功返回 true，队列已满返回 false go e.handleSynSegment(ctx, s, &amp;opts) &#125; else &#123; // 这里采用 SYNCookies 策略，SYN 半连接队列就没有逻辑上的最大值 cookie := ctx.createCookie(s.id, s.sequenceNumber, encodeMSS(opts.MSS)) ... sendSynTCP(&amp;s.route, s.id, flagSyn|flagAck, cookie, s.sequenceNumber+1, ctx.rcvWnd, synOpts) &#125; case flagAck: if data, ok := ctx.isCookieValid(s.id, s.ackNumber-1, s.sequenceNumber-1); ok &amp;&amp; int(data) &lt; len(mssTable) &#123; // 验证 ACK 的正确性 ... n, err := ctx.createConnectedEndpoint(s, s.ackNumber-1, s.sequenceNumber-1, rcvdSynOptions) if err == nil &#123; e.deliverAccepted(n) &#125; &#125; &#125;&#125; e.handleSynSegment 做的事情就是创建 handshake 结构体，执行三步握手，然后将完成握手的新的 endpoint 传入 Accept 队列。 123456789func (e *endpoint) handleSynSegment(ctx *listenContext, s *segment, opts *header.TCPSynOptions) &#123; defer decSynRcvdCount() // 不论最后有没有成功建立连接，把半连接数量 -1 n, err := ctx.createEndpointAndPerformHandshake(s, opts) if err != nil &#123; return &#125; e.deliverAccepted(n)&#125; 1234567891011121314151617func (l *listenContext) createEndpointAndPerformHandshake(s *segment, opts *header.TCPSynOptions) (*endpoint, *tcpip.Error) &#123; // Create new endpoint. irs := s.sequenceNumber // irs: initial remote sequenceNUmber cookie := l.createCookie(s.id, irs, encodeMSS(opts.MSS)) // 同样需要使用 cookie 来实现验证 ep, err := l.createConnectedEndpoint(s, cookie, irs, opts) ... // Perform the 3-way handshake. h, err := newHandshake(ep, l.rcvWnd) ... if err := h.execute(); err != nil &#123; ep.Close() return nil, err &#125; ... return ep, nil&#125; 主要看下 handshake 的 excute 方法，也就是具体执行握手的方法。在看代码之前我们要做到心中有 B 树，哦不，是连接状态机： 注意这个函数可以在被动的 Listen 函数里调用，也可以在主动的 Connect 里被调用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455func (h *handshake) execute() *tcpip.Error &#123; // Initialize the resend timer. resendWaker := sleep.Waker&#123;&#125; timeOut := time.Duration(time.Second) // 设置初始 RTO 为 1s rt := time.AfterFunc(timeOut, func() &#123; resendWaker.Assert() // RTO 后触发超时重传 &#125;) defer rt.Stop() // Set up the wakers. s := sleep.Sleeper&#123;&#125; s.AddWaker(&amp;resendWaker, wakerForResend) s.AddWaker(&amp;h.ep.notificationWaker, wakerForNotification) s.AddWaker(&amp;h.ep.newSegmentWaker, wakerForNewSegment) defer s.Done() synOpts := header.TCPSynOptions&#123; WS: h.rcvWndScale, // 这里设置的是自己这一端的 wndScale TS: true, TSVal: h.ep.timestamp(), TSEcr: h.ep.recentTS, &#125; if h.state == handshakeSynRcvd &#123; synOpts.TS = h.ep.sendTSOk // handshakeSynRcvd 说明当前是由 Listen 调用的被动连接，由对方决定是否使用 TS 选项 &#125; // 注意以下的 ACK 序列号，如果是主动发起连接，该值为 0，相反，则值为 irs + 1 sendSynTCP(&amp;h.ep.route, h.ep.id, h.flags, h.iss, h.ackNum, h.rcvWnd, synOpts) for h.state != handshakeCompleted &#123; switch index, _ := s.Fetch(true); index &#123; case wakerForResend: // SYN+ACK 超时重传的情况 timeOut *= 2 // 指数退避行为 if timeOut &gt; 60*time.Second &#123; // 最大超时时间 return tcpip.ErrTimeout &#125; rt.Reset(timeOut) sendSynTCP(&amp;h.ep.route, h.ep.id, h.flags, h.iss, h.ackNum, h.rcvWnd, synOpts) case wakerForNotification: // 收到关闭信号 n := h.ep.fetchNotifications() if n&amp;notifyClose != 0 &#123; return tcpip.ErrAborted &#125; case wakerForNewSegment: // 等待并处理新的 SYN 数据包或握手第三步的 ACK if err := h.processSegments(); err != nil &#123; return err &#125; &#125; &#125; return nil&#125; 如上，excute 首先发送一个 SYN + ACK 报文（注意这里对应主动和被动两种情况），然后进入循环直到建立连接。同理，h.processSegments 也对应两种情况。如果自己是主动连接，那么自己目前处于 SYN_SENT 状态，等待一个 SYN + ACK 报文并执行 synSentState： 12345678910111213141516171819202122232425262728293031323334353637383940func (h *handshake) synSentState(s *segment) *tcpip.Error &#123; // RFC 793, page 37, states that in the SYN-SENT state, a reset is // acceptable if the ack field acknowledges the SYN. if s.flagIsSet(flagRst) &#123; if s.flagIsSet(flagAck) &amp;&amp; s.ackNumber == h.iss+1 &#123; return tcpip.ErrConnectionRefused &#125; return nil &#125; if !h.checkAck(s) || !s.flagIsSet(flagSyn) &#123; return nil &#125; rcvSynOpts := parseSynSegmentOptions(s) h.ep.maybeEnableTimestamp(&amp;rcvSynOpts) // 设置是否允许时间戳选项 h.ackNum = s.sequenceNumber + 1 h.flags |= flagAck h.mss = rcvSynOpts.MSS h.sndWndScale = rcvSynOpts.WS if s.flagIsSet(flagAck) &#123; // 发出 SYN 后收到了 SYN + ACK，再发送一个 ACK，连接就完成建立了 h.state = handshakeCompleted h.ep.sendRaw(nil, flagAck, h.iss+1, h.ackNum, h.rcvWnd&gt;&gt;h.effectiveRcvWndScale()) return nil &#125; // 以下这一端对应的是状态机那张图里的‘同时连接’的情况，此时作为主动方已经发出了一个 SYN，然后又收到了一个 SYN，此时只要发送一个 SYN + ACK，对于对方来说这个连接就已经建立了，对于自己来说，再收到一个 SYN + ACK 也算完成连接。 h.state = handshakeSynRcvd synOpts := header.TCPSynOptions&#123; WS: h.rcvWndScale, TS: rcvSynOpts.TS, TSVal: h.ep.timestamp(), TSEcr: h.ep.recentTS, &#125; sendSynTCP(&amp;s.route, h.ep.id, h.flags, h.iss, h.ackNum, h.rcvWnd, synOpts) return nil&#125; 如果是被动连接，那么自己目前处于 SYN_RCVD 状态，等待一个 ACK： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253func (h *handshake) synRcvdState(s *segment) *tcpip.Error &#123; if s.flagIsSet(flagRst) &#123; // if s.sequenceNumber.InWindow(h.ackNum, h.rcvWnd) &#123; return tcpip.ErrConnectionRefused &#125; return nil &#125; if !h.checkAck(s) &#123; return nil &#125; if s.flagIsSet(flagSyn) &amp;&amp; s.sequenceNumber != h.ackNum-1 &#123; // 之前已经收到过了一个 SYN，然后又收到了一个 SYN，并且两次 seq 不同，那么认为对方抽风，发送 RST 关闭连接。 ack := s.sequenceNumber.Add(s.logicalLen()) seq := seqnum.Value(0) if s.flagIsSet(flagAck) &#123; seq = s.ackNumber &#125; h.ep.sendRaw(nil, flagRst|flagAck, seq, ack, 0) if !h.active &#123; return tcpip.ErrInvalidEndpointState &#125; if err := h.resetState(); err != nil &#123; return err &#125; synOpts := header.TCPSynOptions&#123; WS: h.rcvWndScale, TS: h.ep.sendTSOk, TSVal: h.ep.timestamp(), TSEcr: h.ep.recentTS, &#125; sendSynTCP(&amp;s.route, h.ep.id, h.flags, h.iss, h.ackNum, h.rcvWnd, synOpts) return nil &#125; if s.flagIsSet(flagAck) &#123; // 如果之前协商好了要带上 timeStamp 选项，但是握手第三步没有带上时间戳，那么丢弃这个 ACK 数据包 if h.ep.sendTSOk &amp;&amp; !s.parsedOptions.TS &#123; atomic.AddUint64(&amp;h.ep.stack.MutableStats().DroppedPackets, 1) return nil &#125; // 更新时间戳 h.ep.updateRecentTimestamp(s.parsedOptions.TSVal, h.ackNum, s.sequenceNumber) h.state = handshakeCompleted return nil &#125; return nil&#125;]]></content>
      <categories>
        <category>netstack_tcp</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>netstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netstack TCP(I) 总览]]></title>
    <url>%2Fnetstack-tcp%2Fnetstack_tcp_overview.html</url>
    <content type="text"><![CDATA[netstack 是 Google 开源的用 Go 语言实现的网络协议栈。在之前的几篇文章中我们简要的了解了 TCP 协议的基本内容，接下来我会通过读源码来加深对协议的理解，学习如何架构一个比较复杂的项目。当然只会对源码进行大致的分析以及梳理关键点，源码还需要详细的去阅读。这里附上我 fork 的 netstack项目,我在原来的基础上加了一些自己的注释或一些问题，为了区别原有注释，注释中以 ‘note：’ 开头的是我自己的笔记。如果你是用的 Intellij 的编辑器，参照这篇设置高亮。 主要结构及其关联 TCP 实现里暴露出来的最主要的接口是 EndPoint，它对应 Socket 的概念，提供了应用层常用的 Listen、Accept、Bind、Connect 等等方法。endpoint 结构体实现了 EndPoint 接口，它是一个 TCP 连接一端的实体，主要包含 sender、receiver、handshake 这三个结构体，这三个结构体也实现了一个 TCP 端所需的主要功能。 还有另一个非常重要的自段：stack，它是整个网络协议栈的抽象，这里负责把网络层和传输层连接起来。 调用过程 整个运行的核心在图中标红的两个循环里，其余的部分代码较少，实现也简单。endpoint 的 Listen 函数在 protocolListenLoop 中监听新的连接请求，主要处理三步握手的 SYN 报文和 ACK 报文，负责连接的被动建立。可以看到，这里会有一个处于 SYN_RCVD 状态的半连接的队列。建立好的连接通过一个长度为 backlog 的channel，把新建连接对应的 endpoint 放到 backlog 队列，然后执行 Accept 的逻辑。 需要注意的是，负责 Listen 的 endpoint 管理的是所有未完成的连接，而连接建立以后会获得一个新的 endpoint，专门负责那一个连接。 Accept 和 Connect 函数处理的都是已经建立好的连接，不同之处是 Connect 是主动发起连接，而 Accept 是被动的。 sleep 包进入 protocolMainLoop 之前，先注册了一些回调函数，然后进入循环，当对应事件发生时，通过 sleeper-waker 机制，调用提前注册的函数。sleep 实现了一个边缘触发的 epoll 1It is similar to edge-triggered epoll waits, where the user registers each object of interest once, and then can repeatedly wait on all of them. 用法如下： 12345678910111213141516171819202122232425262728293031323334func protocolMainLoop() *tcpip.Error&#123; ... // One time set-up. s := sleep.Sleeper&#123;&#125; funcs := []struct &#123; w *sleep.Waker f func() bool &#125;&#123; &#123; w: &amp;e.sndWaker, f: e.handleWrite, &#125;, &#123; w: &amp;e.sndCloseWaker, f: e.handleClose, &#125;, &#123; w: &amp;e.newSegmentWaker, f: e.handleSegments, &#125;, &#125; for i := range funcs &#123; s.AddWaker(funcs[i].w, i) &#125; // Called repeatedly. for &#123; v, _ := s.Fetch(true) if !funcs[v].f() &#123; return nil &#125; &#125; &#125; 进入循环以后，就是 endpoint 的 sender 和 receiver 的工作了，TCP 实现的总体结构就是这样了。接下来需要仔细看看连接如何建立，如何三次握手，以及连接建立后如何控制流量与拥塞控制。]]></content>
      <categories>
        <category>netstack_tcp</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>netstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij 自定义注释]]></title>
    <url>%2Funcategorized%2Fintellij%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E9%87%8A.html</url>
    <content type="text"><![CDATA[有时候在读好的代码的时候想要自己加上一些注释，并且为了和原来的注释区分开，想让它高亮显示，应该怎么设置呢？ steps 打开 preference –&gt; editor –&gt; TODO 在 Patterns 里添加一行, 填写 \bname\b.*, 其中 name 就是你的自定义注释，选择颜色，然后就 OK 啦！ 使用的时候按照 todo 那种注释写，不过把 todo 换成你自定义的就好啦 如图：]]></content>
      <tags>
        <tag>Intellij</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 疑难杂症]]></title>
    <url>%2Fnetwork-protocol%2Ftcp_faq.html</url>
    <content type="text"><![CDATA[TCP 的一些问题与解答TCP 连接的初始化序列号能否固定如果初始化序列号（缩写为ISN：Inital Sequence Number）可以固定，我们来看看会出现什么问题： 假设ISN固定是1，Client和Server建立好一条TCP连接后，Client连续给Server发了10个包，这10个包不知怎么被链路上的路由器缓存了(路由器会毫无先兆地缓存或者丢弃任何的数据包)，这个时候碰巧Client挂掉了； 然后Client用同样的端口号重新连上Server，Client又连续给Server发了几个包，假设这个时候Client的序列号变成了5； 接着，之前被路由器缓存的10个数据包全部被路由到Server端了，Server给Client回复确认号10，这个时候，Client整个都不好了，这是什么情况？我的序列号才到5，你怎么给我的确认号是10了，整个都乱了。 RFC793](https://tools.ietf.org/html/rfc793)中，建议ISN和一个假的时钟绑在一起，这个时钟会在每4微秒对 ISN 做加一操作，直到超过2^32，又从0开始，这需要4小时才会产生 ISN 的回绕问题，这几乎可以保证每个新连接的ISN不会和旧的连接的 ISN 产生冲突。这种递增方式的 ISN，很容易让攻击者猜测到TCP连接的ISN，现在的实现大多是在一个基准值的基础上进行随机的。 初始化连接的 SYN 超时问题Client发送SYN包给Server后挂了，Server 回给 Client 的 SYN-ACK 一直没收到 Client 的 ACK 确认，这个时候这个连接既没建立起来，也不能算失败。这就需要一个超时时间让 Server 将这个连接断开，否则这个连接就会一直占用Server的SYN连接队列中的一个位置，大量这样的连接就会将Server的 SYN 连接队列耗尽，让正常的连接无法得到处理。 目前，Linux下默认会进行5次重发SYN-ACK包，重试的间隔时间从1s开始，下次的重试间隔时间是前一次的双倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了.所以，总共需要 63s，TCP才会把断开这个连接。 由于，SYN 超时需要63秒，那么就给攻击者一个攻击服务器的机会，攻击者在短时间内发送大量的SYN包给Server(俗称 SYN flood 攻击)，用于耗尽Server的SYN队列。对于应对SYN 过多的问题，linux提供了几个TCP参数：tcp_syncookies、tcp_synack_retries、tcp_max_syn_backlog、tcp_abort_on_overflow 来调整应对。 TIME_WAIT 状态TIME_WAIT状态是TCP连接中主动关闭连接的一方会进入的状态，在发出最后一个 ACK 包之后，主动关闭方进入 TIME_WAIT 状态，从而确保 ACK 包到达对端，以及等待网络中之前迷路的数据包完全消失，防止端口被复用的时候收到迷路包从而出现收包错误。 TIME_WAIT 状态会持续 2MSL（max segment lifetime）的时间，一般 1 分钟到 4 分钟。在这段时间内端口不能被重新分配使用。 Linux 上使用 sysctl -a | grep time | grep wait 命令查看如下： TIME_WAIT会带来哪些问题呢？ 作为服务器，短时间内关闭了大量的 Client 连接，就会造成服务器上出现大量的TIME_WAIT连接，占据大量的tuple，严重消耗着服务器的资源； 作为客户端，短时间内大量的短连接，会大量消耗的Client机器的端口，毕竟端口只有65535个，端口被耗尽了，后续就无法在发起新的连接了。 如何解决服务端为了解决这个 TIME_WAIT 问题，可选的方式有3种： 保证由客户端主动发起关闭 关闭的时候使用 RST 方式（set SO_LINGER） 对处于 TIME_WAIT 状态的 TPC 允许重用（set SO_REUSEADDR），设置TCP参数 net.ipv4.tcp_tw_reuse = 1 和 net.ipv4.tcp_tw_recycle = 1。注意：使用tcp_tw_reuse和tcp_tw_recycle解决TIME_WAIT过多问题是非常危险的，参考RFC]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 保活机制]]></title>
    <url>%2Fnetwork-protocol%2Ftcp_keepalive.html</url>
    <content type="text"><![CDATA[TCP 保活机制 TCP 协议没有轮询机制，对于一个没有传输数据的连接来说，连接也可以一直保持。理论上，中间路由器可以崩溃和重启，数据线也可以断开再重连，只要两端没有重启或更改 IP ，依然可以保持连接状态。 有的情况下，服务端需要知道客户端是否已经离开以便回收空间；有的情况下，连接很久不需要数据交换，但是我们希望保持一定的数据流。于是设计了保活机制。 保活机制是一种在不影响数据流内容的情况下探测对方的方式。有一个保活计时器实现，定时器超时，就发送一个保活探测包，另一端收到后会返回相应的 ACK。 保活功能默认情况下是关闭的。如果在一段时间（保活时间，keepalive time）连接处于非活动状态，开启了保活功能的一端向另一端发送一个探测报文，如果在一定时间（保活时间间隔，keepalive interval）没有收到响应，那么将继续每隔保活时间间隔发送一个探测报文，直到次数达到一个阈值（保活探测数，keepalive probe）,如果仍然没有响应，就认为对方不可达，连接中断。 在不同的系统中，这些变量默认值如下： times\os Linux FreeBSD OSX Windows keepalive time 2h 2h 2h 2h keepalive interval 75s 75s 75s 1s Keepalive probe 9 8 9 10 保活报文段可以为空报文段，但通常包含一个字节的数据，它的序列号为对方发送的 ACK 的最大序号减 1（为了不影响已到达的报文段）。即使探测报文丢失也不会重传。 对方的四种状态 对方主机正常工作，并且可以到达。对方 TCP 响应正常。 对方主机已崩溃，包括已经关机或正在重启。对方不会响应探测报文，请求端持续发送 Keepalive probe 次的报文，然后关闭连接 对方主机崩溃并且已经重启。此时对方收到保活探测报文，会返回一个重置报文段，于是请求方关闭连接 对方主机正常工作，但是网络不可达。 一般来说主机无法分辨第二种和第四种情况，这也是一种缺陷，比如当中间路由器崩溃时，连接一方发送保活探测，于是只好断开连接。除了第一种情况，请求端的应用层会收到来自 TCP 层的差错报告，比如连接超时、连接重置等等。 FAQ为什么两端主机和中间路由器工作正常，并且链路可达，但是没有超过 2 小时，连接也会关闭呢？ 如图，两个主机之间 TCP 连接的保持同样会受到中间节点的影响，尤其是会受到防火墙（软件或硬件防火墙）的限制。防火墙的工作特性决定了要维护一个网络连接就需要耗费较多的资源，并且企业防火墙常常位于企业网络的出入口，长时间维护非活跃的 TCP 连接必将导致网络性能的下降。因此，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 TCP 连接断连。 解决方案： 延长防火墙终止非活跃的 TCP 连接的时间。例如，针对上述案例，可以调节防火墙设置，将时间设置为大于服务器端设定的 2 小时。 缩短服务器端的 TCP 连接保活时间。缩短该时间的目的是为了在连接被防火墙终止之前发送保活探测报文，既可以探测客户端状态，又可以使连接变为活跃状态。 为什么说基于TCP的移动端IM仍然需要心跳保活？Keep Alive 机制开启后，TCP 层将在定时时间到后发送相应的 KeepAlive 探针以确定连接可用性。一般时间为 7200 s（2h），失败后重试 10 次，每次超时时间 75 s。显然默认值无法满足我们的需求，而修改过设置后就可以满足了吗？答案仍旧是否定的。 考虑一种情况，某台服务器因为某些原因导致负载超高，CPU 100%，无法响应任何业务请求，但是使用 TCP 探针则仍旧能够确定连接状态，这就是典型的连接活着但业务提供方已死的状态，对客户端而言，这时的最好选择就是断线后重新连接其他服务器，而不是一直认为当前服务器是可用状态，一直向当前服务器发送些必然会失败的请求。 KeepAlive 并不适用于检测双方存活的场景，这种场景还得依赖于应用层的心跳。应用层心跳有着更大的灵活性，可以控制检测时机，间隔和处理流程，甚至可以在心跳包上附带额外信息。从这个角度而言，应用层的心跳的确是最佳实践。]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 拥塞控制]]></title>
    <url>%2Fnetwork-protocol%2Ftcp_congestion_control.html</url>
    <content type="text"><![CDATA[TCP 拥塞控制 在上一篇文章中，讲了通过滑动窗口实现发送方和接收方之间一对一的流量控制。这次我们来看一下 TCP 协议是如何对网络进行宏观调控，也就是 TCP 拥塞控制。 网络拥塞网络中的路由器因无法处理高速到达的流量而被迫丢弃数据信息的现象称为拥塞。这里可能是因为路由器缓存较小或者处理不及时，虽然和流量控制时接收方的情况相似，但是这里有本质区别。因为后者是一对一的，几乎只影响一条连接；后者则影响多个连接。 当网络中大量的发送方和接收方被要求承担超负荷的通信任务时，可以采用降低发送方发送速率或者丢弃部分数据（也可二者结合）来降低拥塞。 TCP 拥塞检测通常来说，接收方没有一个精确的方法去知道中间路由器的状态。目前基本的方法有： 依据丢包情况，如果有丢包发生，可以认为是网络拥堵引发的丢包，但是丢包本身就是不能精确判断的。并且有时候我们不能判断丢包是因为路由器拥塞造成的还是由传输错误造成的（在无线网络中，传输和接收错误是丢包主要原因） 通过时延测量，当感知到 RTT 明显增大时，可以认为是网络拥堵。但是 RTT 测量本身也没有精确的方法。 显式收到一个丢包的消息，也称显式拥塞通知（Explicit Congestion Notification, ECN）。路由器在发生拥堵的时候，向数据包的 IP 首部中设置两个 ENC 标志位，发送方收到后可知拥塞发生。接收方收到则将其放到 ACK 报文中返回给发送方，直到发送方发来的报文中 CWR（接下来会说到） 字段被置为了 1。但是这个方法主要的限制是，它还没有被很好的推广，网络中很多路由器还不支持它。 拥塞窗口之前的文章提到，发送方为了适应接收方接受速度，设置了一个发送窗口来控制流量。同样的，当拥堵发生时，也需要控制发送速率，于是引入了一个窗口变量，来反映网络传输能力，称为拥塞窗口（Congestion window），记作 cwnd。很直观的，我们可以知道，发送端实际可用窗口 W 表示如下,其中 awnd 表示接收方窗口大小： ​ W = min(cwnd, awnd) 也就是说，还没有收到 ACK 的数据量（也称在外数据量）不能多于 W 。通常 W 以字节或包为单位。很明显， W 的值是在随时变化的，并且我们希望 W 接近一个最佳窗口大小——带宽延时积（Bandwidth-Delay Product, BDP）,BDP 表示某一时刻的在外数据量，但是确定一个连接的 BDP 也是一个难点。 拥塞控制经典算法当连接建立之初，还无法获知可用的连接资源，也无法确定 cwnd 初始值（有例外，就是之前文章里提到的目的度量）。这时候不应该直接大量快速的向网络中发送数据，因为会造成更严重的网络拥堵。获得 cwnd 最佳值的唯一方法就是以越来越快的速度发包，直到有数据包丢失（或网络拥堵）。可以考虑慢启动发送。在讨论具体算法之前，需要先了解数据包守恒的概念。 TCP 发送端的拥塞控制行为是由 ACK 的接收来驱动或“控制”的。并且链路的传输能力是固定的，当发送方接收到一个 ACK 时，就表示链路上多了一个“空位”，于是发送方可以再发送一个数据包。数据包守恒就是指链路中最大包的数量守恒。 慢启动当一个连接刚启动时，或者检测到重传超时导致的丢包时，需要执行慢启动； TCP 长时间处于空闲状态也可能触发慢启动。其目的是探寻到 cwnd 值已经帮助 TCP 建立 ACK 时钟。 TCP 发送一定数目的报文开始慢启动，该数目称为初始窗口（IInitial Window，IW）。为了简便，我们讨论 IW 为一个 SMSS （sender’s MSS）的情况。意味着初始 cwnd 大小为 1 SMSS。 假设没有丢包且每一个数据都有相应的 ACK。那么第一个 ACK 到达，说明可以再发送一个新的报文段（数据包守恒），每收到一个“好的” ACK，cwnd = cwnd + min(N, SMSS)，这里的 N 是指那个“好的” ACK 所确认的字节数。所谓“好的”是指 ACK 号使窗口更新了。 因为通常来说 N 的值等于 SMSS，使得 cwnd 在收到一个 ACK 后增大一倍。所以慢启动实际上是以指数增长，在 K 轮之后，cwnd = 2^K。如下图： 当接收方开启延时 ACK，则发送方 cwnd 增长曲线如图中蓝色曲线，虽然起步看起来慢，但仍是指数增长。当然这对于带宽延时积很大的网络来说，确实有所浪费，应该采用更好的办法。 当然不可能让窗口大小无限增长，否则会造成严重的网络拥堵直至网络瘫痪。在上述情况下，cwnd 将大幅减小（减至原值一半），也是慢启动和拥塞避免的转折点，与慢启动阈值（slow start threshold, ssthresh）有关。 避免拥塞当 cwnd 达到 ssthresh 时，可能还有一些传输资源未被占用。但这时候需要谨慎的试探，不能再以较快速度增大 cwnd。采用避免拥塞算法，每接收到一个新的 ACK，cwnd 会做以下更新： ​ cwnd = cwnd + SMSS * SMSS / cwnd 假设 cwnd = k * SMSS，则可推导如下： ​ cwnd = cwnd + SMSS / k 发包来看像这样： 通常认为拥塞避免阶段 cwnd 呈线性增长，称为累加增长。 慢启动 和 拥塞避免 的选择通常 TCP 连接总是会选择慢启动和拥塞避免中的一个，依据就是之前提到的慢启动阈值。当 cwnd &lt; ssthresh，采用慢启动算法， cwnd &gt; ssthresh 采用拥塞避免，相等时选择任意都行。所以关键就是 ssthresh 的值，该值并不是固定的，它的主要目的是，记录上一次最好的窗口估计值。 ssthresh 初始值可以任意设定（如 awnd 或更大），这通常会使 TCP 总是以慢启动开始。当出现重传，无论是超时重传还是快速重传，都会导致 ssthresh 值更新如下： ​ ssthresh = max(在外数据值 / 2, 2 * SMSS) 在外数据值其实就是当前窗口大小。这样通常会使 ssthresh 变小（但也可能使其变大），然后触发拥塞避免。 Tahoe、Reno、快速恢复 、 标准 TCP 接下来讨论的几个算法是将慢启动和拥塞避免结合使用，并且实现一些优化。 Tahoe 算法规定当重传时，都会进入慢启动，并且丢包时，将 cwnd 设为 1 SMSS。这显然性能不太好，已被弃用，不用深究。 Reno 算法是标准 TCP 的基础，它根据之前提到的“包守恒”实现了快速恢复，较好的利用了带宽。快速恢复是针对快速重传的情景实现的，来看一下它在标准 TCP 中的使用： TCP 连接之初采用慢启动，cwnd = 1 SMSS 每收到一个好的 ACK，cwnd 就会相应更新： cwnd += SMSS (cwnd &lt; ssthresh ) cwnd += SMSS * SMSS / cwnd (cwnd &gt; ssthresh) 收到三次冗余 ACK时，执行以下行为： 更新 ssthresh 启动快速重传算法，将 cwnd 设为 ssthresh + 3 * SMSS（依据包守恒，因为已经有三个包已经收到） 每收到一个冗余 ACK，再将 cwnd 增加 1 SMSS 当收到一个好的 ACK，说明已经恢复正常，则将 cwnd 重新置为 ssthresh 注：以上 2、3 步构成了快速恢复,如图： 以下是 Reno 的状态转换图： NewRenoReno 算法在同一窗口下丢失多个包时，其中一个包快速重传成功，就会停止 cwnd 膨胀，造成其它丢失的包可能触发超时重传，然后 cwnd 降为 1 SMSS，吞吐量大大降低。NewReno 采用了一个“恢复点”，指的是收到的 ACK 号大于已发送包的序列号的最大值，达到这个恢复点，才会退出快速恢复。下图最右图中， ACK11 达到了恢复点。 限制传输限制传输策略对 TCP 做了微小改进，主要是为了解决窗口较小时，出现丢包，但是没有足够的包去引发快速重传/快速恢复机制。为了尽快触发快速重传，每接收两个连续重复 ACK，就发送一个新的包，使网络中的数据量维持一定数量。这是 TCP 推荐策略。 拥塞窗口校验发送端受限 发送端可能出现发送受限， cwnd 的值就会变的不那么准确。 空闲阶段（idle period）：发送端暂时没有发送的需求，并且之前发送的数据都已经收到 ACK 应用受限（application-limited period）：发送方实际发送的数据小于 cwnd，并且可能仍有 ACK 未收到 这里对应 TCP/IP 详解卷一里，书上对于“应用受限”说法不正确。书上说此时“无法发送”，但是查阅 rfc 原文如下： 1&quot;application-limited period&quot; for the time when the sender sends less than is allowed by the congestion or receiver windows. CWV拥塞窗口校验（Congestion Window Validation）机制规定，需要发送新数据时，距离上次发送操作超过一个 RTO，如果是： 空闲阶段： ssthresh = max(ssthresh, 0.75 * cwnd) 每隔一个 RTT，cwnd 减半，但不小于 1 SMSS 应用受限： 实际使用的窗口大小记为 W_used ssthresh = max(ssthresh, 0.75 * cwnd) cwnd = (cwnd + W_used) / 2 在长时间发送暂停后，cwnd 低于 ssthresh，再次发送时会进入慢启动。Linux 默认开启 CWV。 伪 RTO 处理 —— Eifel 算法在之前的超时重传里，我们提到了 伪超时，再来回顾下(注意下图是相当简易的情形，没有考虑延时 ACK 以及 cwnd 增长，会意即可)： 伪超时可能引起“回退 N 步”的行为，并且可能触发快速重传，浪费不少资源。 Eifel 检测算法该算法利用 TCP 的 TSOPT 选项，在发送生超时后，重传报文并记录 TSV，期待一个 ACK，若 ACK 的 TSER 小于重传报文的 TSV，则认为该 ACK 是对原始报文的确认而不是对重传报文的确认，即认定该重传是伪重传。 Eifel 响应前面提到过，发生超时，则 ssthresh 减半，cwnd 降为 1 SMSS。发生伪超时的话，在 RTO 之后到来的 ACK 会使 cwnd 快速变大，但仍会有不必要重传。 采用 Eifel 算法，在判定伪超时后，会撤销对 ssthresh 的修改。在每次超时对 ssthresh 修改之前，会用 pipe_prev 变量来保存当前的 ssthresh，以便撤销修改。 若出现伪重传，当 ACK 到达时，假设 ACK 确认的报文段长度为 A： cwnd = 在外数据值 + min(A，IW) ssthresh = pipe_prev 窗口缩减行为前面讨论了当失序或者超时的时候 TCP 的行为，这些行为都是通过 ACK 的反馈来触发或者驱动的，换句话说，这些“拥塞”的情况是“猜出来的”。当明确知道发生拥堵了，TCP 会执行拥塞窗口缩减（congestion window reducing，CWR）。明确知道拥堵的情况主要有两种： 收到携带了 ENC-Echo 的报文，由路由器给出的网络拥堵信息 本地拥堵，上层应用发送速率大于下层协议发送速率 CWR 处理过程如下： ssthresh = cwnd / 2 cwnd = min(cwnd, 在外数据值 + 1) 每收到 2 个 ACK，将 cwnd 减 1 直到 cwnd 达到新的 ssthresh 值或者由于其他原因（如丢包）打断 CWR。 拥塞控制状态机 这部分内容 TCP/IP 详解卷没有，是从这篇论文里总结的，希望能够帮助理解拥塞控制状态。 到此，我们总结一下 TCP 拥塞控制的几个重要状态： Open —— 未出现超时或者失序，按照慢启动或者避免拥塞正常处理 ACK Lost —— 出现超时重传 DisOrder —— 失序 Recover —— 快速重传引发的快速恢复 CWR —— 明确拥塞时的窗口缩减状态，可打断 缓冲区膨胀这个问题还是很有趣的，所以拿出来讲一下。先说结论，网络设备的缓冲区并不是越大越好，也不是越小越好，而是需要根据链路速率和RTT进行计算，得到一个经验值。 缓存区过小缓冲区过小的问题很明显，如果缓冲区太小，很容易就被写满了，只要不能进行适当的排队，丢包率会高，导致传输效率差。 缓存区过大假设如下场景： 上图中，我们假设中间的路由设备的buffer极大，理论来说无论来多少数据，都能buffer起来。中间的路由设备，接收速率是1M/s，而发送速率只有10k/s。 到某一时刻，发送方认为某一数据超时丢失（实际上没有丢失，而是在缓冲区没来得及处理），于是重发，导致缓存区有冗余数据。大量的冗余数据导致利用率变得极低。 而缓冲区为正常大小的时候，多的数据会被丢弃，过一会而缓冲区有新的位置，新的数据会到来，接收方收到数据是失序的，于是发送冗余 ACK，促进快速重传，反而使链路利用率得到保障。 与拥塞控制相关的攻击大多数攻击是强迫 TCP 发送速率比一般情况更快或更慢。 ACK 分割攻击原理是接收方将原来的确认范围划分成很多小块，把一个 ACK 变成多个 ACK，使得发送方不断增大 cwnd，使网络变的拥堵。可以通过计算每个 ACK 的确认量（而不是一个包）来判断是否是正确的 ACK。 乐观响应攻击接收方对还没到达的数据进行提前确认，使得 RTT 变得比较小，同样使得发送方不断增大 cwnd。可以采用一个可累加的随机数，动态匹配 ACK。 Reference rfc Congestion Control in Linux TCP ​]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 数据流与窗口管理]]></title>
    <url>%2Fnetwork-protocol%2Ftcp_window_management.html</url>
    <content type="text"><![CDATA[TCP 数据流与窗口管理交互式通信ssh 是一个典型的交互式通信协议，它是加密了的，通常每次按键都会生成一个单独的包。另外，ssh 会在服务端对客户端输入的字符进行回显。因此，服务端收到数据包会先发送一个 ACK，然后发送一个回显报文，再由客户端发送对回显报文段的 ACK，如下左图。 但通常第二段和第三段可以合并来减少传输次数，这种方法称为捎带延时确认，如上右图。我们可以再来看看 wireshark 抓的包: 不难发现，这些包三个为一组，先是客户端(192.168.0.120)发送一个加密的包，然后收到服务端一个加密包，然后客户端回复一个 ACK。看一下服务端发过来的包： 可以看到，标志位的 ACK 置为了 1，ACK 值为 145，PSH 位也置为了 1（表明收到后立刻返回给应用层），并且数据段不为空，说明包含了回显的部分。很明显这里采用了捎带延时确认。 延时确认在很多情况下，TCP 累计确认可以允许延迟一小会儿发送 ACK，以便结合相同方向的数据一起传送。但是显然，TCP 不能延时任意时长，通常建议：TCP 实现延迟应小于 500 ms，实践中延时应小于 200 ms。该延时值是可以配置的可选值如下：禁用延时，始终延时，每隔一个包回复一个 ACK，自动确认时间；默认值为 3。 Nagle 算法通常在类似于 ssh 这样的应用里，每次传输的数据包非常小，称为微型报文，这些报文会造成相当高的传输代价。可以采用 Nagle 算法来解决这类问题。 Nagle 算法规定，当一个 TCP 连接有在传数据时，小的报文段（长度小于 SMSS）不会被发送，直到所有在传数据都收到 ACK。并且收到 ACK 后，会收集小数据并整合到一个报文段发送。 下图为 ssh 应用中没有开启 Nagle 算法（左图）和开启 Nagle 算法（右图）的差别。 可以看到，没有开启时，同一时刻有很多包在传输，并且有很多小包（tinygram），总体时间短，但是网络负担大。开启了 Nagle 算法时，同一时刻只有一个方向的传输，并且在合适的情况下，合并小包一起发送，时间较长，但传输次数少，网络负担小。 延时 ACK 与 Nagle 结合无论是延迟 ACK 还是 Nagle 算法，其目的都是减少网络中传输的包，减轻网络负担。但是二者一起使用时，可能会出现问题。 考虑如下情况：客户端依次要发送一个全长报文段以及若干个小包，服务端收到第一个全长包，然后延迟发送 ACK（延时，或者期待第二个全长报文段到达），而客户端采用了 Nagle 算法，需要等到 ACK 到达才能继续发送。这样就会形成一个短暂的死锁，性能反而变差。所以在有些情况下，如 ssh ，可以禁用 Nagle 算法。 流量控制与窗口管理 每个 TCP 报文段的首部里都包含了一个窗口大小字段，该字段占 16 位，最大表示 65536，也就是 64 KB，但 TCP 选项中的窗口缩放选项可以让它表示更大的窗口。 一般来说每个连接的接收端会有一个大小固定的缓存，用来暂存发送端发来的数据，然后由应用程序读取。当应用程序来不及处理缓存数据，而发送方又不停的发送数据，超出缓存大小，就会造成数据丢失和不必要的重传。窗口大小字段用于 TCP 的流量控制，用于表示接收端可用缓存大小。 滑动窗口发送窗口每个 TCP 连接的两端都维护了一个发送窗口，结构如下： 主要分四部分：已经发送并收到确认、已经发送但未收到确认、未发送但可以发送、未发送并且目前不能发送。第三部分称为可用窗口，第二部分和第三部分合称发送窗口。随着时间推移，窗口可以有几种运动： 关闭：随着 ACK 到来，发送窗口左边界向右移，窗口减小。 打开：窗口右边界右移，即接收方可用缓存增大，发送方可用窗口也就增大。 收缩：右边界左移，主机不支持这种做法，但 TCP 必须能处理这种问题。 接收窗口除了发送窗口，接收方还维护了一个接收窗口。 接收窗口结构简单，包括已经接收且已经回复 ACK、允许对方发送但还未收到、目前不允许对方发送的部分。 控制流程接收方收到一个数据包后，返回一个 ACK，根据自己的可用接收缓存大小设置 ACK 报文里的窗口大小。发送方收到这个窗口通告后，根据可用窗口大小调整自己的发送窗口，以达到调节发送速率的目的。 零窗口与 TCP 持续计时器当发送方不停发送，接收方又比较忙的时候，可能会导致可用窗口大小为 0。当出现零窗口时，发送方收到一个 ACK 报文，其中的窗口大小为零，那么就表示暂时不能发送数据。而当接收方应用程序开始处理收到的数据，使得接收缓存里又有了空间，但是我们知道，窗口通告是包含在 ACK 报文里的，没有收到新的数据，就没法发送窗口通告，这时就会造成死锁。 所以当出现零窗口时，发送方会采用一个持续计时器间歇地查询接收端是否有可用窗口，持续计时器会触发窗口探测（window probe）的传输。为了保证对方能够收到查询，我们必须要往数据段放一些数据，以保证超时重发，通常会放一个字节的数据 。接收方收到窗口探测后，会被强制返回一个 ACK，并且包含自己当前可用窗口大小（这个大小会有特殊情况）。注意这里采用指数退避来计算持续计时器的超时时间。 前面谈到，大量数据量较小的包会造成传输速度的下降，也会造成网络负担。当接收端可用缓存从 0 慢慢增大到一个较小的值，这时候收到一个窗口探测，为了避免发送较小的包，接收端可以仍然在 ACK 中回复一个零窗口。 糊涂窗口综合征当发送方发送的报文大小不固定时，可能会出现糊涂窗口综合征（Silly Window Syndrome，SWS）。当出现该问题时，交换的报文数据段大小较小，耗费的资源较多。 TCP 连接两端都可能导致 SWS：当接收端的通告窗口较小（或者是还没等到窗口变得够大），或者发送端发送的包较小（或者是没有等待其他小数据组合成大数据包）。为了避免 SWS，发送方要遵循一定规则。 对于接收方： 不应通告小的窗口值。在窗口增至 min(MSS，接收端缓存的一半) 之前，不能通告比当前窗口（可能为 0）更大的值 对于发送方，满足任意一个： 全长报文段可以发送 数据段长度 &gt;= 最大窗口通告的一半 该连接禁用 Nagle 算法 没有未经确认的在传数据 大容量缓存与自动调优在相似的环境下，较小的接收缓存的 TCP 应用吞吐性能会较低。很多 TCP 协议栈中上层应用不能指定接收缓存大小，由操作系统来指定一个固定的或者动态变化的值。]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 超时重传]]></title>
    <url>%2Fnetwork-protocol%2Ftcp_retransmission.html</url>
    <content type="text"><![CDATA[##TCP超时重传 TCP 提供可靠数据传输服务，为保证传输正确性，TCP 重传其认为已经丢失的包。TCP 有两套重传机制，一是基于定时器（超时），二是基于确认信息的构成（快速重传）。 ###基于计时器的重传 简单的超时重传 图中黑色那条就是因为定时器超时仍没有收到 ACK，所以引起了发送方超时重传。实际上 TCP 有两个阈值来决定如何重传同一个报文段：一是愿意重传的次数 R1、二是应该放弃当前连接的时机 R2。R1 和 R2 的值应分别至少为 3 次和 100 秒，如果超过任何一个但还没能重传成功，会放弃该连接。当然这两个值是可以设置的，在不同系统里默认值也不同。 那么如何设定一个合适的超时的值呢？假设 TCP 工作在静态环境中，这很容易，但真实网络环境不断变化，需要根据当前状态来设定合适的值。 超时时间 RTORTO（retransmission timeout）一般是根据RTT（round trip time）也就是往返时间来设置的。若 RTO 小于 RTT，则会造成很多不必要的重传；若 RTO 远大于 RTT，则会降低整体网络利用率，RTO 是保证 TCP 性能的关键。并且不同连接的RTT不相同，同一个连接不同时间的 RTT 也不相同，所以 RTO 的设置一直都是研究热点。 所以凭我们的直觉，RTO 应该比 RTT 稍大： ​ RTO=RTT+Δt 那么，RTT 怎么算呢： ​ SRTT=(1−α)×SRTT+α×RTTnew SRTT(smooth RTT)，RTTnew 是新测量的值。如上，为了防止 RTT 抖动太大，给了一个权值 a ，也叫平滑因子。a 的值建议在 10%~20%。举个例子，当前 RTTs=200ms，RTTs=200ms，最新一次测量的 RTT=800ms，RTT=800ms，那么更新后的 RTTs=200×0.875+800×0.125=275ms，RTTs=200×0.875+800×0.125=275ms. Δt如何得到呢？RFC 2988 规定： ​ RTO=SRTT+4×RTTD 因此，按照上面的定义，Δt=4×RTTD. 而 RTTD 计算公式如下： ​ RTTD=(1−β)×RTTD+β×|SRTT−RTTnew| 实际上，RTTD 就是一个均值偏差，它就相当于某个样本到其总体平均值的距离。这就好比你的成绩与你班级平均成绩差了多少。RFC 推荐 β=0.25。 退避指数根据前面的公式，我们可以得到 RTO。一旦超过 RTO 还没收到 ACK，就会引起发送方重传。但如果重传后还是没有在 RTO 时间内收到 ACK，这时候会认为是网络拥堵，会引发 TCP 拥塞控制行为，使 RTO 翻倍。则第 n 次重传的 RTOn 值为： ​ RTOn=2^(n−1)×RTO1 下图是一个例子： 如上，在时间为0.22531时开始第一次重传，此后重传时间开始指数增大，（在尝试了8次后停下，说明其 R2 的值可能为8）。 带时间戳的 RTT 测量前面说了 RTO 的公式，它和 RTT 有关，那么每一次的 RTT 是如何得到的呢？在之前 TCP 连接管理的时候讲过，TCP有一个 TSOPT (timestamp option) 选项，它包含两个时间戳值。它允许发送者在报文中带上一个32比特的时间戳值（TSV），然后接收方 将收到的值原封不动的填入 ACK 报文段中 TSOPT 选项的第二部分，时间戳回显字段（TSER）。发送方收到 ACK 以后，将当前时间戳减去 TSOPT 选项的 TSER 就可得到精确的RTT值。 但是这里有很微妙的细节：接收方在收到数据包后，并不是立即发送 ACK，通常会延时“一小会儿”，多等待几个数据包后返回一个累积 ACK。此时接收方将确认时间最近的报文段的 TSV 填入 TSER 发送给发送方。 重传二义性与 Karn 算法还有另一个重要的细节，如果测量 RTT 的样本出现了超时重传，但是我们收到了 ACK 时无法分辨是对哪一次的确认，这时候 RTT 的值可能是不正确的。 因此，Karn 算法规定：此时不更新 RTTnew 的值。并且如果发生再次重传，则采用退避后的 RTO 的值，直到发送成功，退避指数重新设定为 1 。 丢包和失序的情况假设有三个数据包依次发送，1号和3号先到达，2号数据包由于网络因素最后到达。接收方收到3号时，会发送一个1号的冗余 ACK，然后2号到达，此时会发送一个3号的累积 ACK 表明这三个到达。在这个例子里，3号 ACK 并没有立即返回，发送方收到3号的 ACK 后，根据其 TSER 计算此时的 RTT，就会导致发送方过高的估计 RTT，降低重传积极性，使得 RTO 相应增大，当然这在失序时是有好处的，因为过分积极会导致大量的伪重传。 伪超时与重传如下图，在发送第四个 ACK 后出现延迟高峰，导致发送方在 RTO 时间内没有收到 5 ~ 8 的 ACK，于是发生重传，然后之前的 ACK 到达，于是又依次发送 6 ~ 8，就导致了不必要的重传。可以用 Eifel 算法来解决（略）。 目的度量从前面可以看出，TCP 可以学习链路特征，如 RTT、SRTT 等，但一旦连接关闭，这些信息就会丢失。即使相同的接收方与发送方建立新的连接，也必须从头开始“学习”。较新的 TCP 实现维护了这些值，在 Linux 中可以通过如下命令查看： 1ip route show cache [ip] ###基于确认信息的重传 快速重传在大多数情况下，计时器超时并触发重传是不必要的，也不是期望的，因为 RTO 通常是大于 RTT（约2倍或更大），因此基于计时器的重传会导致网络利用率降低。 首先我们要知道，接收方收到失序报文段时，应立即生成确认信息（重复 ACK），以便发送方尽快、高效地填补空缺。而发送方在收到重复 ACK 时，无法判断是由于数据包丢失还是仅仅因为延迟，所以发送方等待一定数目的重复 ACK （重复 ACK 阈值，dupthresh），这时可以认为是数据包丢失，即便还未超时，也立即发送丢失的分组。 所以快速重传概括如下：TCP 发送方在观测到至少 dupthresh ( 通常是 3 ) 个重复 ACK，立即重传，而不必得到计时器超时。当然也可以同时发送新的数据。 示例如下： 包失序与包重复失序当然快速重传也会造成一些问题。在轻微失序的情况下(左图)，不会有什么影响。但在严重失序时(右图)，4号数据包延迟到达，接收方发送 4 个冗余 ACK ，让发送方认为 4 号分组丢失，造成伪快速重传。 重复尽管可能性较小，但 IP 协议也可能将单个包传输多次。假如 IP 协议将一个包传输了 4 次，然后发送方接收到 3 个冗余 ACK ，也会让发送方以为分组丢失，导致伪快速重传。 带选择确认的重传在上一篇文章中提到过 TCP 的 SACK 选项，它通过若干个 SACK 块来帮助发送方知道接收方有哪些空缺，可以减少不必要的重传。 接收端的 SACK 行为接收端在 TCP 连接建立期间收到 SACK 选项即可生成 SACK。通常来说，当收到失序报文段，接收方就会生成 SACK。 第一个 SACK 块包含的应该是最近收到的报文段的序列号范围。由于 SACK 选项空间有限，应尽可能向发送方提供最新信息。其余的 SACK 按先后顺序依次排列，也就是说，该 ACK 报文段除了包含最新接收的序列号信息，还应重复之前的 SACK 信息。这是因为 ACK 报文段是没有重发机制的，可能会丢失，重复提高了其鲁棒性。 发送端的 SACK 行为发送方应该充分利用 SACK 信息来进行重传，称为选择性重传。发送方记录累积 ACK 信息和 SACK 信息，当接收到相应序列号范围内的 ACK 时，在其重传缓存中标记该报文段重传成功。]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node 异步 I/O]]></title>
    <url>%2Funcategorized%2Fnode_async_io.html</url>
    <content type="text"><![CDATA[这篇文章主要讲 nodejs 中的异步 IO，关于同步、异步、阻塞、非阻塞 请移步这里。 事件循环 和 消息队列我们常说“JavaScript是单线程的”。 所谓单线程，是指在JS引擎中负责解释和执行JavaScript代码的线程只有一个。不妨叫它主线程。 但是实际上还存在其他的线程。例如：处理AJAX请求的线程、定时器线程、读写文件的线程等等。这些线程可能存在于JS引擎之内，也可能存在于JS引擎之外，在此我们不做区分。不妨叫它们工作线程。 node 执行过程 处理并执行完 js 代码，main函数继续往下调用libuv的事件循环入口uv_run()，node进程进入事件循环。 uv_run() 的 while 循环做的就是一件事，判断 default_loop_struct 是否有存活的 io 观察者 或 定时器。 事件循环 事件循环是指主线程重复从消息队列中取消息、执行的过程 事件循环对应上图 3 号标注的部分。用代码表示大概是这样的： 1234while(true) &#123; var message = queue.get(); execute(message);&#125; 如上图，每一次执行一次循环体的过程称为 Tick。 事件循环的阶段： 123456789101112131415161718 ┌───────────────────────┐┌─&gt;│ timers │ 执行定时器(setTimeout/setInterval)注册的回调函数，也是进入事│ └──────────┬────────────┘ 件循环第一个阶段。│ ┌──────────┴────────────┐│ │ I/O callbacks │ I/O 事件相关联的回调或者报错会在这里执行│ └──────────┬────────────┘│ ┌──────────┴────────────┐│ │ idle, prepare │ 内部使用，不讨论│ └──────────┬────────────┘ ┌───────────────┐│ ┌──────────┴────────────┐ │ incoming: │ 最重要的一个阶段，I/O 观察者观察到线程池│ │ poll │&lt;─────┤ connections, │ 里有任务已经完成，就会在这里执行回调。│ └──────────┬────────────┘ │ data, etc. ││ ┌──────────┴────────────┐ └───────────────┘│ │ check │ 专门用来执行 setImmediate() 的回调│ └──────────┬────────────┘│ ┌──────────┴────────────┐└──┤ close callbacks │ 一个连接或 handle 突然被关闭，close 事件会被发送到这里执行回调 └───────────────────────┘ 如上图，共有六个阶段（官方称为 phase）。特别要说明的是 poll 阶段，在这个阶段，如果暂时没有事件到来，主线程便会阻塞在这里，等待事件发生。当然它不会一直等下去： 它首先会判断后面的 Check Phase 以及 Close Phase 是否还有等待处理的回调. 如果有, 则不等待, 直接进入下一个 Phase. 如果没有其他回调等待执行, 它会给 epoll 这样的方法设置一个 timeout. 可以猜一下, 这个 timeout 设置为多少合适呢? 答案就是 Timer Phase 中最近要执行的回调启动时间到现在的差值, 假设这个差值是 delta. 因为 Poll Phase 后面没有等待执行的回调了. 所以这里最多等待 delta 时长, 如果期间有事件唤醒了消息循环, 那么就继续下一个 Phase 的工作; 如果期间什么都没发生, 那么到了 timeout 后, 消息循环依然要进入后面的Phase, 让下一个迭代的 Timer Phase 也能够得到执行. 来看一下流程： 到这里你一定发现少了一些问题：process.nextTick() 和 Promise 都是异步的，它们对应以上哪个阶段呢？往下看 任务队列12341、运行主线程（函数调用栈）中的同步任务2、主线程（函数调用栈）执行到任务源时，通知相应的webAPIs进行相应的执行异步任务，将任务源指定的异步任务放入任务队列中3、主线程（函数调用栈）中的任务执行完毕后，然后执行所有的微任务，再执行宏任务，找到一个任务队列执行完毕，再执行所有的微任务4、不断执行第三步 任务队列也叫消息队列。主要分两类任务：宏任务(macro-task)、微任务(micro-task) 宏任务：setTimeout setInterval setImmediate I/O 微任务：process.nextTick Promise 的回调 在上面的图中，各个 phase 完成了宏任务对应的事件。微任务的执行时机在每一次进入下一个阶段之前，process.nextTick 优先级大于 Promise 的回调。 FAQsetTimeout 和 setImmediate 的比较12setImmediate(() =&gt; console.log(2))setTimeout(() =&gt; console.log(1)) 这段代码的结果实际上是不确定的。可是，为什么？按照流程图，应该是 timer 先于 check 阶段，所以应该是 setTimeout 先执行，可是为什么结果不是这样呢？首先我们要知道： 1setTimeout(fn) ==&gt; setTimeout(fn, 0) ==&gt; setTimeout(fn, 1) 上面三个效果是一样的！前两个好理解，给定的默认值是0。其实在 node 源码中，最低为 1 ms，官方文档如下： 1When delay is larger than 2147483647 or less than 1, the delay will be set to 1. 所以当进入 timer 阶段时，1ms 可能超时也可能没有，这个影响因素有很多。如果还没超时，则进入下一个 phase，依次往下，所以先输出 2 。如果已经超时，则先输出 1。 但是！如果它们在 I/O 事件回调中，那么输出顺序是固定了的，如下 12345require('fs').readFile('path.txt', () =&gt; &#123; setImmediate(() =&gt; console.log(2)) setTimeout(() =&gt; console.log(1))&#125;);// 输出: 2 1 如果不知道为什么，答案就在循环图中。 (完) Reference The Node.js Event Loop, Timers, and process.nextTick()]]></content>
      <tags>
        <tag>JavaScript</tag>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 连接管理]]></title>
    <url>%2Fnetwork-protocol%2FTCPConn.html</url>
    <content type="text"><![CDATA[TCP 连接的建立和终止一个TCP连接由一个四元组构成：源IP、源端口、目的IP、目的端口。一个连接通常分为三个阶段：启动、数据传输（也称“连接已建立”）、关闭。以下是建立连接是三步握手和关闭时四步挥手的过程。 握手： 客户端先发一个SYN（synchronous）报文段，并指明客户端的初始序列号（Initial Sequence Number），图中值为ISN(c)。（注意这里可能出现超时或报文丢失的情况） 服务端收到后返回一个ACK（acknowledgement）,并指明ACK确认号的值为ISN(c) + 1来表明已经收到Seq值为ISN(c)的SYN报文段。服务端在同一个报文段还发送了一个SYN并指明自己的初始序列号ISN(s). 客户端收到ACK+SYN，发送ACK向服务端确认收到来自服务端的SYN，并指明Seq=ISN(s) + 1. 重要的细节：对于client来说，第三步似乎是多余的，但是对服务端来说，是一个防止SYN泛洪攻击的手段：服务端在建立连接后需要为该连接分配变量和内存，如果没有第三步，恶意客户端通过不停伪造IP和端口发起SYN（客户端没有太大内存消耗），导致服务端不停分配变量，最后内存消耗完崩溃。所以第三步可以让服务端辨别恶意客户端。 ######挥手： 关闭发起者（TCP连接是双向的，任何一方都可以主动断开连接）向另一方发送一个FIN（final）段表示要开始关闭连接。此时的ACK值是确认最近一次发来的数据。 被动方接收FIN，发回一个ACK。 被动方向发起方发送一个FIN，同时再次确认之前的FIN，ACK和上次相同。 发起方收到FIN，发回ACK 挥手断开这里同样有很多重要细节： 前两步完成后，发起方到被动方的连接已经关闭，但TCP是双向的，此时由于被动方还没有发送FIN，所以被动方到发起方的连接还打开着，TCP连接目前处于半关闭状态，此时被动方仍然可以向发起方发送数据，发起方也可以正常接受数据。但是如果被动方既不再发送数据，也不发送最后的FIN，就会出现问题。所以发起方收到FIN的ACK时，设置了一个定时器，在规定时间内没有数据发过来，就自动断开连接。 另一个问题是，如果发起方发送了最后一个ACK用于确认被动方的FIN之后立刻关闭，但是此ACK超时未达或者丢失了，就会造成问题—被动方的FIN得不到确认。这时被动方会在超时后重新发送FIN，直到收到ACK为止。所以发起方发送完最后一个ACK后不能马上离开，而要等一段时间，用于确保对方收到ACK，这段时间叫静默时间，并且这个时间是强制的。静默时间大小一般为2*MSL（Max Segment Lifetime,报文段在被丢弃前允许的最长存活时间）所以它还有另一个重要的作用，就是让属于这个已经关闭连接的报文段过期，以免相同的客户端和服务端再次建立连接时受到之前已经关闭连接的影响。 TCP FSM以下是TCP三步握手和四步挥手的有限状态机。应该掌握。 TCP 选项TCP有若干选项，每个选项的头一个字节表示“种类”，指明了选项的类型。 MSS 最大段大小选项Max segment size。当一条TCP连接建立时，通信双方都要在SYN报文段的MSS选项说明自己允许的最大段大小。注意最大段大小不是双方协商的结果，而是表明自己不愿意接收任何大于该尺寸的报文段。 SACK 选择确认段Select ACK。在滑动窗口中，TCP采用累计ACK确认，不能正确的确认已经收到的但是是失序的报文段，接收方的数据队列就会出现空洞。SACK能够使发送方了解到空洞出现并进行更有效的重传工作。通过接收SYN报文段中的“允许确认选项”，TCP通信方会知道自身拥有了发布SACK的能力。SACK选项由n个SACK块构成，每个SACK块是一对32位的序列号（a，b），表明已经接受a到b的数据。 WSOPTWindow scale option。窗口本来大小只有16位，若wsopt值为s，则窗口大小为16*2^s,最大值为1G #####TSOPT timestamp option。发送方发出的报文段带有发出时的时间戳，接收方收到后将该值写入ACK报文段发回给发送方。发送方据此可以精确地计算RTT（round trip time）。同时该选项还可用于防回绕：假如存在一个过期了的报文段恰好和下一次要接受的报文段序列号相同，这时候可以通过时间戳来判断，如果该报文时间戳小于最近一次收到的报文段，说明改报文段是过期了的。 TCP服务器选项TCP服务端会为每一个客户端分配一个新的进程或线程，这样负责监听的服务器就能始终准备着处理下一个到来的连接请求。但是如果服务器正在创建一个新进程（线程）时有更多的连接到来，应该如何处理？ 在被用于应用程序之前，新的连接可能会有两种状态：1、SYN_RCVD 状态 2、 ESTABLISHED 状态 但未被应用程序所接受。 TCP为这两种状态的连接准备了两个队列，可以通过限制它们的大小来管理连接。 当一个SYN报文段到达，将会检查SYN_RCVD队列是否已满（Linux中默认为1000），未满则加入队列，否则拒绝连接。 ESTABLISHED状态的队列通常被称为未完成连接（backlog，虽然叫未完成，但是三次握手已经完成，只是还没被应用程序处理），backlog队列最大长度默认为128 如果backlog队列未满，则会根据SYN_RCVD队列应答SYN并完成握手，握手完成后，加入backlog队列，由负责监听的服务器依次分配线程。注意当客户端发送ACK后，会认为服务端已经做好接收数据的准备来，所以会立即发送数据，但此时连接可能还处于backlog队列，还未被应用程序处理，所以TCP还有一个专门的数据队列。 如果backlog已满，则会延迟应答SYN。正常的TCP机制里，客户端会等待SYN超时，但在Linux客户端中，既不超时也不重置。]]></content>
      <categories>
        <category>network protocol</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node 模块机制]]></title>
    <url>%2Funcategorized%2Fnode_commonJS.html</url>
    <content type="text"><![CDATA[node 模块机制模块引用示例代码如下： 1const fs = require("fs"); 在 CommonJS 规范中，require 接受一个模块标志，以此引入模块的 API。 模块提供了 exports 对象来导出方法或变量，另外还有一个 module 对象，该对象即模块本身，而在 nodejs 中，文件就是模块。在 module 对象上有一个 module.exports 属性，这是其导出的内容，变量 exports 指向的地址就是 module.exports。也就是说： 1module.exports === exports 这里注意，可以在 exports 上添加属性或方法来导出，但不可修改 exports 本身的值，因为改了以后，exports 不在指向 module.exports, 也就不会被导出。如果想要导出一个类，可以： 1234let A = &#123;&#125;A.prototype.foo = foo;...module.exports = A; node 模块实现 node 会将加载过的模块放入缓存，下次引用直接从缓存加载。 路径分析 和 文件定位 核心模块，如 fs 、path、http 等，直接引用模块名。node 启动时就已经加载到内存，加载速度最快 “.” 或”..”开头，相对路径查找，知道路径，查找快，但仍需动态加载，速度稍慢 “/“开头，从根目录查找，同上 自定义模块，根据 module.paths 变量递归向上查找 node_modules 目录 文件定位 require 查找模块时，需要 fs 模块同步阻塞的判断是否存在。 require 时一般不需要指定文件后缀名，但也可以加上。如果没有后缀，node 会依次在对应路径查找 .js、.json、.node。如果是后两种，加上后缀名查找会稍快。 很可能最后找不到对应的.js、.json、.node文件，但找到的是一个目录。则会查看该目录package.json下main 项对应的值。示例如下: 123456"version": "1.0.0", "description": "", "main": "webpack.config.js", "scripts": &#123; "test": "echo \"Error: no test specified\" &amp;&amp; exit 1" &#125;, 于是找到了 webpack.config.js 文件。如果没有 main 项或者不存在 package.json，则会依次查找 index.js , index.json, index.node。如果仍然没有，就按照 module.path 数组依次递归向上查找。最终找不到，则抛出异常。 模块编译node 中模块定义如下： 123456789101112function Module(id, parent) &#123; this.id = id; this.parent = parent; this.exports = &#123;&#125;; if(parent &amp;&amp; parent.children)&#123; parent.children.push(this); &#125; this.filename = null; //定义时还不能确定该值 this.loaded = false; this.children = [];&#125; 定位到具体文件后，对不同类型的文件操作不一样： .js 文件，通过 fs 模块同步读取后编译执行 .node 文件，这是 c/c++ 写的扩展文件 .json 文件，读取后通过 JSON.parse() 解析并返回结果 每一个编译后的模块都被缓存起来。 javaScript 模块的编译我们前面知道有 require 方法和 exports 对象，可是这些变量和方法在哪里声明的呢？实际上，node 对读取到的 js 文件做了包装： 123(function (exports, require, module, __filename, __dirname) &#123; // module content&#125;); node 读取 js 文件后执行的就是这个包装函数，然后得到 module.exports 。 (待续)]]></content>
      <tags>
        <tag>JavaScript</tag>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang unsafe 包]]></title>
    <url>%2Fgo-sdk%2FGo%20unsafe%20%E5%8C%85.html</url>
    <content type="text"><![CDATA[golang unsafe 包ArbitraryType 和 PointerGo 语言是强类型语言，并且出于安全的考虑，它不允许不同类型的指针互相转换，比如*int不能转为*float64。但是它提供了 unsafe 包来做转换。 12type ArbitraryType inttype Pointer *ArbitraryType 从命名可以看出，ArbitraryType 代表了任意类型，其实，ArbitraryType不是一个真正的类型，它只是一个占位符。而 Pointer 是其指针，并且是一种特殊意义的指针，它可以包含任意类型的地址，有点类似于 C 语言里的void* 指针，全能型的。 ArbitraryType 上有三个函数： 123func Alignof（variable ArbitraryType）uintptrfunc Offsetof（selector ArbitraryType）uintptrfunc Sizeof（variable ArbitraryType）uintptr 与Golang中的大多数函数不同，上述三个函数的调用将始终在编译时求值，而不是运行时。 这意味着它们的返回结果可以分配给常量。（BTW，unsafe包中的函数中非唯一调用将在编译时求值。当传递给len和cap的参数是一个数组值时，内置函数和cap函数的调用也可以在编译时被求值。） uintptruintptr 不是 unsafe 包的一部分，但是它总是和 unsafe 一起用。uintptr 是底层内置类型，用于表示指针的值，区别在于go 语言中指针不可以参与计算，而 uintptr 可以。另外，指针和 uintptr 也是不可以直接转换的。 特别需要注意的是，GC 不会把 uintptr 当成指针，所以由 uintptr 变量表示的地址处的数据也可能被GC回收。 用法及注意事项转换不同类型的指针123func Float64bits(f float64) uint64 &#123; return *(*uint64)(unsafe.Pointer(&amp;f)) &#125; 把指针转换成 uintptr12Converting a Pointer to a uintptr creates an integer value with no pointer semantics//上面说过的，uintptr 没有指针的含义 如下转换： 1234var a int64 = 0pa := &amp;aup := uintptr(unsafe.Pointer(pa))pa = &amp;int64(1) 当 pa 地址改变，uintptr 是不会更新的。且当只有 up 包含了变量 a 的地址，但是 GC 不会把 up 当做指针，所以GC 会回收变量 a 。 uintptr 转指针12p := &amp;T&#123;&#125;p = unsafe.Pointer(uintptr(p) + offset) 这里的 offset 得当的话，可以取到 T 类型中没有导出的值，这也是一个巧妙的用法，但是不推荐。注意这里不能写成这样： 123p := &amp;T&#123;&#125; // 1up := uintptr(p) // 2p = unsafe.Pointer(up + offset) //3 这样非常危险，因为有可能在 3 执行之前，up 这个临时变量被 GC ，最终操作的不知道是哪个内存了。因此不能将 uintptr(p) 保存在变量中。 另外，在 C语言 中我们可以将 offset 设成 T 的长度，然后直接对得到的地址进行操作。但是在 go 语言中是不合法的，可以读取，但不应该操作分配给 T 内存之外的部分，会引发 panic： 1panic: runtime error: invalid memory address or nil pointer dereference 系统调用时转换指针1syscall.Syscall(SYS_READ, uintptr(fd), uintptr(unsafe.Pointer(p)), uintptr(n)) 如上，当系统调用需要一个 uintptr 作为参数，也一定把 uintptr(..) 放在系统调用表达式的参数里，以防止被 GC。在系统调用过程中，不必担心 uintptr 失效，它所持有的对象不会被 GC 。 reflect.Value.Pointer在一些函数的返回值中，也可能出现 uintptr，比如 reflect.Value.Pointer和reflect.Value.UnsafeAddr,对其转换成指针的时候也要注意，不能有中间变量: 12345678p := (*int)(unsafe.Pointer(reflect.ValueOf(new(int)).Pointer()))//// As in the cases above, it is invalid to store the result before the conversion://// INVALID: uintptr cannot be stored in variable// before conversion back to Pointer.// u := reflect.ValueOf(new(int)).Pointer()// p := (*int)(unsafe.Pointer(u)) Summary unsafe包用于Go编译器，而不是Go运行时。 使用unsafe作为程序包名称只是让你在使用此包是更加小心。 使用unsafe.Pointer并不总是一个坏主意，有时我们必须使用它。 Golang的类型系统是为了安全和效率而设计的。 但是在Go类型系统中，安全性比效率更重要。 通常Go是高效的，但有时安全真的会导致Go程序效率低下。 unsafe包用于有经验的程序员通过安全地绕过Go类型系统的安全性来消除这些低效。 unsafe包可能被滥用并且是危险的 涉及到 uintptr 转指针时，一定注意不能有中间变量 (续)question在关于操作不可知内存的时候，会有一些莫名其妙的现象，如下代码是 gocn 上一篇文章里的： 123456789101112131415161718func main() &#123; illegalUseB()&#125;func illegalUseB() &#123; a := [4]int&#123;0, 1, 2, 3&#125; p := unsafe.Pointer(&amp;a) for i := 0; i &lt;= len(a); i++ &#123; *(*int)(p) = 1 fmt.Println(i, ":", *(*int)(p)) // panic at the above line for the last iteration, when i==4. // runtime error: invalid memory address or nil pointer dereference p = unsafe.Pointer(uintptr(p) + 8) &#125;&#125; 运行这段代码，报错如下： 12345670 : 11 : 12 : 13 : 1panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x1 pc=0x100ca32]... 但是比较诡异的情况如下： 12345678910111213func illegalUseB() &#123; a := [4]int&#123;0, 1, 2, 3&#125; p := unsafe.Pointer(&amp;a) for i := 0; i &lt;= len(a); i++ &#123; fmt.Println(i, ":", *(*int)(p)) // panic at the above line for the last iteration, when i==4. // runtime error: invalid memory address or nil pointer dereference p = unsafe.Pointer(uintptr(p) + 8) *(*int)(p) = 1 // 调整了位置 &#125;&#125; 或者如下： 123456789101112131415func illegalUseB() &#123; a := [4]int&#123;0, 1, 2, 3&#125; p := unsafe.Pointer(&amp;a) for i := 0; i &lt;= len(a); i++ &#123; *(*int)(p) = 1 fmt.Println(i, ":", *(*int)(p), (*int)(p)) // 多输出了一个值 // panic at the above line for the last iteration, when i==4. // runtime error: invalid memory address or nil pointer dereference p = unsafe.Pointer(uintptr(p) + 8) &#125;&#125; 这两种情况都不会报错。按理说都是操作了声明变量以外的内存，但是没有向之前一样报错，不知道是什么原因。我的 go SDK 版本是 1.9.1，如果你知道的话麻烦告诉我，谢！]]></content>
      <categories>
        <category>go sdk</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go net/dial.go (II)]]></title>
    <url>%2Fgo-sdk%2FGo%20net%3Adial.go%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E4%BA%8C).html</url>
    <content type="text"><![CDATA[上一篇文章 我们大致分析了dial.go中的代码，起主要的功能就是为真正发起连接做一些准备，起到了应用层的作用（DNS解析等）。但是一个连接完整的连接还需要更深层次的网络协议来完成协作，所以我们接着上篇来分析，由于篇(懒)幅原因，只将dialTcp作为传输层的例子。。。话不多说，上代码： 123456func dialTCP(ctx context.Context, net string, laddr, raddr *TCPAddr) (*TCPConn, error) &#123; if testHookDialTCP != nil &#123; //testHookDialTCP 是语言开发者为了测试留的钩子函数，不用管 return testHookDialTCP(ctx, net, laddr, raddr) &#125; return doDialTCP(ctx, net, laddr, raddr)&#125; 注意现在所在文件是在tcpsock_posix.go 这部分是传输层的内容了。 来看doDialTCP: 123456789101112131415func doDialTCP(ctx context.Context, net string, laddr, raddr *TCPAddr) (*TCPConn, error) &#123; fd, err := internetSocket(ctx, net, laddr, raddr, syscall.SOCK_STREAM, 0, "dial") for i := 0; i &lt; 2 &amp;&amp; (laddr == nil || laddr.Port == 0) &amp;&amp; (selfConnect(fd, err) || spuriousENOTAVAIL(err)); i++ &#123; if err == nil &#123; fd.Close() &#125; fd, err = internetSocket(ctx, net, laddr, raddr, syscall.SOCK_STREAM, 0, "dial") &#125; if err != nil &#123; return nil, err &#125; return newTCPConn(fd), nil&#125; 参数里的ctx自然不言而喻了，是为了控制请求超时取消请求释放资源的；laddr是 local address ， raddr是指 remote address；返回值这里会得到 TCPConn。代码不长，就是调用了 internetSocket得到一个文件描述符，并用其新建一个conn返回。但这里我想多说几句，因为不难发现， internetSocket可能会被调用多次，为什么呢？ 首先我们需要知道 Tcp 有一个极少使用的机制，叫simultaneous connection（同时连接）。正常的连接是：A主机 dial B主机，B主机 listen。 而同时连接则是： A 向 B dial 同时 B 向 A dial，那么 A 和 B 都不需要监听。 我们知道，当 传入 dial 函数的参数laddr==raddr时，内核会拒绝dial。但如果传入的laddr为nil，kernel 会自动选择一个本机端口，这时候有可能会使得新的laddr==raddr,这个时候，kernel不会拒绝dial，并且这个dial会成功，原因是就simultaneous connection，这可能是kernel的bug。所以会判断是否是 selfConnect或者spuriousENOTAVAIL(spurious error not avail)来判断上一次调用internetSocket返回的 err 类型，在特定的情况下重新尝试internetSocket.关于这个问题的讨论参见这里。 好了，我们接下来看看internetSocket，该函数在ipsock_posix.go文件，到了网络层的范围了。 12345678func internetSocket(ctx context.Context, net string, laddr, raddr sockaddr, sotype, proto int, mode string) (fd *netFD, err error) &#123; if (runtime.GOOS == "windows" || runtime.GOOS == "openbsd" || runtime.GOOS == "nacl") &amp;&amp; mode == "dial" &amp;&amp; raddr.isWildcard() &#123; raddr = raddr.toLocal(net) // 如果 raddr 是零地址，把它转化成当前系统对应的零地址格式(local system address 127.0.0.1 or ::1) &#125; family, ipv6only := favoriteAddrFamily(net, laddr, raddr, mode) return socket(ctx, net, family, sotype, proto, ipv6only, laddr, raddr)&#125; （sotype 和 proto 是生成 socket 文件d的系统调用时用的）首先判断了运行系统的类型，favoriteAddrFamily返回了当前 dial 最合适的地址族，主要是判断应该用ipv4还是ipv6或者都用，其返回值 family 有两种可能值：AF_INET和AF_INET6，都是int类型，感兴趣的朋友可以参见这里。 让我们接着关注socket,该函数在sock_posix.go文件，意味着接下来将是更加底层的系统调用了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// socket returns a network file descriptor that is ready for// asynchronous I/O using the network poller.func socket(ctx context.Context, net string, family, sotype, proto int, ipv6only bool, laddr, raddr sockaddr) (fd *netFD, err error) &#123; s, err := sysSocket(family, sotype, proto) if err != nil &#123; return nil, err &#125; if err = setDefaultSockopts(s, family, sotype, ipv6only); err != nil &#123; poll.CloseFunc(s) return nil, err &#125; if fd, err = newFD(s, family, sotype, net); err != nil &#123; poll.CloseFunc(s) return nil, err &#125; // This function makes a network file descriptor for the // following applications: // // - An endpoint holder that opens a passive stream // connection, known as a stream listener // // - An endpoint holder that opens a destination-unspecific // datagram connection, known as a datagram listener // // - An endpoint holder that opens an active stream or a // destination-specific datagram connection, known as a // dialer // // - An endpoint holder that opens the other connection, such // as talking to the protocol stack inside the kernel // // For stream and datagram listeners, they will only require // named sockets, so we can assume that it's just a request // from stream or datagram listeners when laddr is not nil but // raddr is nil. Otherwise we assume it's just for dialers or // the other connection holders. if laddr != nil &amp;&amp; raddr == nil &#123; switch sotype &#123; case syscall.SOCK_STREAM, syscall.SOCK_SEQPACKET: if err := fd.listenStream(laddr, listenerBacklog); err != nil &#123; fd.Close() return nil, err &#125; return fd, nil case syscall.SOCK_DGRAM: if err := fd.listenDatagram(laddr); err != nil &#123; fd.Close() return nil, err &#125; return fd, nil &#125; &#125; if err := fd.dial(ctx, laddr, raddr); err != nil &#123; fd.Close() return nil, err &#125; return fd, nil&#125; 这段代码隐含了大量细节，首先看最上面函数的注释，返回值是一个使用了network poller的异步I/O的文件描述符。前面三个 if 里，先创建了一个 socket，然后设置基本参数，再 new 一个文件描述符，其中包含了大量的系统调用和底层细节，这里先跳过。我想说的在下面。 socket 这个函数可以为一下几种应用创建一个文件描述符： 一个打开了 被动的、流式的 连接的终端，通常叫stream listener 一个打开了 没有具体目的地的、数据报格式的 连接的终端，通常叫datagram listener 一个打开了 主动的、有明确目的地的、数据报格式的 连接的终端，通常叫dialer 一个打开了其他连接的终端，比如与内核中的协议栈通信 通常可以认为当 laddr不为空但raddr为空时的 request 是来自stream or datagram listeners。否则就是来自 dialers 或者其他系统连接。 所以一个dialer和listener的区别就是 laddr， 也就是dialer在一定情况下可以当做listener，到这里就可以解释之前tcp的simultaneous connection同时连接了。 接下来调用了fd的dial函数，这里才真正通过socket开始发送连接请求。 (待续)]]></content>
      <categories>
        <category>go sdk</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go net/dial.go（I）]]></title>
    <url>%2Fgo-sdk%2Fgolang%20net%3Adial.go.html</url>
    <content type="text"><![CDATA[实际上dial.go这个文件中并没有实际发起连接的部分，基本上是在为真正发起连接做一系列的准备，比如：解析网络类型、从addr解析ip地址。。。实际发起连接的函数在tcpsock_posix.go、udpsock_posix.go。。。 首先看一下最主要的类型： 1234567891011121314151617type Dialer struct &#123; Timeout time.Duration Deadline time.Time LocalAddr Addr //真正dial时的本地地址，兼容各种类型(TCP、UDP...),如果为nil，则系统自动选择一个地址 DualStack bool // 双协议栈，即是否同时支持ipv4和ipv6.当network值为tcp时，dial函数会向host主机的v4和v6地址都发起连接 FallbackDelay time.Duration // 当DualStack为真，ipv6会延后于ipv4发起，此字段即为延迟时间，默认为300ms KeepAlive time.Duration Resolver *Resolver Cancel &lt;-chan struct&#123;&#125; // 用于取消dial&#125; Dial是最主要的函数，看一下源码注释： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Dial connects to the address on the named network.//// Known networks are "tcp", "tcp4" (IPv4-only), "tcp6" (IPv6-only),// "udp", "udp4" (IPv4-only), "udp6" (IPv6-only), "ip", "ip4"// (IPv4-only), "ip6" (IPv6-only), "unix", "unixgram" and// "unixpacket".//// For TCP and UDP networks, the address has the form "host:port".// The host must be a literal IP address, or a host name that can be// resolved to IP addresses.// The port must be a literal port number or a service name.// If the host is a literal IPv6 address it must be enclosed in square// brackets, as in "[2001:db8::1]:80" or "[fe80::1%zone]:80".// The zone specifies the scope of the literal IPv6 address as defined// in RFC 4007.// The functions JoinHostPort and SplitHostPort manipulate a pair of// host and port in this form.// When using TCP, and the host resolves to multiple IP addresses,// Dial will try each IP address in order until one succeeds.//// Examples:// Dial("tcp", "golang.org:http")// Dial("tcp", "192.0.2.1:http")// Dial("tcp", "198.51.100.1:80")// Dial("udp", "[2001:db8::1]:domain")// Dial("udp", "[fe80::1%lo0]:53")// Dial("tcp", ":80")//// For IP networks, the network must be "ip", "ip4" or "ip6" followed// by a colon and a literal protocol number or a protocol name, and// the address has the form "host". The host must be a literal IP// address or a literal IPv6 address with zone.// It depends on each operating system how the operating system// behaves with a non-well known protocol number such as "0" or "255".//// Examples:// Dial("ip4:1", "192.0.2.1")// Dial("ip6:ipv6-icmp", "2001:db8::1")// Dial("ip6:58", "fe80::1%lo0")//// For TCP, UDP and IP networks, if the host is empty or a literal// unspecified IP address, as in ":80", "0.0.0.0:80" or "[::]:80" for// TCP and UDP, "", "0.0.0.0" or "::" for IP, the local system is// assumed.//// For Unix networks, the address must be a file system path. 从注释可以看出，Dial 支持多种网络类型；支持ipv4、ipv6；还支持用host名代替ip地址。 12345678910111213func Dial(network, address string) (Conn, error) &#123; var d Dialer return d.Dial(network, address)&#125;func DialTimeout(network, address string, timeout time.Duration) (Conn, error) &#123; d := Dialer&#123;Timeout: timeout&#125; return d.Dial(network, address)&#125;func (d *Dialer) Dial(network, address string) (Conn, error) &#123; return d.DialContext(context.Background(), network, address)&#125; 以上前两个是导出的主要函数，都调用了d.dial()，d.DialContext()。d.DialContext()可以传入一个context，如果context的生命周期在connect完成之前结束，那么会立即返回错误。如果context在连接建立完成之后结束，则不会影响连接。另外如果addr是一组ip地址的话，会把当前剩下的所有时间均分到每个ip上去尝试连接。只要有一个成功，就会立即返回成功的连接并取消其他尝试。具体看代码(有删减)： 123456789101112131415161718192021222324252627282930313233343536373839func (d *Dialer) DialContext(ctx context.Context, network, address string) (Conn, error) &#123; ... deadline := d.deadline(ctx, time.Now()) //d.deadline() 比较d.deadline、ctx.deadline、now+timeout，返回其中最小.如果都为空，返回0 ... subCtx, cancel := context.WithDeadline(ctx, deadline) //设置新的超时context defer cancel() ... // Shadow the nettrace (if any) during resolve so Connect events don't fire for DNS lookups. resolveCtx := ctx ...//给resolveCtx带上一些value addrs, err := d.resolver().resolveAddrList(resolveCtx, "dial", network, address, d.LocalAddr) // 解析IP地址，返回值是一个切片 dp := &amp;dialParam&#123; Dialer: *d, network: network, address: address, &#125; var primaries, fallbacks addrList if d.DualStack &amp;&amp; network == "tcp" &#123; //表示同时支持ipv4和ipv6 primaries, fallbacks = addrs.partition(isIPv4) // 将addrs分成两个切片，前者包含ipv4地址，后者包含ipv6地址 &#125; else &#123; primaries = addrs &#125; var c Conn if len(fallbacks) &gt; 0 &#123;//有ipv6的情况，v4和v6一起dial c, err = dialParallel(ctx, dp, primaries, fallbacks) &#125; else &#123; c, err = dialSerial(ctx, dp, primaries) &#125; if err != nil &#123; return nil, err &#125; ... return c, nil&#125; 从上面代码看到，DialContext最终调用的是dialParallel和dialSerial,先看dialParallel，该函数将v4地址和v6地址分开，先尝试v4地址组，在dialer.fallbackDelay 时间后开始尝试v6地址组，每一组都是调用dialSerial(),让两组竞争： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func dialParallel(ctx context.Context, dp *dialParam, primaries, fallbacks addrList) (Conn, error) &#123; if len(fallbacks) == 0 &#123; return dialSerial(ctx, dp, primaries) &#125; type dialResult struct &#123; Conn error primary bool done bool &#125; results := make(chan dialResult) // unbuffered startRacer := func(ctx context.Context, primary bool) &#123; ras := primaries // ras 意思是 remote addresses if !primary &#123; ras = fallbacks &#125; c, err := dialSerial(ctx, dp, ras) ... results &lt;- dialResult&#123;Conn: c, error: err, primary: primary, done: true&#125; &#125; var primary, fallback dialResult // Start the main racer. primaryCtx, primaryCancel := context.WithCancel(ctx) defer primaryCancel() go startRacer(primaryCtx, true) //先尝试ipv4地址组 // Start the timer for the fallback racer. fallbackTimer := time.NewTimer(dp.fallbackDelay()) defer fallbackTimer.Stop() for &#123; select &#123; case &lt;-fallbackTimer.C: // ipv6延迟时间到，开始尝试ipv6地址组 fallbackCtx, fallbackCancel := context.WithCancel(ctx) defer fallbackCancel() go startRacer(fallbackCtx, false) case res := &lt;-results: //表示至少有一组已经建立连接 if res.error == nil &#123; // return res.Conn, nil &#125; if res.primary &#123; primary = res &#125; else &#123; fallback = res &#125; if primary.done &amp;&amp; fallback.done &#123;//同时建立连接，抛弃 return nil, primary.error &#125; if res.primary &amp;&amp; fallbackTimer.Stop() &#123; // If we were able to stop the timer, that means it // was running (hadn't yet started the fallback), but // we just got an error on the primary path, so start // the fallback immediately (in 0 nanoseconds). fallbackTimer.Reset(0) &#125; &#125; &#125;&#125; 继续看dialSerial： 123456789101112131415161718192021222324252627282930313233func dialSerial(ctx context.Context, dp *dialParam, ras addrList) (Conn, error) &#123; var firstErr error // The error from the first address is most relevant. for i, ra := range ras &#123; // ra =&gt; remote address select &#123; case &lt;-ctx.Done(): //表示 return nil, &amp;OpError&#123;Op: "dial", Net: dp.network, Source: dp.LocalAddr, Addr: ra, Err: mapErr(ctx.Err())&#125; default: &#125; deadline, _ := ctx.Deadline() partialDeadline, err := partialDeadline(time.Now(), deadline, len(ras)-i) // 这里表示前 i 个IP地址的连接失败，然后将剩下的时间均分到剩余的IP地址 ...//判断是否超时并处理 dialCtx := ctx dialCtx, cancel := context.WithDeadline(ctx, partialDeadline) defer cancel() c, err := dialSingle(dialCtx, dp, ra)// 对单个IP地址发起连接 if err == nil &#123; return c, nil &#125; if firstErr == nil &#123; firstErr = err &#125; &#125; if firstErr == nil &#123; firstErr = &amp;OpError&#123;Op: "dial", Net: dp.network, Source: nil, Addr: nil, Err: errMissingAddress&#125; &#125; return nil, firstErr&#125; 最终所有的对单个IP地址发起链接的任务是由dialSingle分配的（此处简单看下就好），该函数解决了兼容不同网络类型的问题： 123456789101112131415161718192021222324252627282930313233func dialSingle(ctx context.Context, dp *dialParam, ra Addr) (c Conn, err error) &#123; trace, _ := ctx.Value(nettrace.TraceKey&#123;&#125;).(*nettrace.Trace) if trace != nil &#123; raStr := ra.String() if trace.ConnectStart != nil &#123; trace.ConnectStart(dp.network, raStr) &#125; if trace.ConnectDone != nil &#123; defer func() &#123; trace.ConnectDone(dp.network, raStr, err) &#125;() &#125; &#125; la := dp.LocalAddr switch ra := ra.(type) &#123; case *TCPAddr: la, _ := la.(*TCPAddr) c, err = dialTCP(ctx, dp.network, la, ra) case *UDPAddr: la, _ := la.(*UDPAddr) c, err = dialUDP(ctx, dp.network, la, ra) case *IPAddr: la, _ := la.(*IPAddr) c, err = dialIP(ctx, dp.network, la, ra) case *UnixAddr: la, _ := la.(*UnixAddr) c, err = dialUnix(ctx, dp.network, la, ra) default: return nil, &amp;OpError&#123;Op: "dial", Net: dp.network, Source: la, Addr: ra, Err: &amp;AddrError&#123;Err: "unexpected address type", Addr: dp.address&#125;&#125; &#125; if err != nil &#123; return nil, &amp;OpError&#123;Op: "dial", Net: dp.network, Source: la, Addr: ra, Err: err&#125; // c is non-nil interface containing nil pointer &#125; return c, nil&#125; 到此，dial.go基本就这么多内容，真正通过socket建立连接的部分下篇再写吧(其实是偷懒)。 (待续)]]></content>
      <categories>
        <category>go sdk</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go bytes.go]]></title>
    <url>%2Fgo-sdk%2Fbyte.html</url>
    <content type="text"><![CDATA[学习bytes的时候，网上找了很多文章，但基本上是用法，很少对代码的分析。这篇文章对bytes.go 做了简要的分析。 首先从 import 的包来看，只引入了unicode 包的部分函数，所以这个文件代码主要是对字节切片做字符处理。从主要的功能来分，bytes.go 分为几个部分： index/contain 系列函数 splite、fields 拆分函数 Map 遍历函数 prepare开始对每个部分分析前，先来看一下 unicode 包里用的比较多的内容。 常量123456const ( RuneError = '\uFFFD' // 这是一个特殊的字符，用于表示“非法”的unicode RuneSelf = 0x80 // 十六进制的80，等于十进制的127，0~127刚好表示128个ASCII码。一个字符的字节码大于127，表示不是ASCII，可能是unicode MaxRune = '\U0010FFFF' // 最大的unicode编码 UTFMax = 4 // 一个unicode码最大的字节长度) 函数utf8.DecodeRune(p []byte)(r rune, size int):从字节切片中解析出第一个完整的unicode码，返回一个rune类型的r（第一个unicode），和r的真实长度size，从代码中可看出，size的值是0~4。简单看一下返回值就好，这不是本文的重点：123456789101112131415161718192021222324252627282930313233343536373839func DecodeRune(p []byte) (r rune, size int) &#123; n := len(p) if n &lt; 1 &#123; return RuneError, 0 &#125; p0 := p[0] x := first[p0] if x &gt;= as &#123; // The following code simulates an additional check for x == xx and // handling the ASCII and invalid cases accordingly. This mask-and-or // approach prevents an additional branch. mask := rune(x) &lt;&lt; 31 &gt;&gt; 31 // Create 0x0000 or 0xFFFF. return rune(p[0])&amp;^mask | RuneError&amp;mask, 1 &#125; sz := x &amp; 7 accept := acceptRanges[x&gt;&gt;4] if n &lt; int(sz) &#123; return RuneError, 1 &#125; b1 := p[1] if b1 &lt; accept.lo || accept.hi &lt; b1 &#123; return RuneError, 1 &#125; if sz == 2 &#123; return rune(p0&amp;mask2)&lt;&lt;6 | rune(b1&amp;maskx), 2 &#125; b2 := p[2] if b2 &lt; locb || hicb &lt; b2 &#123; return RuneError, 1 &#125; if sz == 3 &#123; return rune(p0&amp;mask3)&lt;&lt;12 | rune(b1&amp;maskx)&lt;&lt;6 | rune(b2&amp;maskx), 3 &#125; b3 := p[3] if b3 &lt; locb || hicb &lt; b3 &#123; return RuneError, 1 &#125; return rune(p0&amp;mask4)&lt;&lt;18 | rune(b1&amp;maskx)&lt;&lt;12 | rune(b2&amp;maskx)&lt;&lt;6 | rune(b3&amp;maskx), 4&#125; 注意以上函数返回值， rune 是一个 int32， 占4字节，size则是返回的unicode占的真实长度。这里统一用四个字节来表示一个unicode。 index这里有一系列的index的函数: func Contains(b, subslice []byte) bool func Count(s, sep []byte) int func Index(s, sep []byte) int func IndexByte(s []byte, c byte) int func IndexRune(s []byte, r rune) int func IndexAny(s []byte, chars string) int func IndexFunc(s []byte, f func(r rune) bool) int func LastIndex(s, sep []byte) int func LastIndexAny(s []byte, chars string) int func LastIndexFunc(s []byte, f func(r rune) bool) int … 但是基本上是在调用同一个函数： func Index(s, sep []byte) int 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253func Index(s, sep []byte) int &#123; n := len(sep) switch &#123; case n == 0: return 0 case n == 1: return IndexByte(s, sep[0]) case n == len(s): if Equal(sep, s) &#123; return 0 &#125; return -1 case n &gt; len(s): return -1 case n &lt;= shortStringLen: // Use brute force when s and sep both are small if len(s) &lt;= 64 &#123; return indexShortStr(s, sep) &#125; c := sep[0] i := 0 t := s[:len(s)-n+1] fails := 0 for i &lt; len(t) &#123; if t[i] != c &#123; // IndexByte skips 16/32 bytes per iteration, // so it's faster than indexShortStr. o := IndexByte(t[i:], c) if o &lt; 0 &#123; return -1 &#125; i += o &#125; if Equal(s[i:i+n], sep) &#123; return i &#125; fails++ i++ // Switch to indexShortStr when IndexByte produces too many false positives. // Too many means more that 1 error per 8 characters. // Allow some errors in the beginning. if fails &gt; (i+16)/8 &#123; r := indexShortStr(s[i:], sep) if r &gt;= 0 &#123; return r + i &#125; return -1 &#125; &#125; return -1 &#125; return indexRabinKarp(s, sep)&#125; 可以看到，是几个 case，主要是排除掉一些简单的情况。从s中找到第一次出现sep的位置，当sep长度为1，sep就是一个字节，直接调用IndexByte（s, sep[0]）,就是把s里的字节挨个取出和sep[0]对比。case n &lt;= shortStringLen:表示最普遍的情况，这里使用了相关匹配算法，就不深入谈论了。 再简单看下func IndexAny(s []byte, chars string) int函数，返回s中第一次出现chars中任一字符的位置。注意chars是string类型，可能包含ASCII和unicode，所以要先对chars做处理：12345678910111213141516171819202122232425262728293031323334func IndexAny(s []byte, chars string) int &#123; if chars == "" &#123; // Avoid scanning all of s. return -1 &#125; if len(s) &gt; 8 &#123;// 为什么这里判断len(s) &gt; 8,我也不知道，如果你知道麻烦告诉我哦 // 这里 `makeASCIISet(chars)` 尝试将chars解析成ASCII码并生成集合，如果chars全都是ASCII码，isAscii 为 TRUE，反之为false if as, isASCII := makeASCIISet(chars); isASCII &#123; for i, c := range s &#123; if as.contains(c) &#123;//找到第一个元素，返回下标 return i &#125; &#125; return -1 &#125; &#125; // 当len(s)&lt;=8 或者 chars中包含unicode码会执行到这里。以下这段请仔细看，这样的套路会在bytes包里广泛使用。 var width int //记录每个字符长度 for i := 0; i &lt; len(s); i += width &#123; r := rune(s[i]) if r &lt; utf8.RuneSelf &#123;// 表示r是一个ASCII码，则长度为一字节 width = 1 &#125; else &#123; r, width = utf8.DecodeRune(s[i:]) // 从第 i 个开始到第 i+width 个字节，可能解析成一个unicode &#125; for _, ch := range chars &#123;//依次取出chars中每一个rune，和r比较 if r == ch &#123; return i &#125; &#125; &#125; return -1&#125; 基本上index类的函数理解以上两个就够了，其余的是在他们的基础上有小的调节。 splite func Split(s, sep []byte) [][]byte func SplitN(s, sep []byte, n int) [][]byte func SplitAfter(s, sep []byte) [][]byte func SplitAfterN(s, sep []byte, n int) [][]byte … Splite 函数根据sep将字节切片切分成很多小切片，然后组成新的切片的切片。 和index函数一样，splite基本上是在调用func genSplit(s, sep []byte, sepSave, n int) [][]byte 123456789101112131415161718192021222324252627func genSplit(s, sep []byte, sepSave, n int) [][]byte &#123; //s是源切片，sep是分割切片，sepSave表示分割后要保留sep中的多少位，n表示取前n-1个分段，超出n个的部分不分割，直接返回 if n == 0 &#123; return nil &#125; if len(sep) == 0 &#123; return explode(s, n) //长度为0，则按照“空”分割，也就是每个字符都分割，explode函数的功能是将切片分割成字符切片 &#125; if n &lt; 0 &#123; n = Count(s, sep) + 1 //重新计算n，表示有多少sep段就分多少次 &#125; a := make([][]byte, n) n-- i := 0 for i &lt; n &#123; m := Index(s, sep) if m &lt; 0 &#123; break &#125; a[i] = s[: m+sepSave : m+sepSave] //m + sepSave s = s[m+len(sep):] i++ &#125; a[i] = s return a[:i+1]&#125; fields 的功能也是分段，先来看一下FieldsFunc,该函数通过f()得返回值来判断是否应该在某个字符处分段 123456789101112131415161718192021222324252627282930313233343536373839404142434445func FieldsFunc(s []byte, f func(rune) bool) [][]byte &#123; // A span is used to record a slice of s of the form s[start:end]. // The start index is inclusive and the end index is exclusive. type span struct &#123; //用于记录每一段的起始和终点下标 start int end int &#125; spans := make([]span, 0, 32) // Find the field start and end indices. wasField := false // wasField 表示从fromIndex开始到当前的字符是否应该出现在结果中 fromIndex := 0 for i := 0; i &lt; len(s); &#123; size := 1 r := rune(s[i]) if r &gt;= utf8.RuneSelf &#123; r, size = utf8.DecodeRune(s[i:]) &#125; if f(r) &#123; // r 应该分段 if wasField &#123; // 从fromIndex到当前(i)应该出现在结果中 spans = append(spans, span&#123;start: fromIndex, end: i&#125;) wasField = false &#125; &#125; else &#123; if !wasField &#123; // 从fromIndex到当前(i)不应该出现在结果中 fromIndex = i wasField = true &#125; &#125; i += size &#125; // Last field might end at EOF. if wasField &#123; spans = append(spans, span&#123;fromIndex, len(s)&#125;) &#125; // Create subslices from recorded field indices. a := make([][]byte, len(spans)) for i, span := range spans &#123; a[i] = s[span.start:span.end:span.end] &#125; return a&#125; 还有一个Fields函数，其实就是调用FieldsFunc函数，只不过传入的f参数是一个判断字符是否是空白符的函数，就不展示代码了 Map函数func Map(mapping func(r rune) rune, s []byte) []byte是对字节切片中每个字符进行遍历，并且根据传入的mapping函数对每个字符进行修改然后存到新的切片中，最后返回新的切片。 ToUpper,ToLower,ToTitle…等函数都调用了Map函数 1234567891011121314151617181920212223242526272829303132func Map(mapping func(r rune) rune, s []byte) []byte &#123; // In the worst case, the slice can grow when mapped, making // things unpleasant. But it's so rare we barge in assuming it's // fine. It could also shrink but that falls out naturally. maxbytes := len(s) // length of b nbytes := 0 // number of bytes encoded in b b := make([]byte, maxbytes) for i := 0; i &lt; len(s); &#123; wid := 1 r := rune(s[i]) if r &gt;= utf8.RuneSelf &#123; r, wid = utf8.DecodeRune(s[i:]) &#125; r = mapping(r) //r 即修改后的字符 if r &gt;= 0 &#123; rl := utf8.RuneLen(r) if rl &lt; 0 &#123; rl = len(string(utf8.RuneError)) &#125; if nbytes+rl &gt; maxbytes &#123; // Grow the buffer. maxbytes = maxbytes*2 + utf8.UTFMax nb := make([]byte, maxbytes) copy(nb, b[0:nbytes]) b = nb &#125; nbytes += utf8.EncodeRune(b[nbytes:maxbytes], r) &#125; i += wid &#125; return b[0:nbytes]&#125; （完）]]></content>
      <categories>
        <category>go sdk</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式入门]]></title>
    <url>%2Funcategorized%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%85%A5%E9%97%A8.html</url>
    <content type="text"><![CDATA[原理 正则引擎 为什么正则能有效，因为有引擎，这和为什么JS能执行一样，有JS引擎 正则的引擎大致可分为两类：DFA和NFA DFA (Deterministic finite automaton) 确定型有穷自动机 NFA (Non-deterministic finite automaton) 非确定型有穷自动机，大部分都是NFA 这里的“确定型”指，对于某个确定字符的输入，这台机器的状态会确定地从a跳到b，“非确定型”指，对于某个确定字符的输入，这台机器可能有好几种状态的跳法；这里的“有穷”指，状态是有限的，可以在有限的步数内确定某个字符串是被接受还是发好人卡的；这里的“自动机”，可以理解为，一旦这台机器的规则设定完成，就可以自行判断了，不要人看。 基础知识 正则眼中的字符串——n个字符，n+1个位置 为什么要有字符还要有位置呢？因为位置是可以被匹配的。 “占有字符”和“零宽度”: 如果一个子正则表达式匹配到的是字符，而不是位置，而且会被保存到最终的结果中，那个这个子表达式就是占有字符的，比如 /ha/ （匹配 ha ）就是占有字符的； 如果一个子正则匹配的是位置，而不是字符，或者匹配到的内容不保存在结果中（其实也可以看做一个位置），那么这个子表达式是零宽度的，比如 /read(?=ing)/ （匹配 reading ，但是只将read放入结果中，下文会详述语法，此处仅仅举例用），其中的(?=ing)就是零宽度的，它本质代表一个位置。 占有字符是互斥的，零宽度是非互斥的。也就是一个字符，同一时间只能由一个子表达式匹配，而一个位置，却可以同时由多个零宽度的子表达式匹配。举个栗子，比如/aa/是匹配不了a的，这个字符串中的a只能由正则的第一个a字符匹配，而不能同时由第二个a匹配（废话）；但是位置是可以多个匹配的，比如/\b\ba/是可以匹配a的，虽然正则表达式里有2个表示单词开头位置的\b元字符，这两个\b是可以同时匹配位置0（在这个例子中）的 控制权和传动控制权是指哪一个正则子表达式（可能为一个普通字符、元字符或元字符序列组成）在匹配字符串，那么控制权就在哪。 传动是指正则引擎的一种机制，传动装置将定位正则从字符串的哪里开始匹配。 正则表达式当开始匹配的时候，一般是由一个子表达式获取控制权，从字符串中的某一个位置开始尝试匹配，一个子表达式开始尝试匹配的位置，是从前一子表达匹配成功的结束位置开始的 语法 要用某类常见字符——简单元字符 ‘.’ 匹配除了换行符以外的任意字符，也即是[^\n]，如果要包含任意字符，可使用(.|\n) \w (whatever) 匹配任意字母、数字或者下划线，等价于[a-zA-Z0-9_]，在deerchao的文中还指出可匹配汉字，但是\w在JS中是不能匹配汉字的 \s (space) 匹配任意空白符，包含换页符\f、换行符\n、回车符\r、水平制表符\t、垂直制表符\v \d 匹配数字 \un (Unicode) 匹配n，这里的n是一个有4个十六进制数字表示的Unicode字符，比如\u597d表示中文字符“好”，那么超过\uffff编号的字符怎么表示呢？ES6的u修饰符会帮你。 要表示出现次数（重复）——限定符 a*表示字符a连续出现次数 &gt;= 0 次 a+表示字符a连续出现次数 &gt;= 1 次 a?表示字符a出现次数 0 或 1 次 a{5}表示字符a连续出现次数 5 次 a{5,}表示字符a连续出现次数 &gt;= 5次 a{5,10}表示字符a连续出现次数为 5到10次 ，包括5和10 匹配位置——定位符和零宽断言 \b 匹配单词边界位置，准确的描述是它匹配一个位置，这个位置前后不全是\w能描述的字符，所以像\u597d\babc是可以匹配“好abc”的。 ^ 匹配字符串开始位置，也就是位置0，如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\n’ 或 ‘\r’ 之后的位置 $ 匹配字符串结束位置，如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\n’ 或 ‘\r’ 之前的位置 想表达“或”的意思——字符簇和分歧 字符簇可用来表达字符级别的“或”语义，表示的是方括号中的字符任选一： [abc]表示a、b、c这3个字符中的任意一个，如果字母或者数字是连续的，那么可以用-连起来表示，[b-f]代表从b到f这么多字符中任选一个 [(ab)(cd)]并不会用来匹配字符串“ab”或“cd”，而是匹配a、b、c、d、(、)这6个字符中的任一个，也就是想表达“匹配字符串ab或者cd”这样的需求不能这么做，要这么写ab|cd。但这里要匹配圆括号本身，讲道理是要反斜杠转义的，但是在方括号中，圆括号被当成普通字符看待，即便如此，仍然建议显式地转义 分歧用来表达表达式级别的“或”语义，表示的是匹配|左右任一表达就可：ab|cd会匹配字符串“ab”或者“cd” 会短路，回想下编程语言中逻辑或的短路，所以用(ab|abc)去匹配字符串“abc”，结果会是“ab”，因为竖线左边的已经满足了，就用左边的匹配结果代表整个正则的结果 想表达“非”的意思——反义 \W、\D、\S、\B 用大写字母的这几个元字符表示就是对应小写字母匹配内容的反义，这几个依次匹配“除了字母、数字、下划线外的字符”、“非数字字符”、“非空白符”、“非单词边界位置” [^aeiou]表示除了a、e、i、o、u外的任一字符，在方括号中且出现在开头位置的^表示排除，如果^在方括号中不出现在开头位置，那么它仅仅代表^字符本身 贪婪和非贪婪在限定符中，除了{n}确切表示重复几次，其余的都是一个有下限的范围。 在默认的模式（贪婪）下，会尽可能多的匹配内容。比如用ab*去匹配字符串“abbb”，结果是“abbb”。 而通过在限定符后面加问号?可以进行非贪婪匹配，会尽可能少地匹配。用ab*?去匹配“abbb”，结果会是“a”。 不带问号的限定符也称匹配优先量词，带问号的限定符也称忽略匹配优先量词。 JS 中的正则 字面量, 构造函数和工厂符号都是可以的： /pattern/flags new RegExp(pattern [, flags]) RegExp(pattern [, flags]) 参数pattern正则表达式的文本。flags如果指定，标志可以具有以下值的任意组合： g 全局匹配;找到所有匹配，而不是在第一个匹配后停止 i 忽略大小写 m 多行; 将开始和结束字符（^和$）视为在多行上工作（例如，分别匹配每一行的开始和结束（由 \n 或 \r 分割），而不只是只匹配整个输入字符串的最开始和最末尾处。 u Unicode; 将模式视为Unicode序列点的序列 y 粘性匹配; 仅匹配目标字符串中此正则表达式的lastIndex属性指示的索引(并且不尝试从任何后续的索引匹配)。 有两种方法来创建一个RegExp对象：一是字面量、二是构造函数。要指示字符串，字面量的参数不使用引号，而构造函数的参数使用引号。因此，以下表达式创建相同的正则表达式 /ab+c/i; new RegExp(&apos;ab+c&apos;, &apos;i&apos;); new RegExp(/ab+c/, &apos;i&apos;); 方法 RegExp.prototype.exec() exec() 方法在一个指定字符串中执行一个搜索匹配。返回一个结果数组或 null。 var matches = /h./.exec(&apos;This is a hello world!&apos;); console.log(matches); // [ &apos;hi&apos;, index: 1, input: &apos;This is a hello world!&apos; ] RegExp.prototype.test() test() 方法执行一个检索，用来查看正则表达式与指定的字符串是否匹配。返回 true 或 false。 当你想要知道一个模式是否存在于一个字符串中时，就可以使用 test()（类似于 String.prototype.search() 方法），差别在于test返回一个布尔值，而 search 返回索引（如果找到）或者-1（如果没找到） let str = &apos;hello world!&apos;; let result = /hello/.test(str); console.log(result); // true 例子 使用正则改变数据结构 下例使用 replace 方法 （继承自 String）去匹配姓名 first last 输出新的格式 last, first。脚本中使用 $1 和 $2 指明括号里先前的匹配. var re = /(\w+)\s(\w+)/; var str = &quot;John Smith&quot;; var newstr = str.replace(re, &quot;$2, $1&quot;); print(newstr); //&quot;Smith, John&quot; 在多行中使用正则表达式 var s = &quot;Please yes\nmake my day!&quot;; s.match(/yes.*day/); // Returns null s.match(/yes[^]*day/); // Returns &apos;yes\nmake my day&apos; 使用正则表达式和 Unicode 字符 \w 或 \W 只会匹配基本的 ASCII 字符；如 ‘a’ 到 ‘z’、 ‘A’ 到 ‘Z’、 0 到 9 及 ‘_’。为了匹配其他语言中的字符，如西里尔（Cyrillic）或 希伯来语（Hebrew），要使用 \uhhhh，”hhhh” 表示以十六进制表示的字符的 Unicode 值 var text = &quot;Образец text на русском языке&quot;; var regex = /[\u0400-\u04FF]+/g; var match = regex.exec(text); print(match[1]); // prints &quot;Образец&quot; print(regex.lastIndex); // prints &quot;7&quot; var match2 = regex.exec(text); print(match2[1]); // prints &quot;на&quot; [did not print &quot;text&quot;] print(regex.lastIndex); // prints &quot;15&quot; // and so on 从 URL 中提取子域名 var url = &quot;http://xxx.domain.com&quot;; print(/[^.]+/.exec(url)[0].substr(7)); // prints &quot;xxx&quot;]]></content>
      <tags>
        <tag>regex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dart 语法基础]]></title>
    <url>%2Funcategorized%2Fdart%20%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80.html</url>
    <content type="text"><![CDATA[本文是对 Dart 语言的官方文档做了简单的翻译和总结，有不当之处敬请指正。如果有时间和精力建议通读官方文档 hello world// Define a function. printNumber(num aNumber) { print(&apos;The number is $aNumber.&apos;); // Print to console. } // This is where the app starts executing. main() { var number = 42; // Declare and initialize a variable. printNumber(number); // Call a function. } 重要的概念 能赋值给变量的所以东西都是对象，包括 numbers, null, function, 都是继承自 Object 内置类 尽量给变量定义一个类型，会更安全，没有显示定义类型的变量在 debug 模式下会类型会是 dynamic（动态的） dart 在 running 之前解析你的所有代码，指定数据类型和编译时的常量，可以提高运行速度 dart 提供了顶级函数(如：main()) dart 没有 public、private、protected 这些关键字，变量名以”_”开头意味着对它的 lib 是私有的 变量 没有初始化的变量都会被赋予默认值 null var name = &apos;Bob&apos;; var unInitializeValue1; //未给初值的变量，默认值为 null Int unInitializeValue2; //即使是Int 型，默认值也是 null 程序中只当数据类型是为了指出自己的使用意图，并帮助语言进行语法检查。但是，指定类型不是必须的 num int 取值范围：-2^53 to 2^53 // String -&gt; int var one = int.parse(&apos;1&apos;); // String -&gt; double var onePointOne = double.parse(&apos;1.1&apos;); // int -&gt; String String oneAsString = 1.toString(); // double -&gt; String 注意括号中要有小数点位数，否则报错 String piAsString = 3.14159.toStringAsFixed(2); string ‘’’…’’’，”””…”””表示多行字符串 r’…’,r”…”表示“raw”字符串 用 $ 或 ${} 来计算字符串中变量的值 bool Dart 是强 bool 类型检查，只有bool 类型的值是true 才被认为是true list list 基本和 JavaScript 数组一样，它的方法如下： // 使用List的构造函数，也可以添加int参数，表示List固定长度，不能进行添加 删除操作 var vegetables = new List(); // 或者简单的用List来赋值 var fruits = [&apos;apples&apos;, &apos;oranges&apos;]; // 添加元素 fruits.add(&apos;kiwis&apos;); // 添加多个元素 fruits.addAll([&apos;grapes&apos;, &apos;bananas&apos;]); // 获取第一个元素 fruits.first; // 获取元素最后一个元素 fruits.last; // 查找某个元素的索引号 assert(fruits.indexOf(&apos;apples&apos;) == 0); // 删除指定位置的元素，返回删除的元素 fruits.removeAt(index); // 删除指定元素,成功返回true，失败返回false fruits.remove(&apos;apples&apos;); // 删除最后一个元素，返回删除的元素 fruits.removeLast(); // 删除指定范围元素，含头不含尾，成功返回null fruits.removeRange(start,end); // 删除指定条件的元素，成功返回null fruits.removeWhere((item) =&gt; item.length &gt;6)； // 删除所有的元素 fruits.clear(); // sort()对元素进行排序，传入一个函数作为参数，return &lt;0表示由小到大， &gt;0表示由大到小 fruits.sort((a, b) =&gt; a.compareTo(b)); map 类似 JavaScript map // Map的声明 var hawaiianBeaches = { &apos;oahu&apos; : [&apos;waikiki&apos;, &apos;kailua&apos;, &apos;waimanalo&apos;], &apos;big island&apos; : [&apos;wailea bay&apos;, &apos;pololu beach&apos;], &apos;kauai&apos; : [&apos;hanalei&apos;, &apos;poipu&apos;] }; var searchTerms = new Map(); // 指定键值对的参数类型 var nobleGases = new Map&lt;int, String&gt;(); // Map的赋值，中括号中是Key，这里可不是数组 nobleGase[54] = &apos;dart&apos;; //Map中的键值对是唯一的 //同Set不同，第二次输入的Key如果存在，Value会覆盖之前的数据 nobleGases[54] = &apos;xenon&apos;; assert(nobleGases[54] == &apos;xenon&apos;); // 检索Map是否含有某Key assert(nobleGases.containsKey(54)); //删除某个键值对 nobleGases.remove(54); assert(!nobleGases.containsKey(54)); 注：如果定义了一个 map 常量，那么value 也必须是常量 symbol symbol字面量是编译时常量，在标识符前面加#。如果是动态确定，则使用Symbol构造函数，通过new来实例化 函数 所有的函数都会有返回值。如果没有指定函数返回值，则默认的返回值是null。没有返回值的函数，系统会在最后添加隐式的return 语句。 函数参数函数可以有两种类型的参数： 必须的——必须的参数放在参数列表的前面。 可选的——可选的参数跟在必须的参数后面。 注：可选参数必须放在最后 通过【】来表示可选参数 String say(String from, String msg, [String device]) { var result = &apos;$from says $msg&apos;; if (device != null) { result = &apos;$result with a $device&apos;; } return result; } 还可以设置默认参数值 String say(String from, String msg, [String device = &apos;carrier pigeon&apos;, String mood]) { var result = &apos;$from says $msg&apos;; if (device != null) { result = &apos;$result with a $device&apos;; } if (mood != null) { result = &apos;$result (in a $mood mood)&apos;; } return result; } 函数还可以作为另一个函数的参数 printElement(element) { print(element); } var list = [1, 2, 3]; // Pass printElement as a parameter. list.forEach(printElement); 函数可以匿名，但是不像 JavaScript， 匿名函数不用加上 function 关键字 var list = [&apos;apples&apos;, &apos;oranges&apos;, &apos;grapes&apos;, &apos;bananas&apos;, &apos;plums&apos;]; list.forEach((i) { print(list.indexOf(i).toString() + &apos;: &apos; + i); }); 闭包Function makeAdder(num addBy) { return (num i) =&gt; addBy + i; } main() { // Create a function that adds 2. var add2 = makeAdder(2); // Create a function that adds 4. var add4 = makeAdder(4); assert(add2(3) == 5); assert(add4(3) == 7); } 运算符除了常见的，还有如下运算符： is 运算符，a is b，用于判断 a 对象是否是 b 类的实例，返回 bool 值 is！意义与上面相反 as 运算符；用于检查类型 (emp as Person).firstName = &apos;Bob&apos;; 如果 emp 为空或者不是 Person 的实例，会抛出异常 ??= 运算符 b ??= value; // 如果 b 为空，把 value 赋值给 b; // 否则，b 不变 ?? 运算符 String toString() =&gt; msg ?? super.toString(); //如果 msg 不为空，返回 msg；否则返回后面的 .. 运算符，把对同一对象的不同操作串联起来 final addressBook = (new AddressBookBuilder() ..name = &apos;jenny&apos; ..email = &apos;jenny@example.com&apos; ..phone = (new PhoneNumberBuilder() ..number = &apos;415-555-0100&apos; ..label = &apos;home&apos;) .build()) .build(); 流程控制语句 if…else for while do-while break continue switch…case 如果 case 后面有表达式但是没有 break，会抛出异常 assert（仅在checked模式有效），如果条件为假，抛出异常 异常throw 抛出固定类型的异常： throw new FormatException(&apos;Expected at least 1 section&apos;); 抛出任意类型的异常： throw &apos;out of llamas！&apos; 因为抛出异常属于表达式，可以将throw语句放在=&gt;语句中，或者其它可以出现表达式的地方： distanceTo(Point other) =&gt; throw new UnimplementedError(); catch 可以通过 on语句来指定需要捕获的异常类型，使用catch来处理异常 try { breedMoreLlamas(); } on OutOfLlamasException { // A specific exception buyMoreLlamas(); } on Exception catch (e) { // Anything else that is an exception print(&apos;Unknown exception: $e&apos;); } catch (e, s) { print(&apos;Exception details:\n $e&apos;); print(&apos;Stack trace:\n $s&apos;); } 可以向catch()传递1个或2个参数。第一个参数表示：捕获的异常的具体信息，第二个参数表示：异常的堆栈跟踪(stack trace) rethrow rethrow语句用来处理一个异常，同时希望这个异常能够被其它调用的部分使用 finally Dart 的finally用来执行那些无论异常是否发生都执行的操作。 类 使用new语句来构造一个类。构造函数的名字可能是ClassName，也可以是ClassName.identifier var jsonData = JSON.decode(&apos;{&quot;x&quot;:1, &quot;y&quot;:2}&apos;); // Create a Point using Point(). var p1 = new Point(2, 2); // Create a Point using Point.fromJson(). var p2 = new Point.fromJson(jsonData); 使用.来调用实例的变量或者方法。 使用 ?. 来避免左边操作数为null引发异常。 使用const替代new来创建编译时的常量构造函数。 两个使用const构建的同一个构造函数，实例相等。 获取对象的运行时类型使用：o.runtimeType 所有实例变量会生成一个隐式的getter方法，不是final或const的实例变量也会生成一个隐式的setter方法 构造函数class Point { num x; num y; // 推荐方式 Point(this.x, this.y); } 构造函数不能被继承 子类不会继承父类的构造函数。如果不显式提供子类的构造函数，系统就提供默认的构造函数。 命名构造函数 class Point { num x; num y; Point(this.x, this.y); // 命名构造函数 Point.fromJson(Map json) { x = json[&apos;x&apos;]; y = json[&apos;y&apos;]; } } 使用命名构造函数可以实现一个类多个构造函数。构造函数不能被继承，父类中的命名构造函数不能被子类继承。如果想要子类也拥有一个父类一样名字的构造函数，必须在子类实现这个构造函数 如果父类不显式提供无参的非命名构造函数，在子类中必须手动调用父类的一个构造函数。在子类构造函数名后，大括号{前，使用super.调用父类的构造函数，中间使用:分割 class Person { String firstName; Person.fromJson(Map data) { print(&apos;in Person&apos;); } } class Employee extends Person { // 父类没有无参数的非命名构造函数，必须手动调用一个构造函数 super.fromJson(data) Employee.fromJson(Map data) : super.fromJson(data) { print(&apos;in Employee&apos;); } } 当在构造函数初始化列表中使用super()时，要把它放在最后。 View(Style style, List children) : _children = children, super(style) {} 除了调用父类的构造函数，也可以通过初始化列表 在子类的构造函数体前（大括号前）来初始化实例的变量值，使用逗号,分隔 class Point { num x; num y; Point(this.x, this.y); // 在构造函数体前 初始化列表 设置实例变量 Point.fromJson(Map jsonMap) : x = jsonMap[&apos;x&apos;], y = jsonMap[&apos;y&apos;] { print(&apos;In Point.fromJson(): ($x, $y)&apos;); } } 工厂构造函数 当实例化了一个构造函数后，不想每次都创建该类的一个新的实例的时候使用factory关键字，定义工厂构造函数，从缓存中返回一个实例，或返回一个子类型的实例 class Logger { final String name; bool mute = false; static final Map&lt;String, Logger&gt; _cache = &lt;String, Logger&gt;{}; // 缓存保存对象 factory Logger(String name) { if (_cache.containsKey(name)) { return _cache[name]; } else { final logger = new Logger._internal(name); _cache[name] = logger; return logger; } } Logger._internal(this.name);// 命名构造函数 void log(String msg) { if (!mute) { print(msg); } } } main() { var p1 = new Logger(&quot;1&quot;); p1.log(&quot;2&quot;); var p2 = new Logger(&apos;22&apos;); p2.log(&apos;3&apos;); var p3 = new Logger(&apos;1&apos;);// 相同对象直接访问缓存 } 方法Getters and setters get()和set()方法是Dart 语言提供的专门用来读取和写入对象的属性的方法。每一个类的实例变量都有一个隐式的getter和可能的setter（如果字段为final或const，只有getter） 抽象类 使用abstract关键字定义一个抽象类，抽象类不能实例化。抽象类通常用来定义接口。 隐式接口 每一个类都隐式的定义一个接口，这个接口包含了这个类的所有实例成员和它实现的所有接口 一个类可以实现一个或多个（用,隔开）接口，通过implements关键字。 class Person { final _name; Person(this._name); String greet(who) =&gt; &apos;hello,$who,i am $_name&apos;; } class Imposter implements Person { final _name = &apos;&apos;; String greet(who) =&gt; &apos;hi $who.do you know who i am.&apos;; } greetBob(Person p) =&gt; p.greet(&apos;bob&apos;); main(List&lt;String&gt; args) { print(greetBob(new Person(&apos;lili&apos;))); print(greetBob(new Imposter())); } 继承 使用extends来创造子类，使用super来指向父类 枚举类型 枚举类型是一种特殊的类，通常用来表示一组固定数字的常量值。 每个枚举类型都有一个index的getter，返回以0开始的位置索引，每次加1。 在switch语句中使用枚举，必须在case语句中判断所有的枚举，否则会获得警告。 枚举类型有以下限制： 不能继承，mixin，或实现一个枚举。 不能显式的实例化一个枚举。 泛型 使用&lt;…&gt; 的方式来定义泛型 虽然Dart 语言中类型是可选的，但是明确的指明使用的是泛型，会让代码更好理解 abstract class Cache&lt;T&gt; { T getByKey(String key); setByKey(String key, T value); } 用于集合类型 泛型用于List 和 Map 类型参数化 var names = &lt;String&gt;[&apos;Seth&apos;, &apos;Kathy&apos;, &apos;Lars&apos;]; var pages = &lt;String, String&gt;{ &apos;index.html&apos;: &apos;Homepage&apos;, &apos;robots.txt&apos;: &apos;Hints for web robots&apos;, &apos;humans.txt&apos;: &apos;We are people, not machines&apos; }; 泛型集合及它们所包含的类型 dart的泛型类型是具体的，在运行时包含它们的类型信息。 库和可见性 使用import 和 library 指令可以方便的创建一个模块或分享代码。一个Dart 库不仅能够提供相应的API，还可以包含一些以_开头的私有变量仅在库内部可见 如果导入的库拥有相互冲突的名字，使用as为其中一个或几个指定不一样的前缀。 import &apos;package:lib1/lib1.dart&apos;; import &apos;package:lib2/lib2.dart&apos; as lib2; // ... Element element1 = new Element(); // Uses Element from lib1. lib2.Element element2 = new lib2.Element(); // Uses Element from lib2. 如果只需要使用库的一部分内容，使用show或hide有选择的导入。 // 仅导入foo. import &apos;package:lib1/lib1.dart&apos; show foo; // 除了foo都导入 import &apos;package:lib2/lib2.dart&apos; hide foo; 要延迟加载一个库，首先必须使用deferred as导入它。 import &apos;package:deferred/hello.dart&apos; deferred as hello; greet() async { // 使用await关键字暂停执行，直到库加载 await hello.loadLibrary(); hello.printGreeting(); } 可以在代码中多次调用loadLibrary()方法。但是实际上它只会被执行一次。 使用延迟加载的注意事项： 延迟加载的内容只有在加载后才存在。 Dart 隐式的将deferred as改为了deferred as namespace。loadLibrary()返回值是Future 异步支持使用async函数和await表达式实现异步操作。 当需要使用一个从Future返回的值时，有两个选择： 使用async和await。 使用Future API。 当需要从一个Stream获取值时，有两个选择： 使用async和异步的循环(await for)。 使用Stream API。代码使用了async和await就是异步的，虽然看起来像同步代码。 checkVersion() async { //注意这里 async 在小括号后面，和 JavaScript 不一样 var version = await lookUpVersion(); if (version == expectedVersion) { // Do something. } else { // Do something else. } } 给函数添加async关键字将使函数返回一个Future类型。 // 修改前是同步的 String lookUpVersionSync() =&gt; &apos;1.0.0&apos;; // 修改后 是异步的 函数体不需要使用Future API // dart会在必要的时候创建Future对象 Future&lt;String&gt; lookUpVersion() async =&gt; &apos;1.0.0&apos;; 在Stream中使用异步循环 // expression的值必须是Stram类型 await for (variable declaration in expression) { // Executes each time the stream emits a value. } 异步循环的执行流程如下： 等待 stream 发出数据。 执行循环体，并将变量的值设置为发出的数据。 重复1.，2.直到stream 对象被关闭 注：这个过程类似于 JavaScript 的 Rxjs 可调用类 Dart 语言中为了能够让类像函数一样能够被调用，可以实现call()方法。 class WannabeFunction { call(String a, String b, String c) =&gt; &apos;$a $b $c!&apos;; } main() { var wf = new WannabeFunction(); var out = wf(&quot;Hi&quot;,&quot;there,&quot;,&quot;gang&quot;); print(&apos;$out&apos;); // Hi there, gang! print(wf.runtimeType); // WannabeFunction print(out.runtimeType); // String print(wf is Function); // true }]]></content>
      <tags>
        <tag>dart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS call & bind & apply（I）]]></title>
    <url>%2Funcategorized%2Flearn-into-javaScript_call%26bind%26apply.html</url>
    <content type="text"><![CDATA[call先给一个官方描述吧： call() 方法调用一个函数, 其具有一个指定的this值和分别地提供的参数(参数的列表)。 可以让call()中的对象调用当前对象所拥有的function。你可以使用call()来实现继承：写一个方法，然后让另外一个新的对象来继承它（而不是在新对象中再写一次这个方法）。 一般用法使用call方法调用匿名函数在下例中的for循环体内，我们创建了一个匿名函数，然后通过调用该函数的call方法，将每个数组元素作为指定的this值执行了那个匿名函数。这个匿名函数的主要目的是给每个数组元素对象添加一个print方法，这个print方法可以打印出各元素在数组中的正确索引号12345678910111213var animals = [ &#123;species: 'Lion', name: 'King'&#125;, &#123;species: 'Whale', name: 'Fail'&#125;];for (var i = 0; i &lt; animals.length; i++) &#123; (function (i) &#123; this.print = function () &#123; console.log('#' + i + ' ' + this.species + ': ' + this.name); &#125; this.print(); &#125;).call(animals[i], i);&#125; 使用call方法调用函数并且指定上下文的 this举个栗子：123456789var foo = &#123; value: 1&#125;;function bar() &#123; console.log(this.value);&#125;bar.call(foo); // 1 模拟实现分析在上面的第二个例子里，注意两点： call 改变了 this 的指向，指向到 foo bar 函数执行了 试想当调用 call 的时候，把 foo 对象改造成如下： 12345678var foo = &#123; value: 1, bar: function() &#123; console.log(this.value) &#125;&#125;;foo.bar(); // 1 这个时候 this 就指向了 foo，是不是很简单呢？ 所以我们模拟的步骤可以分为： 将函数设为对象的属性 执行该函数 删除该函数模拟第一步12345678910111213141516Function.prototype.call1 = function(context) &#123; context.fn = this; //this 指向调用 call1 的函数 context.fn(); delete context.fn;&#125;//测试一下var foo = &#123; value: 1&#125;;function bar() &#123; console.log(this.value);&#125;bar.call2(foo); // 1 注意： 模拟第二步：指定参数123456789Function.prototype.call1 = function(context) &#123; context.fn = this; var args = Array.from(arguments).slice(1); //获取arguments（传进来的所有参数），变成数组，并去掉第一个参数（context） context.fn(...args); // ...是es6的语法，意思是展开后面的对象或数组 // 例如： ...[1,2,3,4,5] =&gt; 1,2,3,4,5 delete context.fn;&#125; 以下是没有 es6 时的替代方法123456789Function.prototype.call1 = function(context) &#123; context.fn = this; var args = []; for(var i = 1, len = arguments.length; i &lt; len; i++) &#123; args.push('arguments[' + i + ']'); &#125; eval('context.fn(' + args + ')'); delete context.fn;&#125; 模拟实现第三步模拟代码已经完成 80%，还有两个小点要注意： 1.this 参数可以传 null，当为 null 的时候，视为指向 window 2.函数是可以有返回值的！ 123456789101112Function.prototype.call1 = function(context) &#123; var context = context || window; context.fn = this; var args = Array.from(arguments).slice(1); //获取arguments（传进来的所有参数），变成数组，并去掉第一个参数（context） var result = context.fn(...args); // ...是es6的语法，意思是展开后面的对象或数组 // 例如： ...[1,2,3,4,5] =&gt; 1,2,3,4,5 delete context.fn; return result;&#125; 大功告成！ｂ（￣▽￣）ｄ apply 和 call 一样，只是参数是以数组的形式给出 模拟实现12345678910111213141516171819Function.prototype.apply = function (context, arr) &#123; var context = Object(context) || window; context.fn = this; var result; if (!arr) &#123; result = context.fn(); &#125; else &#123; var args = []; for (var i = 0, len = arr.length; i &lt; len; i++) &#123; args.push('arr[' + i + ']'); &#125; result = eval('context.fn(' + args + ')') &#125; delete context.fn; return result;&#125; bind MDN 的解释：bind() 函数会创建一个新函数（称为绑定函数），新函数与被调函数（绑定函数的目标函数）具有相同的函数体（在 ECMAScript 5 规范中内置的call属性）。当新函数被调用时 this 值绑定到 bind() 的第一个参数，该参数不能被重写。123456789101112131415161718192021Function.prototype.bind = function (oThis) &#123; if (typeof this !== "function") &#123; // closest thing possible to the ECMAScript 5 internal IsCallable function throw new TypeError("Function.prototype.bind - what is trying to be bound is not callable"); &#125; var aArgs = Array.prototype.slice.call(arguments, 1), fToBind = this, fNOP = function () &#123;&#125;, fBound = function () &#123; return fToBind.apply(this instanceof fNOP &amp;&amp; oThis ? this : oThis || window, aArgs.concat(Array.prototype.slice.call(arguments))); &#125;; fNOP.prototype = this.prototype; fBound.prototype = new fNOP(); return fBound;&#125;; call apply bind 区别call和apply，bind都是用来改变函数中this的指向不同的是call和apply不仅改变了函数中this的指向并且立即调用了函数而bind仅仅是替换了this没有调用 apply和call的区别在于当Parent有参数的时候call只能一个一个的赋值 apply可以以数组的方式传递bind体验了js的预处理，预先处理数据 稍后之行]]></content>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redux your app]]></title>
    <url>%2Funcategorized%2Fredux.html</url>
    <content type="text"><![CDATA[redux简介简单来说，redux 就是帮我们统一管理了 react 组件的 state 状态。 为什么要使用 redux 统一管理 state 呢？没有 redux 我们依旧可以开发 APP，但是当 APP 的复杂度到达一定程度的时候，摆在我们面前的就是 难以维护 的代码（其中包含组件大量的异步回调，数据处理等等），但是使用 redux 也会增加我们整个项目的复杂度，这就需要我们在两者之间进行权衡了，对于这一部分，redux 开发者给我们下面几个参考点： 以下几种情况不需要使用 redux： 整体 UI 很简单，没有太多交互。 不需要与服务器进行大量交互，也没有使用 WebSocket。 视图层只从单一来源获取数据。 以下几种情况可考虑使用 redux： 用户的交互复杂。 根据层级用户划分功能。 多个用户之间协作。 与服务器大量交互，或使用了 WebSocket。 视图层需要从多个来源获取数据。 总结以上内容：redux 适用于 多交互，多数据源，复杂程度高的工程中。 也就是说，当我们的组件出现 某个状态需要共享，需要改变另一个组件状态 等传值比较不容易的情况。就可以考虑 redux ，当然还有其他 redux 的替代产品供我们使用。。 重要内容 为了避免混乱，我们不应该直接修改 redux 的状态，需要有特定的办法来修改状态。首先我们需要 action 来触发一个行为，告知 redux 我们需要修改状态，然后应由专门生产新状态的 reducer 来产生新的状态 action action 是一个对象，包含这个行为的 类型 和必要的参数(可选)。action也可写成一个返回对象的函数(ActionCreator) 12345678function testAction(key1, key2, ...keyN) &#123; return &#123; type: "TEST_ACTION", key1: key1, //... keyN: keyN &#125; &#125; reducer reducer 是一个纯函数，满足以下条件： 相同输入必须有相同输出 不能修改传入的参数 不能包含 random、Date 等非纯函数 另外，reducer 每次返回的必须是一个全新的状态1234567891011121314151617const initialState = &#123; article: &#123;&#125;&#125;;export function article(state = initialState, action) &#123; switch (action.type) &#123; case Actions.ADD_ARTICLE_TAG: &#123; let article = Object.assign(state.article); if(article.tags)&#123; article.tags.push(action.tag); &#125;else&#123; article.tags = [action.tag]; &#125; return &#123; ...state, article: article &#125;; &#125; &#125;&#125; 在 react 项目中使用 redux安装123npm install --save reduxnpm install --save react-reduxnpm install --save-dev redux-devtools 配置在 index.js 文件：12345678910111213141516171819202122import &#123;createStore, applyMiddleware&#125; from &apos;redux&apos;;import &#123;Provider&#125; from &apos;react-redux&apos;;import thunk from &apos;redux-thunk&apos;;import reducers from &apos;./src/reducers/index&apos;;const createStoreWithMiddleware = applyMiddleware(thunk)(createStore);const store = createStoreWithMiddleware(reducers);const router = ( &lt;Provider store=&#123;store&#125;&gt; // 在根组件注入store &lt;Router history=&#123;hashHistory&#125;&gt; &lt;Route path=&quot;/&quot;&gt; &lt;IndexRoute component=&#123;Login&#125; /&gt; &lt;Route path=&quot;/articles&quot; component=&#123;Articles&#125;/&gt; &lt;Route path=&quot;/articledetail&quot; component=&#123;ArticleDetail&#125;/&gt; &lt;/Route&gt; &lt;/Router&gt; &lt;/Provider&gt;)ReactDOM.render(router, document.getElementById(&apos;root&apos;)); 以上： 我们先引入redux和一些函数，再引入写好的 reducer ，createStoreWithMiddleware 函数创建了一个顶级的管理所有状态的储存器，统一管理状态。然后将生成的 store 通过 Provider 组件注入，这样为 Provider 的子组件提供了状态的获取途径。 reducersindex文件:12345678import &#123;combineReducers&#125; from "redux";import &#123; admin &#125; from './admin'; //我自己的 reduce 文件import &#123; article &#125; from "./article"; //同上module.exports = combineReducers( &#123; admin: admin, article: article&#125;); reduce 文件(示例):123456789101112131415161718192021import Actions from "../actions/config";const initialState = &#123; logged: false, token: ''&#125;;export function admin(state = initialState, action) &#123; switch (action.type) &#123; case Actions.USER_LOGIN: &#123; let token = action.token; return &#123; ...state, logged: true, token: token &#125;; &#125; case Actions.USER_LOGOUT: &#123; return &#123; ...state, logged: false &#125;; &#125; &#125; return state;&#125; actionsindex:1234567import &#123; admin &#125; from "./admin";import &#123; article &#125; from "./article";module.exports = &#123; ...admin, ...article&#125;; admin action:12345678910111213141516171819import Actions from "./config"; //储存常量字符串function login(token) &#123; return &#123; type: Actions.USER_LOGIN, token: token &#125;;&#125;function logOut() &#123; return &#123; type: Actions.USER_LOGOUT, &#125;;&#125;export const admin = &#123; login, logOut,&#125;; config：1234567891011121314151617module.exports = &#123; //user USER_LOGIN: "USER_LOGIN", USER_LOGOUT:"USER_LOGOUT", //article ADD_ARTICLE_TAG: "ADD_ARTICLE_TAG", REMOVE_ARTICLE_TAG: "REMOVE_ARTICLE_TAG", SAVE_CONTENT: "SAVE_CONTENT", EDIT_ARTICLE: "EDIT_ARTICLE", CLEAR: "CLEAR", //http GET_PERSONAL_PAGE_INFO: "GET_PERSONAL_PAGE_INFO", GET_USER_INFO: "GET_USER_INFO"&#125;; 使用redux 以上步骤已经配置好了。接下来在组件中使用redux 首先要用到的是高阶函数 connect 引入 connect：1import &#123;connect&#125; from "react-redux"; 连接：12345678910function select(store) &#123; return &#123; logged: store.admin.logged, // 这里写你当前组件要用到的redux里的状态 token: store.admin.token &#125;&#125;export default connect(select)(componentName); //componentName 是你的组件名称//如果不需要redux的数据，可以这样写：//export default connect()(componentName); 这一步把当前组件和 redux 连在一起，把 logged、token传到当前组件的 props 里。需要注意的是：还会隐藏的将 dispatch 方法一起注入到 props 使用：使用属性的时候，只需要：1this.props.propName 如果要修改状态，不能直接赋值，应该使用在 actions 里的行为来触发 reducer 的纯函数来修改状态：123456import &#123; login&#125; from '../actions/index';...this.props.dispatch(login()); 这里的 dispatch 意为 分发、派遣、调度，发起一个行为（action），由reducer接收并处理 更多本文只是对redux的一个入门了解，要想学的更深入还是拜读官方文档，或者去看看源码。另外，redux 有一个最佳实践写法，是由阿里前辈推出的 dva 框架，包含了更多的理解与应用，让redux 强化了处理异步操作的能力。推荐去看看。 最后本文是对自己写博客以及管理后台的时候遇到的问题的总结，有很多问题说的不太对，也没有仔细深究，如果有不对的地方，还请指出。示例代码不详细的话，可以戳这里获取项目源码. 欢迎来访，手动笔芯~]]></content>
      <tags>
        <tag>redux</tag>
        <tag>react</tag>
      </tags>
  </entry>
</search>
